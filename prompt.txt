
========================
Project Context
========================
Python script using Pandas and Owlready2 to parse manufacturing data, building and populating an OWL ontology.

To create a structured knowledge graph representing manufacturing assets (Plant/Line/Equipment hierarchy & equipment sequence) and time-based event records. The primary aim is to enable analysis aligned with the **Asset Effectiveness (AE) model**.


=========================
Asset Effectiveness Model
=========================
The Asset Effectiveness Model is a framework used to analyze and improve the productivity of equipment and manufacturing processes. It works by breaking down the total available time for an asset and identifying the various factors that reduce the amount of time the asset is actually producing effectively.   

The model starts with the concept of "Total Available Time," which is the maximum amount of time an asset could potentially operate (e.g., 24 hours a day, 365 days a year). From this starting point, the model systematically accounts for different categories of time loss:   

ALL TIME VALUES IN RAW DATA ARE REPORTED IN MINUTES (only exception is when column specifies SECONDS) -- this does not apply to datetimes 

Business External Time: This is time lost due to factors outside the control of the plant or production operations.   
Plant Decision Time: This represents time when the plant is not scheduled to run due to management decisions, such as planned shutdowns or lack of orders. Subtracting these losses results in "Plant Available Time".   
Production Available Time: Further time reductions occur due to factors like maintenance, process issues or material shortages.
Unplanned Down Time: This is time lost due to unexpected events like equipment breakdowns or unscheduled maintenance. After accounting for downtime, we arrive at "Run Time".   
Run Time Losses: Even during run time, there can be inefficiencies that reduce effective production, such as slow cycles or reduced yield.   
The ultimate goal is to arrive at "Effective Run Time," which is the time the asset is actually producing good quality output at full capacity.   

To quantify and analyze these time losses, the Asset Effectiveness Model uses several Key Performance Indicators (KPIs):   

Asset Utilization (AU): This is a global metric that measures the percentage of Plant Available Time that is Effective Runtime. It's calculated as (Effective Runtime / Plant Available Time) x 100. AU is often used to set productivity improvement goals and is typically reported monthly.   
Operating Efficiency (OE): This KPI represents how well the operation performed when production wanted the equipment to run. It's calculated as (Effective Runtime / Production Available Time) x 100. OE helps diagnose issues related to maintenance, process, materials, or labor.   
Runtime Efficiency (RE): This measures how well the equipment performed specifically during the time it was supposed to be running. It's calculated as (Effective Runtime / Runtime) x 100. RE helps monitor trends in line throughput and quality.   
Asset Effectiveness (AE): Calculated as (Effective Runtime / Total Available Time) x 100. This metric is monitored over longer periods but is less commonly used than Asset Utilization.   
In essence, the Asset Effectiveness Model provides a structured way to understand where production time is being lost, enabling targeted improvement efforts to maximize asset productivity.

===============
RAW DATA SAMPLE
===============
LINE_NAME,EQUIPMENT_NAME,EQUIPMENT_ID,PLANT,DOWNTIME_DRIVER,OPERA_TYPE,GH_AREA,GH_CATEGORY,GH_FOCUSFACTORY,PHYSICAL_AREA,EQUIPMENT_TYPE,EQUIPMENT_MODEL,COMPLEXITY,MODEL,MATERIAL_ID,SHORT_MATERIAL_ID,SIZE_TYPE,MATERIAL_UOM,UOM_ST,UOM_ST_SAP,TP_UOM,PRODUCTION_ORDER_ID,PRODUCTION_ORDER_DESC,PRODUCTION_ORDER_RATE,PRODUCTION_ORDER_UOM,JOB_START_TIME_LOC,JOB_END_TIME_LOC,UTIL_STATE_DESCRIPTION,UTIL_REASON_DESCRIPTION,UTIL_ALT_LANGUAGE_REASON,CO_TYPE,CO_ORIGINAL_TYPE,SHIFT_NAME,SHIFT_START_DATE_LOC,SHIFT_END_DATE_LOC,SHIFT_DURATION_MIN,CREW_ID,RAMPUP_FLAG,PRODUCTIONDATE_DAY_LOC,PRODUCTIONDATE_MONTH_LOC,PRODUCTIONDATE_QUARTER_LOC,PRODUCTIONDATE_YEAR_LOC,PRIMARY_CONV_FACTOR,PLANT_DESCRIPTION,PLANT_STRATEGIC_LOCATION,PLANT_COUNTRY,PLANT_COUNTRY_DESCRIPTION,PLANT_FACILITY_TYPE,PLANT_POSTAL_CODE,PLANT_PURCHASING_ORGANIZATION,PLANT_STRATEGIC_LOCATION_DESCRIPTION,PLANT_LATITUDE,PLANT_LONGITUDE,PLANT_DIVISION,PLANT_DIVISION_DESCRIPTION,PLANT_SUB_DIVISION,PLANT_SUB_DIVISION_DESCRIPTION,AE_MODEL_CATEGORY,TOTAL_TIME_SECONDS,TOTAL_TIME,BUSINESS_EXTERNAL_TIME,PLANT_AVAILABLE_TIME,EFFECTIVE_RUNTIME,PLANT_DECISION_TIME,PRODUCTION_AVAILABLE_TIME,GOOD_PRODUCTION_QTY,REJECT_PRODUCTION_QTY,DOWNTIME,RUN_TIME,NOT_ENTERED,WAITING_TIME,PLANT_EXPERIMENTATION,ALL_MAINTENANCE,AUTONOMOUS_MAINTENANCE,PLANNED_MAINTENANCE,DAYS_MTD,DAYS_YTD,AVG_THROUGHPUT_MTD,AVG_THROUGHPUT_YTD,CHANGEOVER_COUNT,CHANGEOVER_DURATION,CLEANING_AND_SANITIZATION,LUNCH_AND_BREAK,LUNCH,BREAK,MEETING_AND_TRAINING,NO_DEMAND,SOURCE_DATASET,SOURCE_DATASET_FUNCTIONAL_AREA,SOURCE_DATASET_SUBFUNCTIONAL_AREA
VIPCO012,VIPCO012,273.0,MX11,,Full OPERA,TUBE,OC,TPST,OCTubeMaking,Line,,,,AMX02954479,AMX02954479,TM AISA_28D_Size,EA,0.0,,0.0,108438050.0,108438050.0,500.0,EA,2025-02-10 22:45:02.000 -0500,2025-02-11 11:02:57.000 -0500,DOWNTIME,Ending order,Terminando Orden,ALL,ALL,Shift3,2025-02-10 21:30:00.000 -0500,2025-02-11 05:59:59.000 -0500,510.0,A,False,2025-02-10,2025-02-01,2025-01-01,2025-01-01,1.0,"Mexico, Mission Hills",Y,MX,Mexico,MFG,37980,MX03,Strategic,20.9817163,-100.4223264,LA,Latin America,LA,Latin America,Unplanned,74,1.233333,0.0,1.233333,0.0,0.0,1.233333,0,0,1.233333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,19,78,0.0,0.0,0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,OPERA,Supply Chain,Manufacturing
VIPCO002,VIPCO002_KSM,242.0,MX11,,Full OPERA,TUBE,OC,TPST,OCTubeMaking,Equipment,AISA 500L,,,AMX02954462,AMX02954462,TM AISA_38D_Size,EA,0.0,,0.0,108459605.0,108459605.0,500.0,EA,2025-02-25 17:54:16.000 -0500,2025-02-26 02:04:54.000 -0500,WAITING,Upstream,Falta Producto,ALL,ALL,Shift2,2025-02-25 14:00:00.000 -0500,2025-02-25 21:29:59.000 -0500,450.0,B,False,2025-02-25,2025-02-01,2025-01-01,2025-01-01,1.0,"Mexico, Mission Hills",Y,MX,Mexico,MFG,37980,MX03,Strategic,20.9817163,-100.4223264,LA,Latin America,LA,Latin America,Waiting,962,16.033335,0.0,16.033335,0.0,0.0,16.033335,0,0,0.0,0.0,0.0,16.033335,0.0,0.0,0.0,0.0,19,78,0.0,0.0,0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,OPERA,Supply Chain,Manufacturing
FIPCO006,FIPCO006_CasePacker,227.0,MX11,,Full OPERA,PACK,OC,TPST,OralCare,Equipment,,Kids,TFS30,MX03109A,MX03109A,OFT 38TP_75ml_12_Size,CS,12.0,12.0,12.0,108430287.0,108430287.0,12.0,CS,2025-02-05 20:12:40.000 -0500,2025-02-05 20:13:31.000 -0500,BUSINESS EXTERNAL,No Demand,No Demanda,Size,Size,Shift3,2025-02-04 21:30:00.000 -0500,2025-02-05 05:59:59.000 -0500,510.0,D,False,2025-02-04,2025-02-01,2025-01-01,2025-01-01,12.0,"Mexico, Mission Hills",Y,MX,Mexico,MFG,37980,MX03,Strategic,20.9817163,-100.4223264,LA,Latin America,LA,Latin America,Business External,11605,193.416666,193.416666,0.0,0.0,0.0,0.0,0,0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,19,78,0.0,0.0,0,0.0,0.0,0.0,0.0,0.0,0.0,193.416666,OPERA,Supply Chain,Manufacturing
FIPCO001,FIPCO001_CasePacker,158.0,MX11,,Full OPERA,PACK,OC,TPST,OralCare,Equipment,,Low Complexity,TFS80-6,MX06920A,MX06920A,OFT 25FT_50ml_144_Size,CS,144.0,144.0,144.0,108461424.0,108461424.0,3.130000114,CS,2025-02-27 07:24:47.000 -0500,2025-02-27 18:19:39.000 -0500,DOWNTIME,Ending order,Terminando Orden,Product,Product,Shift1,2025-02-27 06:00:00.000 -0500,2025-02-27 13:59:59.000 -0500,480.0,A,False,2025-02-27,2025-02-01,2025-01-01,2025-01-01,144.0,"Mexico, Mission Hills",Y,MX,Mexico,MFG,37980,MX03,Strategic,20.9817163,-100.4223264,LA,Latin America,LA,Latin America,Unplanned,24,0.4,0.0,0.4,0.0,0.0,0.4,0,0,0.4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,19,78,0.0,0.0,0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,OPERA,Supply Chain,Manufacturing
VIPCO012,VIPCO012_CasePacker,506.0,MX11,,Full OPERA,TUBE,OC,TPST,OCTubeMaking,Equipment,AISA 500L,,,AMX02954249,AMX02954249,TM AISA_28D_Size,EA,0.0,,0.0,108462340.0,108462340.0,500.0,EA,2025-02-27 17:42:28.000 -0500,2025-02-28 02:41:34.000 -0500,DOWNTIME,Ending order,Terminando Orden,Product,Product,Shift2,2025-02-27 14:00:00.000 -0500,2025-02-27 21:29:59.000 -0500,450.0,C,False,2025-02-27,2025-02-01,2025-01-01,2025-01-01,1.0,"Mexico, Mission Hills",Y,MX,Mexico,MFG,37980,MX03,Strategic,20.9817163,-100.4223264,LA,Latin America,LA,Latin America,Unplanned,77,1.283333,0.0,1.283333,0.0,0.0,1.283333,0,0,1.283333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,19,78,0.0,0.0,0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,OPERA,Supply Chain,Manufacturing

================
DATA ANNOTATIONS
================
Raw Data Column Name,Contextual Description,Ontological Relationships/Mapping
PLANT,Identifier code for the manufacturing plant/site.,"Used to create/identify Plant instance (e.g., Plant_{PLANT}). Plant.plantId (Functional Data Property). Links Line, FocusFactory, PhysicalArea, Equipment via locatedInPlant."
GH_FOCUSFACTORY,"Identifier for a specific production unit within the plant (e.g., TPST).","Used to create/identify FocusFactory instance. FocusFactory.focusFactoryName (Functional Data Property). Links to Plant via locatedInPlant; links PhysicalArea, Line, Equipment via partOfFocusFactory."
PHYSICAL_AREA,"Name of the physical location within the Focus Factory containing production lines (e.g., OCTubeMaking, OralCare).","Used to create/identify PhysicalArea instance. PhysicalArea.areaName (Functional Data Property). Links to FocusFactory via partOfFocusFactory; links Line, Equipment via locatedInArea."
LINE_NAME,Unique identifier/name for the manufacturing finishing line.,"Used to create/identify Line instance (e.g., Line_{LINE_NAME}). Line.lineName (Functional Data Property). Links Equipment via isPartOfLine. Used with EQUIPMENT_NAME to parse equipment type."
EQUIPMENT_ID,Unique system identifier (asset ID) for a specific piece of equipment.,"Used as the preferred base for Equipment instance ID (e.g., Equipment_{EQUIPMENT_ID}). Equipment.equipmentId (Functional Data Property)."
EQUIPMENT_NAME,"Name of the equipment, often includes Line prefix (e.g., VIPCO012_CasePacker).",Used to identify Equipment instance if EQUIPMENT_ID is missing. Equipment.equipmentName (Functional Data Property). Parsed (using LINE_NAME) to determine Equipment.equipmentBaseType.
EQUIPMENT_TYPE,Distinguishes if the data row represents the entire 'Line' or a specific 'Equipment' level activity.,Used during mapping to determine if the EventRecord pertains to the Line instance or a specific Equipment instance via involvesEquipment. Not directly stored as ontology property by default.
EQUIPMENT_MODEL,Manufacturer model name/number for the equipment.,"Equipment.equipmentModel (Data Property, potentially Non-functional)."
COMPLEXITY,"Classification of the equipment's complexity (e.g., Low Complexity).",Could be added as Equipment.complexity (Data Property). Currently not explicitly mapped.
MODEL,"Another model identifier, potentially internal.",Could be added as Equipment.alternativeModel (Data Property). Currently not explicitly mapped.
MATERIAL_ID,Unique identifier for the material (SKU) being processed.,"Used to create/identify Material instance. Material.materialId (Functional Data Property). Links EventRecord via processesMaterial (Object Property, Non-functional)."
SHORT_MATERIAL_ID,Shortened or alternative material identifier.,Could map to Material.materialDescription (Data Property) or a separate shortMaterialId property. Currently mapped to description.
SIZE_TYPE,Description of the product's size/format/packaging.,Could be added as Material.sizeType (Data Property). Currently not explicitly mapped.
MATERIAL_UOM,"Unit of Measure for the material (e.g., CS, EA).","Material.materialUOM (Functional Data Property). Unit for goodProductionQty, rejectProductionQty."
"UOM_ST, UOM_ST_SAP, TP_UOM","Standard units of measure, potentially conversion related.",Could be added as properties on Material or used in external calculations. Currently not explicitly mapped.
PRIMARY_CONV_FACTOR,Primary conversion factor between units for the material.,Could be added as Material.conversionFactor (Data Property). Currently not explicitly mapped.
PRODUCTION_ORDER_ID,Identifier for the specific manufacturing work order.,"Used to create/identify ProductionOrder instance. ProductionOrder.orderId (Functional Data Property). Links EventRecord via relatesToOrder (Object Property, Non-functional)."
PRODUCTION_ORDER_DESC,Description associated with the production order.,ProductionOrder.orderDescription (Data Property).
PRODUCTION_ORDER_RATE,Target production rate (speed) for this production order.,ProductionOrder.orderRate (Functional Data Property).
PRODUCTION_ORDER_UOM,Unit of measure for the production order rate/quantity.,ProductionOrder.orderRateUOM (Functional Data Property).
JOB_START_TIME_LOC,Local timestamp indicating the start of the event period recorded.,Used to create TimeInterval instance. TimeInterval.startTime (Functional Data Property). Defines start for EventRecord via occursDuring.
JOB_END_TIME_LOC,Local timestamp indicating the end of the event period recorded.,Used to create TimeInterval instance. TimeInterval.endTime (Functional Data Property). Defines end for EventRecord via occursDuring. Used to calculate calculatedDurationSeconds.
SHIFT_NAME,Name/ID of the work shift during which the event occurred.,Used to create/identify Shift instance. Shift.shiftName (Functional Data Property). Links EventRecord via duringShift (Functional Object Property).
"SHIFT_START_DATE_LOC, SHIFT_END_DATE_LOC",Start/End times for the shift definition.,Could be added as startTime/endTime properties on the Shift instance. Currently not explicitly mapped.
SHIFT_DURATION_MIN,Duration of the shift in minutes.,Could be added as Shift.durationMinutes (Data Property). Currently not explicitly mapped.
CREW_ID,Identifier for the specific crew working during the shift.,Used to create/identify Crew instance. Crew.crewId (Functional Data Property). Links EventRecord via operatedByCrew (Functional Object Property).
RAMPUP_FLAG,Flag indicating if the event occurred during a production ramp-up phase.,"EventRecord.rampUpFlag (Functional Data Property, Boolean)."
PRODUCTIONDATE...,"Date components (Day, Month, Quarter, Year) for the production activities.",Could be linked to EventRecord or TimeInterval via date properties if needed for direct querying. Currently not explicitly mapped. (Can be derived from startTime).
UTIL_STATE_DESCRIPTION,"Description of the equipment/line state during the recorded period (e.g., DOWNTIME, RUNNING).","Determines the specific subclass of UtilizationState (e.g., DowntimeState, RunningState) linked to EventRecord via hasState (Functional Object Property). Original description stored on the State instance."
UTIL_REASON_DESCRIPTION,"Detailed reason for the utilization state (e.g., No Demand, Jammed Machine).","Determines the specific subclass of UtilizationReason (e.g., NoDemandReason, JamReason) linked to EventRecord via hasReason (Object Property, Non-functional). Original description stored on the Reason instance."
UTIL_ALT_LANGUAGE_REASON,Reason description in an alternative language.,Could be added as UtilizationReason.altDescription (Data Property). Currently not explicitly mapped.
DOWNTIME_DRIVER,Higher-level categorization of downtime reason or source system info.,Not explicitly mapped in current structure; potentially redundant or could be added as property on EventRecord or UtilizationReason.
OPERA_TYPE,"Type of operation associated with the source system (e.g., PACK).",Source system metadata. Could be added as property on EventRecord. Currently not explicitly mapped.
"CO_TYPE, CO_ORIGINAL_TYPE","Type of Changeover event occurring (e.g., Size, Product).",Could inform more specific ChangeoverReason subclasses or properties. Currently primarily captured via UTIL_REASON_DESCRIPTION mapping to ChangeoverReason.
TOTAL_TIME,The total duration (in minutes) allocated to this specific event record/state. Key AE Model duration.,"EventRecord.reportedDurationMinutes (Functional Data Property, Float)."
BUSINESS_EXTERNAL_TIME,"Time (minutes) unavailable due to external factors (e.g., No Demand). AE Model Component.","EventRecord.businessExternalTimeMinutes (Functional Data Property, Float)."
PLANT_AVAILABLE_TIME,Total time (minutes) the plant/asset is considered available for production. AE Model Calculation.,"EventRecord.plantAvailableTimeMinutes (Functional Data Property, Float)."
EFFECTIVE_RUNTIME,Idealized value-adding time (minutes) running at max speed with no quality loss. AE Model Output/Target.,"EventRecord.effectiveRuntimeMinutes (Functional Data Property, Float)."
PLANT_DECISION_TIME,"Time (minutes) lost due to plant-level decisions (scheduling, etc.). AE Model Component.","EventRecord.plantDecisionTimeMinutes (Functional Data Property, Float)."
PRODUCTION_AVAILABLE_TIME,Time (minutes) asset was scheduled and available to run. AE Model Calculation.,"EventRecord.productionAvailableTimeMinutes (Functional Data Property, Float)."
DOWNTIME,"Total time (minutes) the asset was scheduled but stopped (unplanned, changeovers, maint.). AE Model Loss Category.","EventRecord.downtimeMinutes (Functional Data Property, Float)."
RUN_TIME,"Total time (minutes) the asset was actually running (incl. slow speed, rejects). AE Model Calculation.","EventRecord.runTimeMinutes (Functional Data Property, Float)."
NOT_ENTERED,Time (minutes) where the state was not recorded or unknown. AE Model Component (Data Gap).,"EventRecord.notEnteredTimeMinutes (Functional Data Property, Float)."
WAITING_TIME,"Time (minutes) spent waiting (upstream, downstream, materials, etc.). AE Model Loss Category (often part of Downtime).","EventRecord.waitingTimeMinutes (Functional Data Property, Float). Corresponds often to WaitingState."
PLANT_EXPERIMENTATION,Time (minutes) used for planned experiments/trials. AE Model Component (Planned Stop).,"EventRecord.plantExperimentationTimeMinutes (Functional Data Property, Float). Corresponds often to ExperimentationReason."
ALL_MAINTENANCE,Total time (minutes) spent on any maintenance. AE Model Loss Category (Planned/Unplanned Stop).,"EventRecord.allMaintenanceTimeMinutes (Functional Data Property, Float)."
AUTONOMOUS_MAINTENANCE,Time (minutes) on operator maintenance. AE Model Component (Planned/Unplanned Stop).,"EventRecord.autonomousMaintenanceTimeMinutes (Functional Data Property, Float). Corresponds often to AutonomousMaintenanceReason."
PLANNED_MAINTENANCE,Time (minutes) on scheduled maintenance. AE Model Component (Planned Stop).,"EventRecord.plannedMaintenanceTimeMinutes (Functional Data Property, Float). Corresponds often to PlannedMaintenanceReason."
CHANGEOVER_DURATION,Time (minutes) spent performing changeovers. AE Model Loss Category (Planned Stop).,"EventRecord.changeoverDurationMinutes (Functional Data Property, Float). Corresponds often to ChangeoverState/ChangeoverReason."
CLEANING_AND_SANITIZATION,Time (minutes) spent on cleaning/sanitation. AE Model Component (Planned Stop).,"EventRecord.cleaningSanitizationTimeMinutes (Functional Data Property, Float). Corresponds often to CleaningSanitationReason."
LUNCH_AND_BREAK,Time (minutes) allocated for operator breaks/lunch. AE Model Component (Planned Stop).,"EventRecord.lunchBreakTimeMinutes (Functional Data Property, Float). Corresponds often to LunchBreakReason."
MEETING_AND_TRAINING,Time (minutes) used for meetings or training. AE Model Component (Planned Stop).,"EventRecord.meetingTrainingTimeMinutes (Functional Data Property, Float). Corresponds often to MeetingTrainingReason."
NO_DEMAND,Time (minutes) line didn't run due to lack of demand. AE Model Component (External).,"EventRecord.noDemandTimeMinutes (Functional Data Property, Float). Corresponds often to NoDemandReason/BusinessExternalState."
GOOD_PRODUCTION_QTY,Quantity of conforming product produced during the event's run time.,"EventRecord.goodProductionQty (Functional Data Property, Float). Unit defined by Material.materialUOM."
REJECT_PRODUCTION_QTY,Quantity of non-conforming product produced during the event's run time.,"EventRecord.rejectProductionQty (Functional Data Property, Float). Unit defined by Material.materialUOM."
CHANGEOVER_COUNT,"Count of changeover events (likely aggregated, not per event record).",Aggregate metric. Not directly stored per EventRecord. Could be calculated from events with ChangeoverState/Reason.
"AVG_THROUGHPUT_MTD, AVG_THROUGHPUT_YTD",Calculated average throughput rates (Month/Year-to-Date).,Aggregate KPIs. Not stored per EventRecord. Calculated from ontology data externally.
"DAYS_MTD, DAYS_YTD",Days Month/Year-to-Date (purpose/validity unclear from sample).,Unclear purpose. Currently not explicitly mapped.
TOTAL_TIME_SECONDS,Redundant duration in seconds.,Ignored. Duration derived from timestamps (calculatedDurationSeconds) or TOTAL_TIME (reportedDurationMinutes).
"LUNCH, BREAK",Separate time for lunch/breaks (potentially redundant with LUNCH_AND_BREAK).,"Could be mapped if LUNCH_AND_BREAK is not reliable, otherwise potentially ignored. Currently ignored in favor of LUNCH_AND_BREAK."
"SOURCE_DATASET, SOURCE_DATASET...AREA",Metadata about the source system/data origin.,"Could be added as properties on EventRecord (e.g., EventRecord.sourceSystem). Currently not explicitly mapped."
PLANT_DESCRIPTION,Full text name of the plant.,Plant.plantDescription (Data Property).
PLANT_STRATEGIC_LOCATION,Code for the plant's strategic location grouping.,Used to create/identify StrategicLocation instance linked via Plant.hasStrategicLocation.
PLANT_COUNTRY,Country code where the plant is located.,Used to create/identify Country instance. Country.countryCode. Links Plant via locatedInCountry.
PLANT_COUNTRY_DESCRIPTION,Full name of the country.,Country.countryName (Functional Data Property).
"PLANT_FACILITY_TYPE, PLANT_POSTAL_CODE, PLANT_PURCHASING_ORGANIZATION, PLANT_STRATEGIC_LOCATION_DESCRIPTION",Other plant attributes.,Could be added as Data Properties on Plant or related instances (StrategicLocation). Currently not explicitly mapped.
"PLANT_DIVISION, PLANT_DIVISION_DESCRIPTION",Business division code and name.,Used to create/identify Division instance. Division.divisionName. Links Plant/FocusFactory via partOfDivision.
"PLANT_SUB_DIVISION, PLANT_SUB_DIVISION_DESCRIPTION",Business sub-division code and name.,Used to create/identify SubDivision instance. SubDivision.subdivisionName. Links Plant/FocusFactory via partOfSubDivision.
"GH_AREA, GH_CATEGORY",Global Hierarchy fields for reporting/categorization.,Could be used to create/identify GlobalHierarchyArea / GlobalHierarchyCategory instances and link Plant/FocusFactory/Line. Currently not explicitly mapped.
AE_MODEL_CATEGORY,"Asset Effectiveness category associated with the asset (e.g., Kids).","Could be added as a property (e.g., Equipment.aeCategory or Line.aeCategory). Currently not explicitly mapped."


==============================
CURRENT CODEBASE - PYTHON CODE
==============================

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Consolidated Python script for Manufacturing Ontology definition, population,
and querying using Owlready2.
"""

import argparse
import logging
import sys
from pathlib import Path
import pandas as pd
import owlready2 as owl
from typing import Dict, Any, Optional, List, Type, Union
from datetime import datetime, timedelta
import re

# =============================================================================
# Logging Setup
# =============================================================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# =============================================================================
# Configuration
# =============================================================================


def get_ontology_settings() -> Dict[str, Any]:
    """Get general ontology settings."""
    return {
        "ontology_iri": "http://example.org/manufacturing_revised_ontology_v2.owl",  # Updated IRI Version
        "default_output_file": "manufacturing_ontology_revised_populated_v2.owl",  # Updated Output Version
        "format": "rdfxml",
    }


def get_equipment_type_sequence_order() -> Dict[str, int]:
    """Define the typical/default sequence order for known equipment types."""
    # Based on EQUIPMENT ORDERING section
    return {
        "Filler": 1,
        "Cartoner": 2,
        "Bundler": 3,
        "CaseFormer": 4,
        "CasePacker": 5,
        "CaseSealer": 6,
        "Palletizer": 7,
        # Add other known types if necessary
    }


def get_equipment_sequence_overrides() -> Dict[str, Dict[str, Dict[str, Any]]]:
    """Define line-specific equipment sequence overrides (order number)."""
    # Example overrides based on previous config examples
    # This now primarily affects the 'sequenceOrder' property value assignment.
    return {
        # Example: VIPCO012 might have a non-standard sequence order
        # "VIPCO012": {
        #     "TubeMaker": {"order": 1}, # Assuming TubeMaker is parsed type
        #     "CasePacker": {"order": 2},
        # },
        # Example: FIPCO006 skips Cartoner, direct Filler->CasePacker
        # "FIPCO006": {
        #     "Filler": {"order": 1},
        #     "CasePacker": {"order": 2}, # Use actual parsed types
        # },
        # Add actual overrides based on real line configurations
    }


# =============================================================================
# Ontology Definition (Core, Classes, Properties) - REVISED
# =============================================================================

# --- Core Ontology Setup ---
settings = get_ontology_settings()
ONTOLOGY_IRI = settings["ontology_iri"]
onto = owl.get_ontology(ONTOLOGY_IRI)

# --- Class Definitions ---
with onto:
    # Basic Thing
    class Thing(owl.Thing):
        pass

    # --- Assets ---
    class ManufacturingAsset(Thing):
        """Base class for all manufacturing assets."""

        pass

    class Plant(ManufacturingAsset):
        """A manufacturing plant/facility."""

        pass

    class Line(ManufacturingAsset):
        """A production line within a plant."""

        pass

    class Equipment(ManufacturingAsset):
        """A specific piece of equipment within a line."""

        pass

    # --- Location ---
    class Location(Thing):
        """Base class for geographical or organizational locations."""

        pass

    class Country(Location):
        pass

    class StrategicLocation(Location):
        pass

    class PhysicalArea(Location):
        """A physical area within a Focus Factory, containing Lines."""

        pass

    # --- Organizational ---
    class OrganizationalUnit(Thing):
        """Base class for organizational units."""

        pass

    class Division(OrganizationalUnit):
        pass

    class SubDivision(OrganizationalUnit):
        pass

    class FocusFactory(OrganizationalUnit):
        """A specialized production unit within a Plant (e.g., TPST)."""

        pass

    class GlobalHierarchyArea(OrganizationalUnit):
        pass  # e.g., TUBE/PACK from GH_AREA

    class GlobalHierarchyCategory(OrganizationalUnit):
        pass  # e.g., OC from GH_CATEGORY

    class PurchasingOrganization(OrganizationalUnit):
        pass

    class Crew(OrganizationalUnit):
        pass

    # --- Process Context ---
    class ProcessContext(Thing):
        """Base class for elements related to the production process."""

        pass

    class Material(ProcessContext):
        pass

    class ProductionOrder(ProcessContext):
        pass

    # --- Time Related ---
    class TimeRelated(Thing):
        pass

    class TimeInterval(TimeRelated):
        """Represents a specific interval in time with a start and end."""

        pass

    class Shift(TimeRelated):
        pass

    # --- Events ---
    class EventRecord(Thing):
        """Represents a single record from the source data, capturing a state over a time interval."""

        pass

    # --- Utilization States (REVISED based on AE Model) ---
    class UtilizationState(Thing):
        """The operational state of an asset during an EventRecord, aligned with AE Model categories."""

        pass

    class RuntimeState(UtilizationState):
        """State corresponding to AE Model category 'Runtime'."""

        pass

    class UnplannedState(UtilizationState):
        """State corresponding to AE Model category 'Unplanned'."""

        pass

    class WaitingState(UtilizationState):
        """State corresponding to AE Model category 'Waiting'."""

        pass

    class PlantDecisionState(UtilizationState):
        """State corresponding to AE Model category 'Plant Decision'."""

        pass

    class BusinessExternalState(UtilizationState):
        """State corresponding to AE Model category 'Business External'."""

        pass

    class UnknownAEState(UtilizationState):
        """State when the AE Model category could not be determined."""

        pass

    # --- Utilization Reasons (Hierarchy kept, but mapping from free text removed) ---
    class UtilizationReason(Thing):
        """The reason behind a specific UtilizationState. (Hierarchy retained for potential future use)."""

        pass

    # Reasons for Planned Stops
    class PlannedReason(UtilizationReason):
        pass

    class MaintenanceReason(PlannedReason):
        pass

    class PlannedMaintenanceReason(MaintenanceReason):
        pass

    class AutonomousMaintenanceReason(MaintenanceReason):
        pass

    class CleaningSanitationReason(PlannedReason):
        pass

    class ChangeoverReason(PlannedReason):
        pass

    class OperationalPlannedReason(PlannedReason):
        pass

    class LunchBreakReason(OperationalPlannedReason):
        pass

    class MeetingTrainingReason(OperationalPlannedReason):
        pass

    class ExperimentationReason(PlannedReason):
        pass

    # Reasons for Unplanned Stops (Downtime/Waiting)
    class UnplannedReason(UtilizationReason):
        pass

    class BreakdownReason(UnplannedReason):
        pass

    class JamReason(UnplannedReason):
        pass

    class AdjustmentReason(UnplannedReason):
        pass

    class ProcessReason(UnplannedReason):
        pass

    class WaitingReason(UnplannedReason):
        pass  # Maps to WaitingState now

    class WaitingForMaterialReason(WaitingReason):
        pass

    class WaitingForOperatorReason(WaitingReason):
        pass

    class WaitingForUpstreamReason(WaitingReason):
        pass

    class WaitingForDownstreamReason(WaitingReason):
        pass

    class WaitingOtherReason(WaitingReason):
        pass

    # Reasons for External Non-Availability
    class ExternalReason(UtilizationReason):
        pass

    class NoDemandReason(ExternalReason):
        pass

    class ExternalFactorReason(ExternalReason):
        pass

    # Other potential reasons
    class QualityLossReason(UtilizationReason):
        pass

    class SpeedLossReason(UtilizationReason):
        pass

    class UnknownReason(UtilizationReason):
        pass


# --- Property Definitions (REVISED) ---
with onto:
    # --- Object Properties (Relationships) ---

    # EventRecord Relationships
    class occursAtPlant(owl.ObjectProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [Plant]

    class occursOnLine(owl.ObjectProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [Line]

    class involvesEquipment(owl.ObjectProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [Equipment]  # Event usually relates to one specific equip instance

    class hasState(owl.ObjectProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [UtilizationState]  # An event captures one AE state

    class hasReason(owl.ObjectProperty):  # Kept, but not populated from free text
        domain = [EventRecord]
        range = [UtilizationReason]
        # Non-functional allows linking if specific reasons *can* be identified later

    class occursDuring(owl.ObjectProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [TimeInterval]

    class processesMaterial(owl.ObjectProperty):
        domain = [EventRecord]
        range = [Material]  # Non-functional

    class relatesToOrder(owl.ObjectProperty):
        domain = [EventRecord]
        range = [ProductionOrder]  # Non-functional

    class duringShift(owl.ObjectProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [Shift]

    class operatedByCrew(owl.ObjectProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [Crew]

    # --- Asset Hierarchy & Location Relationships (INVERSES CORRECTED) ---

    # Focus Factory Relationships
    class locatedInPlant(owl.ObjectProperty, owl.FunctionalProperty):
        # Domain expanded to include FocusFactory
        domain = [Line, Equipment, PhysicalArea, FocusFactory]
        range = [Plant]
        # Inverse will be defined on Plant (e.g., plantContains) if needed, or managed via FF's inverse

    class hasFocusFactory(owl.ObjectProperty):  # Plant -> FocusFactory
        domain = [Plant]
        range = [FocusFactory]
        # inverse_property = locatedInPlant # CORRECTED: Inverse defined on FocusFactory instead

    class partOfFocusFactory(
        owl.ObjectProperty, owl.FunctionalProperty
    ):  # Area/Line/Equip -> FocusFactory
        domain = [PhysicalArea, Line, Equipment]
        range = [FocusFactory]
        # Inverse defined below

    # Define inverses on FocusFactory
    class ffHasArea(owl.ObjectProperty):
        domain = [FocusFactory]
        range = [PhysicalArea]
        inverse_property = partOfFocusFactory

    class ffHasLine(owl.ObjectProperty):
        domain = [FocusFactory]
        range = [Line]
        inverse_property = partOfFocusFactory

    class ffHasEquipment(owl.ObjectProperty):
        domain = [FocusFactory]
        range = [Equipment]
        inverse_property = partOfFocusFactory

    # Also set inverse for hasFocusFactory
    locatedInPlant.inverse_property = hasFocusFactory  # FF -> Plant inverse

    # Physical Area Relationships
    class hasArea(owl.ObjectProperty):  # FocusFactory -> Area (Now use ffHasArea)
        # This might be redundant now, consider removing if ffHasArea covers it. Keep for now.
        domain = [FocusFactory]
        range = [PhysicalArea]
        inverse_property = partOfFocusFactory  # Okay

    class locatedInArea(
        owl.ObjectProperty, owl.FunctionalProperty
    ):  # Line/Equip -> Area
        domain = [Line, Equipment]
        range = [PhysicalArea]
        # Inverse defined below

    # Define inverses on PhysicalArea
    class areaHasLine(owl.ObjectProperty):
        domain = [PhysicalArea]
        range = [Line]
        inverse_property = locatedInArea

    class areaHasEquipment(owl.ObjectProperty):
        domain = [PhysicalArea]
        range = [Equipment]
        inverse_property = locatedInArea

    # Line Relationships
    class hasLine(owl.ObjectProperty):  # PhysicalArea -> Line (Now use areaHasLine)
        # This might be redundant now, consider removing if areaHasLine covers it. Keep for now.
        domain = [PhysicalArea]
        range = [Line]
        inverse_property = locatedInArea  # Okay

    class isPartOfLine(owl.ObjectProperty, owl.FunctionalProperty):  # Equip -> Line
        domain = [Equipment]
        range = [Line]
        # inverse_property = hasLine # CORRECTED below

    # Equipment Relationships
    class hasEquipment(owl.ObjectProperty):  # Line -> Equip
        domain = [Line]
        range = [Equipment]
        inverse_property = isPartOfLine  # CORRECT

    # Correct inverse for isPartOfLine
    isPartOfLine.inverse_property = hasEquipment  # CORRECT

    # Other Location Relationships
    class locatedInCountry(owl.ObjectProperty, owl.FunctionalProperty):
        domain = [Plant]
        range = [Country]

    class hasStrategicLocation(owl.ObjectProperty, owl.FunctionalProperty):
        domain = [Plant]
        range = [StrategicLocation]

    # Equipment Sequence Relationships
    class isImmediatelyUpstreamOf(owl.ObjectProperty):
        domain = [Equipment]
        range = [Equipment]
        # Non-functional, inverse defined below

    class isImmediatelyDownstreamOf(owl.ObjectProperty):
        domain = [Equipment]
        range = [Equipment]
        inverse_property = isImmediatelyUpstreamOf  # CORRECT

    # Organizational Relationships (Example - check if inverses needed/correct)
    class partOfDivision(owl.ObjectProperty, owl.FunctionalProperty):
        domain = [Plant, FocusFactory]
        range = [Division]

    class partOfSubDivision(owl.ObjectProperty, owl.FunctionalProperty):
        domain = [Plant, FocusFactory]
        range = [SubDivision]

    # --- Data Properties (Attributes) ---

    # TimeInterval Properties
    class startTime(owl.DataProperty, owl.FunctionalProperty):
        domain = [TimeInterval]
        range = [datetime]

    class endTime(owl.DataProperty, owl.FunctionalProperty):
        domain = [TimeInterval]
        range = [datetime]

    # Plant Properties
    class plantId(owl.DataProperty, owl.FunctionalProperty):
        domain = [Plant]
        range = [str]

    class plantDescription(owl.DataProperty):
        domain = [Plant]
        range = [str]

    class latitude(owl.DataProperty, owl.FunctionalProperty):
        domain = [Plant]
        range = [float]

    class longitude(owl.DataProperty, owl.FunctionalProperty):
        domain = [Plant]
        range = [float]

    # Country Properties
    class countryCode(owl.DataProperty, owl.FunctionalProperty):
        domain = [Country]
        range = [str]

    class countryName(owl.DataProperty, owl.FunctionalProperty):
        domain = [Country]
        range = [str]

    # StrategicLocation Property (NEW)
    class strategicLocationName(owl.DataProperty, owl.FunctionalProperty):
        domain = [StrategicLocation]
        range = [str]

    # Line Properties
    class lineName(owl.DataProperty, owl.FunctionalProperty):
        domain = [Line]
        range = [str]

    # Equipment Properties
    class equipmentId(owl.DataProperty, owl.FunctionalProperty):
        domain = [Equipment]
        range = [str]

    class equipmentName(owl.DataProperty, owl.FunctionalProperty):
        domain = [Equipment]
        range = [str]

    class equipmentBaseType(owl.DataProperty, owl.FunctionalProperty):
        domain = [Equipment]
        range = [str]

    class equipmentModel(owl.DataProperty):
        domain = [Equipment]
        range = [str]

    class sequenceOrder(owl.DataProperty, owl.FunctionalProperty):
        domain = [Equipment]
        range = [int]

    # FocusFactory, Area, Org Properties
    class focusFactoryName(owl.DataProperty, owl.FunctionalProperty):
        domain = [FocusFactory]
        range = [str]

    class areaName(owl.DataProperty, owl.FunctionalProperty):
        domain = [PhysicalArea]
        range = [str]

    class divisionName(owl.DataProperty, owl.FunctionalProperty):
        domain = [Division]
        range = [str]

    class subdivisionName(owl.DataProperty, owl.FunctionalProperty):
        domain = [SubDivision]
        range = [str]

    # Material Properties
    class materialId(owl.DataProperty, owl.FunctionalProperty):
        domain = [Material]
        range = [str]

    class materialDescription(owl.DataProperty):
        domain = [Material]
        range = [str]

    class materialUOM(owl.DataProperty, owl.FunctionalProperty):
        domain = [Material]
        range = [str]

    # Production Order Properties
    class orderId(owl.DataProperty, owl.FunctionalProperty):
        domain = [ProductionOrder]
        range = [str]

    class orderDescription(owl.DataProperty):
        domain = [ProductionOrder]
        range = [str]

    class orderRate(owl.DataProperty, owl.FunctionalProperty):
        domain = [ProductionOrder]
        range = [float]

    class orderRateUOM(owl.DataProperty, owl.FunctionalProperty):
        domain = [ProductionOrder]
        range = [str]

    # Shift/Crew Properties
    class shiftName(owl.DataProperty, owl.FunctionalProperty):
        domain = [Shift]
        range = [str]

    class crewId(owl.DataProperty, owl.FunctionalProperty):
        domain = [Crew]
        range = [str]

    # EventRecord Properties
    class calculatedDurationSeconds(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class reportedDurationMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class rampUpFlag(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [bool]

    # NEW: Raw descriptions captured on EventRecord
    class rawStateDescription(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [str]

    class rawReasonDescription(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [str]

    # AE Model Time Components (All Functional Floats on EventRecord)
    class businessExternalTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class plantAvailableTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class effectiveRuntimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class plantDecisionTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class productionAvailableTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class downtimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]  # Corresponds to 'Unplanned' AE category total?

    class runTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]  # Corresponds to 'Runtime' AE category total?

    class notEnteredTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]  # Part of 'Unplanned'?

    class waitingTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]  # Corresponds to 'Waiting' AE category total?

    # Note: Some time properties below might map conceptually *within* AE categories (e.g., Maintenance within Plant Decision/Unplanned)
    # Keep them as distinct properties on EventRecord for detailed data capture.
    class plantExperimentationTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class allMaintenanceTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class autonomousMaintenanceTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class plannedMaintenanceTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class changeoverDurationMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class cleaningSanitizationTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class lunchBreakTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class meetingTrainingTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class noDemandTimeMinutes(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]  # Part of 'Business External'?

    # Production Quantities
    class goodProductionQty(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    class rejectProductionQty(owl.DataProperty, owl.FunctionalProperty):
        domain = [EventRecord]
        range = [float]

    # REMOVED: stateDescription, reasonDescription from UtilizationState/Reason classes

    # UtilizationReason Properties (Kept for potential future use of hierarchy)
    class reasonDescription(
        owl.DataProperty
    ):  # Keep property definition, but don't populate from free text
        domain = [UtilizationReason]
        range = [str]


# =============================================================================
# Utility Functions (Largely Unchanged)
# =============================================================================


def parse_datetime_with_tz(timestamp_str: Optional[str]) -> Optional[datetime]:
    """Parse timestamps with timezone information (YYYY-MM-DD HH:MM:SS.fff +/-HHMM)."""
    if (
        pd.isna(timestamp_str)
        or not isinstance(timestamp_str, str)
        or not timestamp_str.strip()
    ):
        return None

    timestamp_str = timestamp_str.strip()

    try:
        # Format expected by source data: 'YYYY-MM-DD HH:MM:SS.fff +/-HHMM'
        if " " in timestamp_str and ("+" in timestamp_str or "-" in timestamp_str[-6:]):
            parts = timestamp_str.rsplit(" ", 1)
            dt_part_str = parts[0]
            tz_part_str = parts[1]

            if ":" in tz_part_str:
                tz_part_str = tz_part_str.replace(":", "")

            if not (
                len(tz_part_str) == 5
                and tz_part_str[0] in ("+", "-")
                and tz_part_str[1:].isdigit()
            ):
                raise ValueError("Timezone offset not in +/-HHMM format")

            timestamp_to_parse = f"{dt_part_str}{tz_part_str}"
            if "." in dt_part_str:
                format_str = "%Y-%m-%d %H:%M:%S.%f%z"
            else:
                format_str = "%Y-%m-%d %H:%M:%S%z"  # Handle cases without milliseconds

            dt_obj = datetime.strptime(timestamp_to_parse, format_str)
            return dt_obj
        else:
            logger.warning(
                f"Timestamp '{timestamp_str}' lacks recognizable timezone offset. Attempting naive parse."
            )
            if "." in timestamp_str:
                format_str = "%Y-%m-%d %H:%M:%S.%f"
            else:
                format_str = "%Y-%m-%d %H:%M:%S"
            dt_obj = datetime.strptime(timestamp_str, format_str)
            logger.warning(f"Parsed '{timestamp_str}' as NAIVE datetime.")
            return dt_obj

    except ValueError as e:
        try:
            iso_str = (
                timestamp_str.replace(" ", "T", 1)
                if " " in timestamp_str
                else timestamp_str
            )
            dt_obj = datetime.fromisoformat(iso_str)
            if dt_obj.tzinfo is None:
                logger.warning(
                    f"Parsed timestamp '{timestamp_str}' as naive datetime using fromisoformat fallback."
                )
            else:
                logger.warning(
                    f"Parsed timestamp '{timestamp_str}' using fromisoformat fallback."
                )
            return dt_obj
        except Exception as e2:
            logger.error(
                f"Error parsing timestamp '{timestamp_str}': Primary error: {e}, Fallback ISO error: {e2}"
            )
            return None
    except Exception as e_gen:
        logger.error(f"Unexpected error parsing timestamp '{timestamp_str}': {e_gen}")
        return None


def parse_equipment_base_type(equipment_name: str, line_name: str) -> str:
    """
    Extract the base equipment type (e.g., 'CasePacker') from the full equipment name
    (e.g., 'FIPCO006_CasePacker') using the line name.
    Handles potential trailing numbers (e.g., 'CasePacker2' -> 'CasePacker').
    Returns 'Unknown' if parsing fails or inputs are invalid.
    """
    if (
        not isinstance(equipment_name, str)
        or not isinstance(line_name, str)
        or not equipment_name
        or not line_name
    ):
        logger.debug(
            f"Invalid input for parsing equipment type: eq_name='{equipment_name}', line_name='{line_name}'"
        )
        return "Unknown"

    equipment_name = equipment_name.strip()
    line_name = line_name.strip()

    prefix = f"{line_name}_"
    if equipment_name.startswith(prefix):
        base_type_part = equipment_name[len(prefix) :]
        base_type = re.sub(
            r"\d+$", "", base_type_part
        )  # Remove potential trailing numbers

        if base_type:
            logger.debug(
                f"Parsed equipment type '{base_type}' from '{equipment_name}' using line '{line_name}'"
            )
            return base_type
        else:
            logger.warning(
                f"Equipment name '{equipment_name}' matches prefix '{prefix}' but has no type part."
            )
            return "Unknown"

    known_types_lower = {t.lower(): t for t in get_equipment_type_sequence_order()}
    if equipment_name.lower() in known_types_lower:
        base_type = known_types_lower[equipment_name.lower()]
        logger.debug(
            f"Equipment name '{equipment_name}' directly matched known type '{base_type}'."
        )
        return base_type

    if "_" in equipment_name:
        possible_type_part = equipment_name.split("_")[-1]
        base_type = re.sub(r"\d+$", "", possible_type_part)
        if base_type:
            if base_type.lower() in known_types_lower:
                return known_types_lower[base_type.lower()]

    logger.debug(
        f"Could not parse equipment type from '{equipment_name}' using line '{line_name}'. Returning 'Unknown'."
    )
    return "Unknown"


def clean_string_value(value: Any) -> Optional[str]:
    """Clean string values, handling None and NaN, return None if invalid."""
    if pd.isna(value) or value is None:
        return None
    cleaned = str(value).strip()
    return cleaned if cleaned else None


def clean_numeric_value(value: Any) -> Optional[float]:
    """Clean numeric values, handling None/NaN/empty strings, return float or None."""
    if pd.isna(value) or value is None or value == "":
        return None
    try:
        if isinstance(value, str):
            value = value.replace(",", "")
        return float(value)
    except (ValueError, TypeError):
        logger.warning(
            f"Could not convert value '{value}' (type: {type(value)}) to float."
        )
        return None


def clean_boolean_value(value: Any) -> Optional[bool]:
    """Clean boolean values, handling None/NaN/strings, return bool or None."""
    if pd.isna(value) or value is None:
        return None
    if isinstance(value, bool):
        return value
    if isinstance(value, (int, float)):
        return bool(value)
    if isinstance(value, str):
        val_lower = value.strip().lower()
        if val_lower in ["true", "t", "yes", "y", "1"]:
            return True
        if val_lower in ["false", "f", "no", "n", "0"]:
            return False
    logger.warning(f"Could not convert value '{value}' to boolean.")
    return None  # Or raise error? Returning None seems safer.


# =============================================================================
# Ontology Helper Functions (REVISED)
# =============================================================================

# Cache for shared instances (like AE states)
_shared_instances_cache = {}


def get_or_create_instance(
    cls: Type[owl.Thing],
    instance_id: str,
    properties: Optional[Dict[str, Any]] = None,
    namespace: owl.Namespace = onto,
    use_cache: bool = False,  # Flag primarily for AE state instances
) -> owl.Thing:
    """
    Get existing instance by identifier or create a new one.
    Handles functional properties by overwriting, non-functional by appending unique.
    Uses a cache for specific classes if use_cache=True.
    """
    if not instance_id or not isinstance(instance_id, str):
        raise ValueError(
            f"Invalid instance_id provided for class {cls.__name__}: {instance_id}"
        )

    # Sanitize ID for IRI - replace non-word chars (excluding hyphen) with underscore
    sanitized_id = re.sub(r"[^\w\-]+", "_", instance_id)
    # Prevent IDs starting with numbers if using certain RDF formats
    if sanitized_id and sanitized_id[0].isdigit():  # Added check for empty string
        sanitized_id = f"_{sanitized_id}"

    # Handle potential empty sanitized_id after sanitization
    if not sanitized_id:
        raise ValueError(
            f"Sanitized instance_id became empty for original ID '{instance_id}' and class {cls.__name__}"
        )

    instance_iri = f"{namespace.base_iri}{sanitized_id}"

    instance = None
    cache_key = (cls, sanitized_id)  # Use class and sanitized ID for cache key

    if use_cache and cache_key in _shared_instances_cache:
        instance = _shared_instances_cache[cache_key]
        # logger.debug(f"Retrieved '{sanitized_id}' of class {cls.__name__} from cache.") # Can be noisy
    else:
        # Search in the world associated with the namespace
        instance = namespace.world.search_one(iri=instance_iri)
        if instance is not None:
            # Check if the found instance is of the expected class type
            if not isinstance(instance, cls):
                # Check superclass compatibility (more robust check)
                instance_class = instance.__class__
                expected_class = cls
                # Check MRO (Method Resolution Order) for flexibility
                if not any(c == expected_class for c in instance_class.mro()):
                    raise TypeError(
                        f"IRI conflict: Found existing instance <{instance_iri}> of type {instance_class.__name__}, not compatible with expected type {expected_class.__name__} (not in MRO)."
                    )
                # If compatible, use existing
            # else: # Instance is of the correct type or a subclass, which is okay
            #     logger.debug(f"Retrieved existing instance '{sanitized_id}' of class {cls.__name__} from ontology.")
            pass  # Use the retrieved instance
        else:
            # logger.debug(f"Creating new instance '{sanitized_id}' of class {cls.__name__}.")
            instance = cls(sanitized_id, namespace=namespace)

        if use_cache:  # Add to cache whether found or newly created
            _shared_instances_cache[cache_key] = instance
            # logger.debug(f"Stored/Updated '{sanitized_id}' of class {cls.__name__} in cache.")

    # Assign properties if provided
    if properties:
        for prop_name, value in properties.items():
            if value is None:  # Skip None values explicitly
                continue

            try:
                # --- MODIFIED PROPERTY LOOKUP & VALIDATION ---
                prop = None  # Initialize prop
                try:
                    prop = onto[prop_name]  # Use dictionary-style lookup
                    # --- ADD DEBUG LOGGING ---
                    logger.debug(
                        f"For prop_name '{prop_name}', onto[...] lookup returned: {prop} (type: {type(prop)})"
                    )
                    # --- END DEBUG LOGGING ---
                except KeyError:
                    logger.warning(
                        f"Property '{prop_name}' not found via dictionary lookup (KeyError) for class {cls.__name__}. Skipping assignment for instance {instance.name}."
                    )
                    continue

                is_prop_instance = isinstance(prop, owl.Property)
                is_prop_subclass = False
                if prop is not None and isinstance(
                    prop, type
                ):  # Check if prop is a class type
                    try:
                        # Check if it's a subclass of owl.Property
                        is_prop_subclass = issubclass(prop, owl.Property)
                    except TypeError:
                        # issubclass() arg 1 must be a class
                        pass  # is_prop_subclass remains False

                logger.debug(
                    f"Property '{prop_name}': is_instance={is_prop_instance}, is_subclass={is_prop_subclass}"
                )

                # Check if it's a valid property (either instance or subclass)
                if not is_prop_instance and not is_prop_subclass:
                    logger.warning(
                        f"Property '{prop_name}' resolved to something ({type(prop)}) that is neither an instance nor a subclass of owl.Property for class {cls.__name__}. Skipping assignment for instance {instance.name}."
                    )
                    continue
                # --- END MODIFIED LOOKUP & VALIDATION ---

                # --- Determine if Functional (Works for both class and instance) ---
                # Check the MRO (Method Resolution Order) for the FunctionalProperty mixin
                prop_mro_check_target = (
                    prop if isinstance(prop, type) else prop.__class__
                )
                is_functional = owl.FunctionalProperty in prop_mro_check_target.mro()
                logger.debug(
                    f"Property '{prop_name}' determined as functional? {is_functional}"
                )
                # --- End Functional Check ---

                # --- Property Assignment Logic (Largely unchanged, uses setattr) ---
                if is_functional:
                    actual_value_to_set = (
                        value[0] if isinstance(value, list) and value else value
                    )
                    if isinstance(value, list) and len(value) > 1:
                        logger.warning(
                            f"Assigning only first value to functional property '{prop_name}' on {instance.name}"
                        )

                    current_direct_val = getattr(instance, prop_name, None)
                    if current_direct_val != actual_value_to_set:
                        setattr(instance, prop_name, actual_value_to_set)
                        # logger.debug(f"Set functional property '{prop_name}' on {instance.name}")

                else:  # Non-functional
                    current_list = list(getattr(instance, prop_name, []))
                    values_to_add = value if isinstance(value, list) else [value]

                    updated_list = list(current_list)
                    newly_added_count = 0
                    for val_item in values_to_add:
                        # Ensure we don't add duplicates
                        if val_item is not None:
                            # Need careful comparison, especially for OWL individuals
                            is_duplicate = False
                            for existing_item in updated_list:
                                if val_item == existing_item:
                                    is_duplicate = True
                                    break
                            if not is_duplicate:
                                updated_list.append(val_item)
                                newly_added_count += 1

                    if newly_added_count > 0:
                        setattr(instance, prop_name, updated_list)
                        # logger.debug(f"Added {newly_added_count} item(s) to non-functional property '{prop_name}' on {instance.name}")

            except AttributeError as ae:
                logger.error(
                    f"AttributeError processing property '{prop_name}' on {instance.name}. Error: {ae}",
                    exc_info=False,
                )
            except Exception as e:
                logger.error(
                    f"Unexpected error setting property '{prop_name}' on instance {instance.name} with value '{value}': {e}",
                    exc_info=True,
                )

    return instance


# --- NEW Helper for AE State Instances ---
def get_ae_state_instance(
    ae_category_name: str, StateClass: Type[UtilizationState]
) -> UtilizationState:
    """
    Gets or creates a shared, cached instance for an AE UtilizationState class.
    The instance ID is derived from the class name and AE category name.
    No description is stored on the state instance itself.
    """
    if not ae_category_name or not StateClass:
        raise ValueError("Valid AE category name and StateClass are required.")

    # Create a clean ID, e.g., UnplannedState_Unplanned
    # Sanitize the category name just in case
    sanitized_category = re.sub(r"[^\w\-]+", "_", ae_category_name)
    instance_id = f"{StateClass.__name__}_{sanitized_category}"

    # Use get_or_create_instance with caching, but no properties
    instance = get_or_create_instance(
        cls=StateClass,
        instance_id=instance_id,
        properties=None,  # Important: Do not store descriptions here
        use_cache=True,
    )
    return instance


# =============================================================================
# Data Handling Functions (Load, Preprocess, Map - REVISED)
# =============================================================================


def load_csv_data(csv_path: str) -> pd.DataFrame:
    """Load data from CSV file."""
    logger.info(f"Loading data from {csv_path}")
    try:
        # Specify dtype for potential ID columns to avoid mixed type warnings if possible
        # Adjust based on actual data - this is a guess
        dtype_spec = {
            "EQUIPMENT_ID": str,
            "PRODUCTION_ORDER_ID": str,
            "MATERIAL_ID": str,
            "SHORT_MATERIAL_ID": str,
            "PLANT": str,
            "LINE_NAME": str,
            "EQUIPMENT_NAME": str,
            "CREW_ID": str,
            # Add others known to be strings or specific types
        }
        df = pd.read_csv(csv_path, low_memory=False, dtype=dtype_spec)
        # Add a unique record ID for easier instance naming/debugging
        df["record_id_str"] = df.index.astype(str)
        logger.info(f"Loaded {len(df)} rows")
        return df
    except FileNotFoundError:
        logger.error(f"Error: {csv_path} not found")
        raise
    except Exception as e:
        logger.error(f"Error loading CSV: {e}")
        raise ValueError(f"Failed to parse CSV: {e}")


def preprocess_manufacturing_data(df: pd.DataFrame) -> pd.DataFrame:
    """Preprocess manufacturing data for ontology population."""
    processed_df = df.copy()
    logger.info("Starting preprocessing...")

    # Define column types for cleaning
    # Ensure AE_MODEL_CATEGORY is treated as a key string identifier
    id_cols = [
        "EQUIPMENT_ID",
        "PRODUCTION_ORDER_ID",
        "MATERIAL_ID",
        "SHORT_MATERIAL_ID",
        "PLANT",
        "LINE_NAME",
        "EQUIPMENT_NAME",
        "CREW_ID",
        "AE_MODEL_CATEGORY",  # Treat as key identifier string
        "UTIL_STATE_DESCRIPTION",  # Will be captured as raw text
        "UTIL_REASON_DESCRIPTION",  # Will be captured as raw text
        "EQUIPMENT_TYPE",  # Row level 'Line' or 'Equipment'
        # Add other categorical/ID-like string columns here
        "PLANT_COUNTRY",
        "PLANT_STRATEGIC_LOCATION",
        "GH_FOCUSFACTORY",
        "PHYSICAL_AREA",
        "SHIFT_NAME",
        "MATERIAL_UOM",
        "PRODUCTION_ORDER_UOM",
    ]
    boolean_cols = ["RAMPUP_FLAG"]
    numeric_cols = [
        "TOTAL_TIME",
        "BUSINESS_EXTERNAL_TIME",
        "PLANT_AVAILABLE_TIME",
        "EFFECTIVE_RUNTIME",
        "PLANT_DECISION_TIME",
        "PRODUCTION_AVAILABLE_TIME",
        "GOOD_PRODUCTION_QTY",
        "REJECT_PRODUCTION_QTY",
        "DOWNTIME",
        "RUN_TIME",
        "NOT_ENTERED",
        "WAITING_TIME",
        "PLANT_EXPERIMENTATION",
        "ALL_MAINTENANCE",
        "AUTONOMOUS_MAINTENANCE",
        "PLANNED_MAINTENANCE",
        "CHANGEOVER_DURATION",
        "CLEANING_AND_SANITIZATION",
        "LUNCH_AND_BREAK",
        "LUNCH",
        "BREAK",
        "MEETING_AND_TRAINING",
        "NO_DEMAND",
        "PRIMARY_CONV_FACTOR",
        "PRODUCTION_ORDER_RATE",
        "SHIFT_DURATION_MIN",
        "PLANT_LATITUDE",
        "PLANT_LONGITUDE",
        "CHANGEOVER_COUNT",
        # UOM_ST, UOM_ST_SAP, TP_UOM - check if numeric or string codes
    ]
    datetime_cols = [  # Columns to be parsed later
        "JOB_START_TIME_LOC",
        "JOB_END_TIME_LOC",
        # Add others like SHIFT_START/END if they are full datetime strings
    ]

    # Clean String/ID columns
    for col in id_cols:
        if col in processed_df.columns:
            processed_df[col] = processed_df[col].apply(clean_string_value)
            # logger.debug(f"Cleaned string/ID column: {col}")

    # Clean Boolean columns
    for col in boolean_cols:
        if col in processed_df.columns:
            processed_df[col] = processed_df[col].apply(clean_boolean_value)
            # logger.debug(f"Cleaned boolean column: {col}")

    # Clean Numeric columns
    for col in numeric_cols:
        if col in processed_df.columns:
            processed_df[col] = processed_df[col].apply(clean_numeric_value)
            # logger.debug(f"Cleaned numeric column: {col}")

    # Clean remaining unspecified columns as general strings (descriptions etc.)
    all_cols = set(processed_df.columns)
    handled_cols = (
        set(id_cols)
        | set(boolean_cols)
        | set(numeric_cols)
        | set(datetime_cols)
        | {"record_id_str"}
    )
    other_string_cols = list(all_cols - handled_cols)
    for col in other_string_cols:
        if col in processed_df.columns:
            # Assume remaining are descriptive strings unless known otherwise
            processed_df[col] = processed_df[col].apply(clean_string_value)
            # logger.debug(f"Cleaned potential string column: {col}")

    # --- Extract Equipment Base Type ---
    logger.info("Extracting Equipment Base Type from EQUIPMENT_NAME...")
    if "EQUIPMENT_NAME" in processed_df.columns and "LINE_NAME" in processed_df.columns:
        processed_df["EQUIPMENT_BASE_TYPE"] = processed_df.apply(
            lambda row: parse_equipment_base_type(
                row["EQUIPMENT_NAME"], row["LINE_NAME"]
            ),
            axis=1,
        )
        logger.info("Finished extracting Equipment Base Type.")
        parsed_counts = processed_df["EQUIPMENT_BASE_TYPE"].value_counts()
        logger.info(f"Equipment Base Type parsing results:\n{parsed_counts}")
    else:
        logger.warning(
            "Missing EQUIPMENT_NAME or LINE_NAME. Cannot extract equipment base type."
        )
        if "EQUIPMENT_BASE_TYPE" not in processed_df.columns:
            processed_df["EQUIPMENT_BASE_TYPE"] = "Unknown"

    # --- Final Checks ---
    # Check if key columns for mapping exist
    required_cols = ["AE_MODEL_CATEGORY", "PLANT", "LINE_NAME", "EQUIPMENT_NAME"]
    missing_req = [
        col
        for col in required_cols
        if col not in processed_df.columns or processed_df[col].isnull().all()
    ]
    if missing_req:
        logger.error(
            f"CRITICAL: Missing required columns or columns entirely null after preprocessing: {missing_req}. Mapping will likely fail."
        )
        # Consider raising an error here depending on desired robustness
        # raise ValueError(f"Missing critical data columns for ontology mapping: {missing_req}")

    logger.info("Preprocessing finished.")
    return processed_df


# --- State Mapping Logic (REVISED) ---

# Map AE_MODEL_CATEGORY values (lowercase, stripped) to Ontology Classes
# Assumes AE_MODEL_CATEGORY contains values like 'Runtime', 'Unplanned', 'Waiting', etc.
AE_CATEGORY_CLASS_MAP = {
    "runtime": onto.RuntimeState,
    "unplanned": onto.UnplannedState,
    "waiting": onto.WaitingState,
    "plant decision": onto.PlantDecisionState,
    "business external": onto.BusinessExternalState,
    # Add mappings for None or specific codes if they represent unknown/other
    # If AE_MODEL_CATEGORY can be None/NaN, map to UnknownAEState
}

# REMOVED: STATE_CLASS_MAP, REASON_CLASS_MAP
# REMOVED: get_state_reason_instance (replaced by get_ae_state_instance used internally)


def map_row_to_ontology(
    row_data: Dict[str, Any],
    # sequence overrides only affect sequenceOrder value now
    equipment_sequence_overrides: Dict[str, Dict[str, Dict[str, Any]]],
    equipment_type_sequence_order: Dict[str, int],
) -> None:
    """Map a single preprocessed data row to ontology instances."""

    record_id_str = row_data.get("record_id_str", "UNKNOWN_RECORD")
    # logger.debug(f"--- Mapping row {record_id_str} ---") # Can be noisy

    try:
        # --- 1. Identify/Create Core Assets (Plant, Line, Equipment) ---
        plant_id = row_data.get("PLANT")
        line_name = row_data.get("LINE_NAME")
        equipment_id = row_data.get("EQUIPMENT_ID")  # Actual unique asset ID
        equipment_name = row_data.get("EQUIPMENT_NAME")  # Name like LINE_CasePacker
        equipment_base_type = row_data.get("EQUIPMENT_BASE_TYPE")  # Parsed: CasePacker
        row_level = row_data.get("EQUIPMENT_TYPE")  # Indicates 'Line' or 'Equipment'

        if not plant_id or not line_name or not equipment_name:
            logger.warning(
                f"Row {record_id_str}: Missing critical identifiers (Plant, LineName, EquipName). Skipping."
            )
            return

        # --- Create Hierarchy (Plant, Country, StratLoc, FF, Area, Line, Equip) ---
        # (Using get_or_create_instance helper)

        plant = get_or_create_instance(
            onto.Plant,
            f"Plant_{plant_id}",
            {
                "plantId": plant_id,
                "plantDescription": row_data.get("PLANT_DESCRIPTION"),
                "latitude": row_data.get("PLANT_LATITUDE"),
                "longitude": row_data.get("PLANT_LONGITUDE"),
            },
        )

        country_code = row_data.get("PLANT_COUNTRY")
        if country_code:
            country = get_or_create_instance(
                onto.Country,
                f"Country_{country_code}",
                {
                    "countryCode": country_code,
                    "countryName": row_data.get("PLANT_COUNTRY_DESCRIPTION"),
                },
            )
            plant.locatedInCountry = country  # Functional

        strat_loc_code = row_data.get("PLANT_STRATEGIC_LOCATION")
        if strat_loc_code:
            # Assuming name property exists or use code as name
            strat_loc = get_or_create_instance(
                onto.StrategicLocation,
                f"StratLoc_{strat_loc_code}",
                {
                    "strategicLocationName": row_data.get(
                        "PLANT_STRATEGIC_LOCATION_DESCRIPTION", strat_loc_code
                    )
                },
            )
            plant.hasStrategicLocation = strat_loc  # Functional

        focus_factory_name = row_data.get("GH_FOCUSFACTORY")
        focus_factory = None
        if focus_factory_name:
            focus_factory = get_or_create_instance(
                onto.FocusFactory,
                f"FocusFactory_{focus_factory_name}",
                {
                    "focusFactoryName": focus_factory_name,
                    "locatedInPlant": plant,  # Functional inverse link
                },
            )
            # Link Plant -> FF (Non-functional) - CORRECTED APPEND LOGIC
            current_ff_on_plant = list(getattr(plant, "hasFocusFactory", []))
            if focus_factory not in current_ff_on_plant:
                current_ff_on_plant.append(focus_factory)
                plant.hasFocusFactory = current_ff_on_plant  # Assign updated list

        physical_area_name = row_data.get("PHYSICAL_AREA")
        physical_area = None
        if physical_area_name:
            area_props = {"areaName": physical_area_name}
            if focus_factory:
                area_props["partOfFocusFactory"] = focus_factory  # Functional link
            # else link area directly to plant?
            # area_props["locatedInPlant"] = plant # Example if needed
            physical_area = get_or_create_instance(
                onto.PhysicalArea, f"Area_{physical_area_name}", area_props
            )
            # Link FF -> Area (Non-functional) - CORRECTED APPEND LOGIC
            if focus_factory:  # Ensure focus_factory exists
                current_area_on_ff = list(getattr(focus_factory, "ffHasArea", []))
                if physical_area not in current_area_on_ff:
                    current_area_on_ff.append(physical_area)
                    focus_factory.ffHasArea = current_area_on_ff  # Assign updated list

        line = get_or_create_instance(
            onto.Line,
            f"Line_{line_name}",
            {
                "lineName": line_name,
                "locatedInPlant": plant,  # Functional
                "partOfFocusFactory": focus_factory,  # Functional (None if no FF)
                "locatedInArea": physical_area,  # Functional (None if no Area)
            },
        )
        # Add inverse links from Area/FF to Line (Non-functional) - CORRECTED APPEND LOGIC
        if physical_area:
            current_line_on_area = list(getattr(physical_area, "areaHasLine", []))
            if line not in current_line_on_area:
                current_line_on_area.append(line)
                physical_area.areaHasLine = current_line_on_area  # Assign updated list
        if focus_factory:
            current_line_on_ff = list(getattr(focus_factory, "ffHasLine", []))
            if line not in current_line_on_ff:
                current_line_on_ff.append(line)
                focus_factory.ffHasLine = current_line_on_ff  # Assign updated list

        # Equipment instance ID logic (handle potential float IDs)
        equip_instance_id_base = equipment_id if equipment_id else equipment_name
        if not equip_instance_id_base:
            logger.warning(
                f"Row {record_id_str}: Cannot identify equipment (missing ID and Name). Skipping."
            )
            return
        if (
            isinstance(equip_instance_id_base, float)
            and equip_instance_id_base.is_integer()
        ):
            equip_instance_id_base = str(int(equip_instance_id_base))
        elif not isinstance(equip_instance_id_base, str):
            equip_instance_id_base = str(equip_instance_id_base)

        equip_instance_id = f"Equipment_{equip_instance_id_base}"

        equipment = get_or_create_instance(
            onto.Equipment,
            equip_instance_id,
            {
                "equipmentId": equipment_id,
                "equipmentName": equipment_name,
                "equipmentBaseType": (
                    equipment_base_type if equipment_base_type != "Unknown" else None
                ),
                "isPartOfLine": line,  # Functional link
                "locatedInArea": physical_area,  # Functional link (redundant via line?)
                "partOfFocusFactory": focus_factory,  # Functional link (redundant via line?)
                "equipmentModel": row_data.get("EQUIPMENT_MODEL"),
            },
        )
        # Add inverse links from Line/Area/FF to Equipment (Non-functional) - CORRECTED APPEND LOGIC
        current_equip_on_line = list(getattr(line, "hasEquipment", []))
        if equipment not in current_equip_on_line:
            current_equip_on_line.append(equipment)
            line.hasEquipment = current_equip_on_line  # Assign updated list

        if physical_area:
            current_equip_on_area = list(getattr(physical_area, "areaHasEquipment", []))
            if equipment not in current_equip_on_area:
                current_equip_on_area.append(equipment)
                physical_area.areaHasEquipment = (
                    current_equip_on_area  # Assign updated list
                )

        if focus_factory:
            current_equip_on_ff = list(getattr(focus_factory, "ffHasEquipment", []))
            if equipment not in current_equip_on_ff:
                current_equip_on_ff.append(equipment)
                focus_factory.ffHasEquipment = (
                    current_equip_on_ff  # Assign updated list
                )

        # Assign sequence order (considers overrides)
        is_line_level_row = (row_level == "Line") or (equipment_name == line_name)
        if (
            not is_line_level_row
            and equipment_base_type
            and equipment_base_type != "Unknown"
        ):
            order = equipment_type_sequence_order.get(equipment_base_type)
            if (
                line_name in equipment_sequence_overrides
                and equipment_base_type in equipment_sequence_overrides[line_name]
            ):
                override_order = equipment_sequence_overrides[line_name][
                    equipment_base_type
                ].get("order")
                if override_order is not None:
                    order = int(override_order)  # Ensure integer

            if order is not None:
                equipment.sequenceOrder = order  # Functional

        # --- REMOVED: Premature sequence linking block ---

        # --- 2. Create EventRecord ---
        event_record_id = f"Event_{equip_instance_id_base}_{record_id_str}"  # Unique ID

        event_props = {
            "occursAtPlant": plant,
            "occursOnLine": line,
            "involvesEquipment": equipment,
            "rampUpFlag": row_data.get("RAMPUP_FLAG"),
            # AE Model Time Components
            "reportedDurationMinutes": row_data.get("TOTAL_TIME"),
            "businessExternalTimeMinutes": row_data.get("BUSINESS_EXTERNAL_TIME"),
            "plantAvailableTimeMinutes": row_data.get("PLANT_AVAILABLE_TIME"),
            "effectiveRuntimeMinutes": row_data.get("EFFECTIVE_RUNTIME"),
            "plantDecisionTimeMinutes": row_data.get("PLANT_DECISION_TIME"),
            "productionAvailableTimeMinutes": row_data.get("PRODUCTION_AVAILABLE_TIME"),
            "downtimeMinutes": row_data.get(
                "DOWNTIME"
            ),  # Maps to UnplannedState total?
            "runTimeMinutes": row_data.get("RUN_TIME"),  # Maps to RuntimeState total?
            "notEnteredTimeMinutes": row_data.get(
                "NOT_ENTERED"
            ),  # Included in Unplanned?
            "waitingTimeMinutes": row_data.get(
                "WAITING_TIME"
            ),  # Maps to WaitingState total?
            "plantExperimentationTimeMinutes": row_data.get("PLANT_EXPERIMENTATION"),
            "allMaintenanceTimeMinutes": row_data.get("ALL_MAINTENANCE"),
            "autonomousMaintenanceTimeMinutes": row_data.get("AUTONOMOUS_MAINTENANCE"),
            "plannedMaintenanceTimeMinutes": row_data.get("PLANNED_MAINTENANCE"),
            "changeoverDurationMinutes": row_data.get("CHANGEOVER_DURATION"),
            "cleaningSanitizationTimeMinutes": row_data.get(
                "CLEANING_AND_SANITIZATION"
            ),
            "lunchBreakTimeMinutes": row_data.get("LUNCH_AND_BREAK"),
            "meetingTrainingTimeMinutes": row_data.get("MEETING_AND_TRAINING"),
            "noDemandTimeMinutes": row_data.get("NO_DEMAND"),
            # Production Quantities
            "goodProductionQty": row_data.get("GOOD_PRODUCTION_QTY"),
            "rejectProductionQty": row_data.get("REJECT_PRODUCTION_QTY"),
            # Raw Descriptions (NEW)
            "rawStateDescription": clean_string_value(
                row_data.get("UTIL_STATE_DESCRIPTION")
            ),
            "rawReasonDescription": clean_string_value(
                row_data.get("UTIL_REASON_DESCRIPTION")
            ),
        }
        event_record = get_or_create_instance(
            onto.EventRecord, event_record_id, event_props
        )

        # --- 3. Add TimeInterval ---
        start_time = parse_datetime_with_tz(row_data.get("JOB_START_TIME_LOC"))
        end_time = parse_datetime_with_tz(row_data.get("JOB_END_TIME_LOC"))

        if start_time and end_time:
            interval_id = f"Interval_{event_record_id}"
            interval = get_or_create_instance(
                onto.TimeInterval,
                interval_id,
                {"startTime": start_time, "endTime": end_time},
            )
            event_record.occursDuring = interval  # Functional

            try:
                duration_seconds = (end_time - start_time).total_seconds()
                if duration_seconds >= 0:
                    event_record.calculatedDurationSeconds = (
                        duration_seconds  # Functional
                    )
                else:
                    logger.warning(
                        f"Row {record_id_str}: Negative duration calculated ({duration_seconds}s). End time may be before start time."
                    )
            except Exception as dur_err:
                logger.warning(
                    f"Row {record_id_str}: Could not calculate duration: {dur_err}"
                )
        else:
            logger.warning(
                f"Row {record_id_str}: Missing or invalid JOB_START/END_TIME_LOC. Cannot create TimeInterval or calculate duration."
            )

        # --- 4. Add Utilization State (based on AE_MODEL_CATEGORY) ---
        ae_category_raw = row_data.get("AE_MODEL_CATEGORY")
        state_instance = None
        TargetStateClass = None

        if ae_category_raw:
            ae_category_clean = str(ae_category_raw).strip().lower()
            TargetStateClass = AE_CATEGORY_CLASS_MAP.get(ae_category_clean)

            if TargetStateClass:
                # Get the shared instance for this AE state (e.g., UnplannedState_Unplanned)
                state_instance = get_ae_state_instance(
                    ae_category_raw, TargetStateClass
                )  # Use original name for helper ID
            else:
                logger.warning(
                    f"Row {record_id_str}: Unknown AE_MODEL_CATEGORY '{ae_category_raw}'. Mapping to UnknownAEState."
                )
                TargetStateClass = onto.UnknownAEState
                state_instance = get_ae_state_instance(
                    "Unknown", TargetStateClass
                )  # Shared Unknown instance
        else:
            logger.warning(
                f"Row {record_id_str}: Missing AE_MODEL_CATEGORY. Mapping to UnknownAEState."
            )
            TargetStateClass = onto.UnknownAEState
            state_instance = get_ae_state_instance(
                "Unknown", TargetStateClass
            )  # Shared Unknown instance

        if state_instance:
            event_record.hasState = state_instance  # Functional

        # --- REMOVED: Reason mapping logic ---
        # Raw reason text is now captured directly in event_props using rawReasonDescription

        # --- 5. Add Process Context (Material, Order, Shift, Crew) ---
        material_id = row_data.get("MATERIAL_ID")
        if material_id:
            material = get_or_create_instance(
                onto.Material,
                f"Material_{material_id}",
                {
                    "materialId": material_id,
                    "materialDescription": row_data.get(
                        "SHORT_MATERIAL_ID"
                    ),  # Or MATERIAL_DESC
                    "materialUOM": row_data.get("MATERIAL_UOM"),
                },
            )
            event_record.processesMaterial = [material]  # Non-functional append unique

        order_id_raw = row_data.get("PRODUCTION_ORDER_ID")
        if order_id_raw:
            order_id = (
                str(int(order_id_raw))
                if isinstance(order_id_raw, float) and order_id_raw.is_integer()
                else str(order_id_raw)
            )
            order = get_or_create_instance(
                onto.ProductionOrder,
                f"Order_{order_id}",
                {
                    "orderId": order_id,
                    "orderDescription": row_data.get("PRODUCTION_ORDER_DESC"),
                    "orderRate": row_data.get("PRODUCTION_ORDER_RATE"),
                    "orderRateUOM": row_data.get("PRODUCTION_ORDER_UOM"),
                },
            )
            event_record.relatesToOrder = [order]  # Non-functional append unique

        shift_name = row_data.get("SHIFT_NAME")
        if shift_name:
            shift = get_or_create_instance(
                onto.Shift, f"Shift_{shift_name}", {"shiftName": shift_name}
            )
            event_record.duringShift = shift  # Functional

        crew_id = row_data.get("CREW_ID")
        if crew_id:
            crew = get_or_create_instance(
                onto.Crew, f"Crew_{crew_id}", {"crewId": crew_id}
            )
            event_record.operatedByCrew = crew  # Functional

        # logger.debug(f"--- Successfully mapped row {record_id_str} ---")

    except Exception as e:
        logger.error(
            f"Error mapping row {record_id_str} to ontology: {e}", exc_info=True
        )
        raise  # Re-raise to potentially stop execution or be caught higher up


# =============================================================================
# Query Functions (Examples - REVISED for new states/properties)
# =============================================================================


def find_equipment_by_type(equipment_type: str) -> List[Equipment]:
    """Find equipment instances by their base type."""
    # No change needed here
    if not equipment_type:
        logger.warning("Cannot search for equipment with None/empty type")
        return []
    matching_equipment = list(
        onto.search(type=onto.Equipment, equipmentBaseType=equipment_type)
    )
    logger.debug(
        f"Found {len(matching_equipment)} instances of type '{equipment_type}'"
    )
    return matching_equipment


def find_downstream_equipment(equipment: Equipment) -> List[Equipment]:
    """Find equipment immediately downstream of the given equipment."""
    if not equipment:
        return []
    # --- ADD DEBUGGING ---
    downstream_prop_value = getattr(equipment, "isImmediatelyUpstreamOf", None)
    logger.debug(
        f"Querying downstream for {equipment.name}: Found isImmediatelyUpstreamOf = {downstream_prop_value}"
    )
    # --- END DEBUGGING ---
    downstream = list(downstream_prop_value) if downstream_prop_value else []
    logger.debug(
        f"Returning {len(downstream)} downstream equipment for {equipment.name}"
    )
    return downstream


def find_upstream_equipment(equipment: Equipment) -> List[Equipment]:
    """Find equipment immediately upstream of the given equipment."""
    if not equipment:
        return []
    # --- ADD DEBUGGING ---
    upstream_prop_value = getattr(equipment, "isImmediatelyDownstreamOf", None)
    logger.debug(
        f"Querying upstream for {equipment.name}: Found isImmediatelyDownstreamOf = {upstream_prop_value}"
    )
    # --- END DEBUGGING ---
    upstream = list(upstream_prop_value) if upstream_prop_value else []
    logger.debug(f"Returning {len(upstream)} upstream equipment for {equipment.name}")
    return upstream


# Example query adjusted for new structure
def find_longest_unplanned_events(
    equipment: Equipment, count: int = 1
) -> List[Dict[str, Any]]:
    """Find the longest event(s) for a piece of equipment classified as UnplannedState."""
    results = []
    if not equipment or not isinstance(equipment, onto.Equipment):
        logger.warning("Invalid equipment provided.")
        return results

    logger.info(f"Searching for longest UnplannedState events for {equipment.name}...")

    # Get the shared instance for UnplannedState
    try:
        # Assumes AE category name is 'Unplanned'
        unplanned_state_instance = get_ae_state_instance(
            "Unplanned", onto.UnplannedState
        )
    except Exception as e:
        logger.error(f"Could not get UnplannedState instance: {e}")
        return results  # Cannot proceed without the state instance

    # Search for events involving the equipment and having the UnplannedState
    unplanned_events = list(
        onto.search(
            type=onto.EventRecord,
            involvesEquipment=equipment,
            hasState=unplanned_state_instance,
        )
    )

    if not unplanned_events:
        logger.info(f"No UnplannedState events found for {equipment.name}.")
        return results

    # Sort by calculated duration (or reported duration as fallback)
    def get_duration(event):
        if (
            hasattr(event, "calculatedDurationSeconds")
            and event.calculatedDurationSeconds is not None
        ):
            return event.calculatedDurationSeconds
        elif (
            hasattr(event, "reportedDurationMinutes")
            and event.reportedDurationMinutes is not None
        ):
            # Convert fallback to seconds for consistent sorting
            return event.reportedDurationMinutes * 60
        return 0  # Treat events with no duration as shortest

    unplanned_events.sort(key=get_duration, reverse=True)

    # Get top N events and their reasons
    top_events = unplanned_events[:count]
    for event in top_events:
        results.append(
            {
                "event_iri": event.iri,
                "duration_seconds": get_duration(event),
                "raw_state_desc": getattr(event, "rawStateDescription", "N/A"),
                "raw_reason_desc": getattr(event, "rawReasonDescription", "N/A"),
                "start_time": (
                    getattr(event.occursDuring, "startTime", None)
                    if event.occursDuring
                    else None
                ),
                "end_time": (
                    getattr(event.occursDuring, "endTime", None)
                    if event.occursDuring
                    else None
                ),
            }
        )

    logger.info(
        f"Found {len(results)} longest UnplannedState event(s) for {equipment.name}."
    )
    return results


# =============================================================================
# Post-Processing: Link Equipment by Sequence (Unchanged)
# =============================================================================


def link_equipment_by_sequence(ontology: owl.Ontology):
    """
    Iterates through all lines and links equipment instances based on their
    sequenceOrder property (n is upstream of n+1). Relies on Owlready2 for inverse.
    """
    logger.info("Starting post-processing step: Linking equipment by sequence order...")
    link_count = 0
    processed_lines = 0

    all_lines = list(ontology.search(type=onto.Line))
    logger.info(f"Found {len(all_lines)} lines to process for equipment sequencing.")

    for line in all_lines:
        processed_lines += 1
        logger.debug(f"--- Processing line: {line.name} ---")

        equipment_on_line_with_order = []
        equip_list = list(getattr(line, "hasEquipment", []))
        logger.debug(
            f"Line {line.name}: Found {len(equip_list)} equipment instances total."
        )

        # Collect equipment that has a valid sequenceOrder
        for equip in equip_list:
            seq_order_val = getattr(equip, "sequenceOrder", None)
            if seq_order_val is not None:
                try:
                    seq_order_int = int(seq_order_val)
                    equipment_on_line_with_order.append((seq_order_int, equip))
                    logger.debug(
                        f"  Equipment {equip.name} (Type: {getattr(equip,'equipmentBaseType','N/A')}) has sequenceOrder: {seq_order_int}"
                    )
                except (ValueError, TypeError):
                    logger.warning(
                        f"  Equipment {equip.name} on line {line.name} has non-integer sequenceOrder '{seq_order_val}'. Skipping for linking."
                    )

        if len(equipment_on_line_with_order) < 2:
            logger.debug(
                f"Line {line.name}: Found only {len(equipment_on_line_with_order)} equipment with sequenceOrder. Need at least 2 to link. Skipping line."
            )
            continue

        # Sort equipment by sequenceOrder
        sorted_equipment_pairs = sorted(
            equipment_on_line_with_order, key=lambda item: item[0]
        )
        sorted_equipment = [pair[1] for pair in sorted_equipment_pairs]
        sorted_orders = [pair[0] for pair in sorted_equipment_pairs]
        logger.debug(
            f"Line {line.name}: Sorted equipment with order: {[f'{e.name}({o})' for e, o in zip(sorted_equipment, sorted_orders)]}"
        )

        # Link adjacent sequences (n to n+1)
        line_links_made = 0
        for i in range(len(sorted_equipment) - 1):
            upstream_eq = sorted_equipment[i]
            downstream_eq = sorted_equipment[i + 1]
            upstream_order = sorted_orders[i]
            downstream_order = sorted_orders[i+1]

            logger.debug(f"  Checking pair: {upstream_eq.name}({upstream_order}) -> {downstream_eq.name}({downstream_order})")

            # Check if sequence order is consecutive
            if downstream_order == upstream_order + 1:
                logger.debug(f"    Orders are consecutive. Attempting to link.")
                pair_linked = False

                # --- ONLY UPDATE ONE SIDE using simple assignment ---
                current_downstream = list(getattr(upstream_eq, "isImmediatelyUpstreamOf", []))
                if downstream_eq not in current_downstream:
                    current_downstream.append(downstream_eq)
                    # Assign the updated list back
                    upstream_eq.isImmediatelyUpstreamOf = current_downstream
                    logger.info(f"    LINKED: {upstream_eq.name} --isImmediatelyUpstreamOf--> {downstream_eq.name} (Owlready2 should handle inverse)")
                    pair_linked = True
                else:
                    logger.debug(f"    Link {upstream_eq.name} -> {downstream_eq.name} already exists.")

                if pair_linked:
                    link_count += 1
                    line_links_made += 1
                    logger.debug(
                        f"    Link {upstream_eq.name} -> {downstream_eq.name} already exists."
                    )

                # --- REMOVED Manual update of isImmediatelyDownstreamOf ---

                if pair_linked:
                    link_count += 1
                    line_links_made += 1

            elif downstream_order > upstream_order + 1:
                logger.debug(
                    f"    Gap in sequence order detected between {upstream_eq.name} ({upstream_order}) and {downstream_eq.name} ({downstream_order}). No direct link created."
                )
            elif downstream_order <= upstream_order:
                logger.warning(
                    f"    Non-increasing or duplicate sequence order detected between {upstream_eq.name} ({upstream_order}) and {downstream_eq.name} ({downstream_order}). Check configuration/data. No link created."
                )

        logger.debug(
            f"--- Finished processing line: {line.name}. Links created on this line: {line_links_made} ---"
        )

    logger.info(
        f"Finished linking equipment by sequence. Created/verified approximately {link_count} link pairs."
    )


# =============================================================================
# Main Execution Block (Adjusted for New Ontology/File Names)
# =============================================================================


def parse_arguments():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Manufacturing Ontology Builder")
    parser.add_argument("--input", "-i", required=True, help="Input CSV file path")
    settings = get_ontology_settings()
    default_output = settings.get("default_output_file")  # Get updated default
    parser.add_argument(
        "--output", "-o", help="Output OWL file path", default=default_output
    )
    parser.add_argument(
        "--log-level",
        "-l",
        choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
        default="INFO",
        help="Logging level",
    )
    return parser.parse_args()


def main():
    args = parse_arguments()
    logging.getLogger().setLevel(getattr(logging, args.log_level.upper()))

    input_path = Path(args.input)
    if not input_path.is_file():  # More specific check
        logger.critical(f"Input file not found or is not a file: {input_path}")
        return 1

    try:
        # Load and preprocess
        df_raw = load_csv_data(args.input)
        processed_df = preprocess_manufacturing_data(df_raw)

        # Check if preprocessing resulted in empty dataframe
        if processed_df.empty:
            logger.critical(
                "Preprocessing resulted in an empty DataFrame. Cannot proceed."
            )
            return 1

        # Check again for AE_MODEL_CATEGORY after preprocessing
        if (
            "AE_MODEL_CATEGORY" not in processed_df.columns
            or processed_df["AE_MODEL_CATEGORY"].isnull().all()
        ):
            logger.critical(
                "CRITICAL: AE_MODEL_CATEGORY column is missing or entirely null after preprocessing. State mapping will fail."
            )
            return 1  # Stop execution

        # Get configuration
        equipment_type_seq = get_equipment_type_sequence_order()
        equipment_seq_overrides = get_equipment_sequence_overrides()

        # Use ontology context for mapping AND linking operations
        logger.info("Entering main ontology context for population and linking...")
        with onto:
            # --- Ontology Population ---
            stats = {"total_rows": len(processed_df), "processed_rows": 0, "error_rows": 0}
            logger.info(f"Populating ontology from {stats['total_rows']} processed rows...")
            row_count = len(processed_df)
            data_rows = processed_df.to_dict("records")

            for i, row_data in enumerate(data_rows):
                try:
                    map_row_to_ontology(
                        row_data, equipment_seq_overrides, equipment_type_seq
                    )
                    stats["processed_rows"] += 1
                except Exception as map_err:
                    stats["error_rows"] += 1
                # Log progress
                if (i + 1) % 5000 == 0 or (i + 1) == row_count:
                    logger.info(
                        f"Mapped {i + 1}/{row_count} rows ({(i + 1) / row_count:.1%})"
                    )

            logger.info(f"Mapped {stats['processed_rows']} rows successfully.")

            # Check for errors before proceeding with linking
            if stats["error_rows"] > 0:
                logger.warning(f"{stats['error_rows']} errors occurred during row mapping. Ontology may be incomplete.")

            # Post-process: Link equipment by sequence order (NOW INSIDE with onto)
            logger.info("Running post-processing: Linking equipment sequences...")
            # Ensure link_equipment_by_sequence uses the version that modifies only one side
            link_equipment_by_sequence(onto)

        logger.info("Exited main ontology context.")

        # Save ontology
        output_path = args.output
        output_format = settings.get("format", "rdfxml")
        logger.info(f"Saving ontology to {output_path} in format {output_format}")
        try:
            onto.save(file=output_path, format=output_format)
            logger.info("Ontology saved successfully.")
        except Exception as save_err:
            logger.critical(f"Failed to save ontology: {save_err}", exc_info=True)
            return 1

        # Run example queries
        logger.info("--- Running Example Queries ---")
        example_equip_type = "CasePacker"
        case_packers = find_equipment_by_type(example_equip_type)
        logger.info(
            f"Found {len(case_packers)} {example_equip_type} equipment instances."
        )

        if case_packers:
            # Find one associated with a line for more interesting queries
            cp1 = None
            for cp in case_packers:
                if getattr(cp, "isPartOfLine", None):
                    cp1 = cp
                    break

            if cp1:
                logger.info(f"Querying around example {example_equip_type}: {cp1.name}")
                upstream = find_upstream_equipment(cp1)
                downstream = find_downstream_equipment(cp1)
                logger.info(f"  Upstream: {[e.name for e in upstream]}")
                logger.info(f"  Downstream: {[e.name for e in downstream]}")

                # Example: Find longest unplanned event for this CasePacker
                longest_unplanned = find_longest_unplanned_events(cp1, count=1)
                if longest_unplanned:
                    event_info = longest_unplanned[0]
                    logger.info(
                        f"  Longest Unplanned Event (~{event_info['duration_seconds']:.0f}s):"
                    )
                    logger.info(f"    State Desc (raw): {event_info['raw_state_desc']}")
                    logger.info(
                        f"    Reason Desc (raw): {event_info['raw_reason_desc']}"
                    )
                else:
                    logger.info(f"  No UnplannedState events found for {cp1.name}.")
            else:
                logger.info(
                    f"Could not find a {example_equip_type} associated with a line for detailed queries."
                )

        # --- Final Statistics ---
        logger.info("--- Processing Summary ---")
        logger.info(f"Input rows processed: {stats['total_rows']}")
        # logger.info(f"Rows successfully mapped: {stats['processed_rows']}") # Less useful if errors are counted
        if stats["error_rows"] > 0:
            logger.warning(f"Rows with errors during mapping: {stats['error_rows']}")
        else:
            logger.info("No errors detected during row mapping.")
        logger.info("---------------------------")

        logger.info("Processing completed.")
        return 0

    except Exception as e:
        logger.critical(
            f"A critical error occurred in the main process: {e}", exc_info=True
        )
        return 1


if __name__ == "__main__":
    sys.exit(main())

==============================
DEBUG LOG SAMPLE
==============================

2025-03-28 11:01:46,578 - __main__ - DEBUG - --- Processing line: Line_FIPCO003 ---
2025-03-28 11:01:46,578 - __main__ - DEBUG - Line Line_FIPCO003: Found 6 equipment instances total.
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_171_0 (Type: Cartoner) has sequenceOrder: 2
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_172_0 (Type: CasePacker) has sequenceOrder: 5
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_170_0 (Type: Bundler) has sequenceOrder: 3
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_173_0 (Type: Filler) has sequenceOrder: 1
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_174_0 (Type: Palletizer) has sequenceOrder: 7
2025-03-28 11:01:46,578 - __main__ - DEBUG - Line Line_FIPCO003: Sorted equipment with order: ['Equipment_173_0(1)', 'Equipment_171_0(2)', 'Equipment_170_0(3)', 'Equipment_172_0(5)', 'Equipment_174_0(7)']
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Checking pair: Equipment_173_0(1) -> Equipment_171_0(2)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Orders are consecutive. Attempting to link.
2025-03-28 11:01:46,578 - __main__ - INFO -     LINKED: Equipment_173_0 --isImmediatelyUpstreamOf--> Equipment_171_0 (Owlready2 should handle inverse)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Link Equipment_173_0 -> Equipment_171_0 already exists.
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Checking pair: Equipment_171_0(2) -> Equipment_170_0(3)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Orders are consecutive. Attempting to link.
2025-03-28 11:01:46,578 - __main__ - INFO -     LINKED: Equipment_171_0 --isImmediatelyUpstreamOf--> Equipment_170_0 (Owlready2 should handle inverse)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Link Equipment_171_0 -> Equipment_170_0 already exists.
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Checking pair: Equipment_170_0(3) -> Equipment_172_0(5)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Gap in sequence order detected between Equipment_170_0 (3) and Equipment_172_0 (5). No direct link created.
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Checking pair: Equipment_172_0(5) -> Equipment_174_0(7)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Gap in sequence order detected between Equipment_172_0 (5) and Equipment_174_0 (7). No direct link created.
2025-03-28 11:01:46,578 - __main__ - DEBUG - --- Finished processing line: Line_FIPCO003. Links created on this line: 4 ---
2025-03-28 11:01:46,578 - __main__ - DEBUG - --- Processing line: Line_FIPCO00H ---
2025-03-28 11:01:46,578 - __main__ - DEBUG - Line Line_FIPCO00H: Found 6 equipment instances total.
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_200_0 (Type: CasePacker) has sequenceOrder: 5
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_201_0 (Type: Filler) has sequenceOrder: 1
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_199_0 (Type: Cartoner) has sequenceOrder: 2
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_198_0 (Type: Bundler) has sequenceOrder: 3
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_202_0 (Type: Palletizer) has sequenceOrder: 7
2025-03-28 11:01:46,578 - __main__ - DEBUG - Line Line_FIPCO00H: Sorted equipment with order: ['Equipment_201_0(1)', 'Equipment_199_0(2)', 'Equipment_198_0(3)', 'Equipment_200_0(5)', 'Equipment_202_0(7)']
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Checking pair: Equipment_201_0(1) -> Equipment_199_0(2)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Orders are consecutive. Attempting to link.
2025-03-28 11:01:46,578 - __main__ - INFO -     LINKED: Equipment_201_0 --isImmediatelyUpstreamOf--> Equipment_199_0 (Owlready2 should handle inverse)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Link Equipment_201_0 -> Equipment_199_0 already exists.
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Checking pair: Equipment_199_0(2) -> Equipment_198_0(3)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Orders are consecutive. Attempting to link.
2025-03-28 11:01:46,578 - __main__ - INFO -     LINKED: Equipment_199_0 --isImmediatelyUpstreamOf--> Equipment_198_0 (Owlready2 should handle inverse)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Link Equipment_199_0 -> Equipment_198_0 already exists.
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Checking pair: Equipment_198_0(3) -> Equipment_200_0(5)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Gap in sequence order detected between Equipment_198_0 (3) and Equipment_200_0 (5). No direct link created.
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Checking pair: Equipment_200_0(5) -> Equipment_202_0(7)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Gap in sequence order detected between Equipment_200_0 (5) and Equipment_202_0 (7). No direct link created.
2025-03-28 11:01:46,578 - __main__ - DEBUG - --- Finished processing line: Line_FIPCO00H. Links created on this line: 4 ---
2025-03-28 11:01:46,578 - __main__ - DEBUG - --- Processing line: Line_FIPCO00J ---
2025-03-28 11:01:46,578 - __main__ - DEBUG - Line Line_FIPCO00J: Found 5 equipment instances total.
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_769_0 (Type: Filler) has sequenceOrder: 1
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_767_0 (Type: Cartoner) has sequenceOrder: 2
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_768_0 (Type: CasePacker) has sequenceOrder: 5
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Equipment Equipment_766_0 (Type: Bundler) has sequenceOrder: 3
2025-03-28 11:01:46,578 - __main__ - DEBUG - Line Line_FIPCO00J: Sorted equipment with order: ['Equipment_769_0(1)', 'Equipment_767_0(2)', 'Equipment_766_0(3)', 'Equipment_768_0(5)']
2025-03-28 11:01:46,578 - __main__ - DEBUG -   Checking pair: Equipment_769_0(1) -> Equipment_767_0(2)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Orders are consecutive. Attempting to link.
2025-03-28 11:01:46,578 - __main__ - INFO -     LINKED: Equipment_769_0 --isImmediatelyUpstreamOf--> Equipment_767_0 (Owlready2 should handle inverse)
2025-03-28 11:01:46,578 - __main__ - DEBUG -     Link Equipment_769_0 -> Equipment_767_0 already exists.
2025-03-28 11:01:46,579 - __main__ - DEBUG -   Checking pair: Equipment_767_0(2) -> Equipment_766_0(3)
2025-03-28 11:01:46,579 - __main__ - DEBUG -     Orders are consecutive. Attempting to link.
2025-03-28 11:01:46,579 - __main__ - INFO -     LINKED: Equipment_767_0 --isImmediatelyUpstreamOf--> Equipment_766_0 (Owlready2 should handle inverse)
2025-03-28 11:01:46,579 - __main__ - DEBUG -     Link Equipment_767_0 -> Equipment_766_0 already exists.
2025-03-28 11:01:46,579 - __main__ - DEBUG -   Checking pair: Equipment_766_0(3) -> Equipment_768_0(5)
2025-03-28 11:01:46,579 - __main__ - DEBUG -     Gap in sequence order detected between Equipment_766_0 (3) and Equipment_768_0 (5). No direct link created.
2025-03-28 11:01:46,579 - __main__ - DEBUG - --- Finished processing line: Line_FIPCO00J. Links created on this line: 4 ---
2025-03-28 11:01:46,579 - __main__ - INFO - Finished linking equipment by sequence. Created/verified approximately 54 link pairs.
2025-03-28 11:01:46,579 - __main__ - INFO - Exited main ontology context.
2025-03-28 11:01:46,579 - __main__ - INFO - Saving ontology to mx.owl in format rdfxml
2025-03-28 11:01:46,908 - __main__ - INFO - Ontology saved successfully.
2025-03-28 11:01:46,909 - __main__ - INFO - --- Running Example Queries ---
2025-03-28 11:01:46,914 - __main__ - DEBUG - Found 13 instances of type 'CasePacker'
2025-03-28 11:01:46,914 - __main__ - INFO - Found 13 CasePacker equipment instances.
2025-03-28 11:01:46,914 - __main__ - INFO - Querying around example CasePacker: Equipment_193_0
2025-03-28 11:01:46,914 - __main__ - DEBUG - Querying upstream for Equipment_193_0: Found isImmediatelyDownstreamOf = []
2025-03-28 11:01:46,914 - __main__ - DEBUG - Returning 0 upstream equipment for Equipment_193_0
2025-03-28 11:01:46,914 - __main__ - DEBUG - Querying downstream for Equipment_193_0: Found isImmediatelyUpstreamOf = []
2025-03-28 11:01:46,914 - __main__ - DEBUG - Returning 0 downstream equipment for Equipment_193_0
2025-03-28 11:01:46,914 - __main__ - INFO -   Upstream: []
2025-03-28 11:01:46,914 - __main__ - INFO -   Downstream: []
2025-03-28 11:01:46,914 - __main__ - INFO - Searching for longest UnplannedState events for Equipment_193_0...
2025-03-28 11:01:46,921 - __main__ - INFO - Found 1 longest UnplannedState event(s) for Equipment_193_0.
2025-03-28 11:01:46,921 - __main__ - INFO -   Longest Unplanned Event (~59633s):
2025-03-28 11:01:46,921 - __main__ - INFO -     State Desc (raw): DOWNTIME
2025-03-28 11:01:46,921 - __main__ - INFO -     Reason Desc (raw): Ending order
2025-03-28 11:01:46,921 - __main__ - INFO - --- Processing Summary ---
2025-03-28 11:01:46,921 - __main__ - INFO - Input rows processed: 5450
2025-03-28 11:01:46,921 - __main__ - INFO - No errors detected during row mapping.
2025-03-28 11:01:46,921 - __main__ - INFO - ---------------------------
2025-03-28 11:01:46,921 - __main__ - INFO - Processing completed.

=======================
owlready2 documentation
=======================

================================================
File: doc/README.md
================================================
# General Information

This directory contains the source file for the docs.

# Dependencies

To ensure you have all dependencies for building the documentation, run the followin:
```
pip install sphinx
pip install sphinx-rtd-theme
```

# Build the Docs

From the project root (where `setup.py` lives) run the folloing:

```
sphinx-build -b html doc doc/html
```

For more information see <https://www.sphinx-doc.org/en/master/usage/quickstart.html>.



================================================
File: doc/annotations.rst
================================================
Annotations
===========

In Owlready2, annotations are accessed as attributes.
For Classes, notice that annotations are **not** inherited.


Adding an annotation
--------------------

For a given entity (a Class, a Property or an Individual), the following syntax can be used to add
annotations:

::
   
   >>> from owlready2 import *
   
   >>> onto = get_ontology("http://test.org/onto.owl")
   
   >>> with onto:
   ...     class Drug(Thing):
   ...         pass
   
   >>> Drug.comment = ["A first comment on the Drug class", "A second comment"]
   
   >>> Drug.comment.append("A third comment")

The following annotations are available by default: comment, isDefinedBy, label, seeAlso,
backwardCompatibleWith, deprecated, incompatibleWith, priorVersion, versionInfo.

Owlready2 also supports annotations on relation triples, using the AnnotatedRelation class as folows:

::

   >>> with onto:
   ...     class HealthProblem(Thing):
   ...         pass

   ...     class is_prescribed_for(Drug >> HealthProblem):
   ...         pass

   >>> acetaminophen = Drug("acetaminophen")
   >>> pain = HealthProblem("pain")
   >>> acetaminophen.is_prescribed_for.append(pain)
   
   >>> AnnotatedRelation(acetaminophen, is_prescribed_for, pain).comment = ["A comment on the acetaminophen-pain relation"]

The AnnotatedRelation class constructor takes three parameters, corresponding to a subject-predicate-object triple.
Then, you can use the dotted notation on the AnnotatedRelation object to access the various annotations
(e.g., .comment, .label, etc).

.. note::

   The following, old, syntax remains supported:

   ::

      >>> comment[acetaminophen, is_prescribed_for, pain] = ["A comment on the acetaminophen-pain relation"]
   

Special pseudo-properties are provided for annotating is-a relations (rdfs_subclassof and rdf_type),
domains (rdf_domain) and ranges (rdf_range).

::

   >>> AnnotatedRelation(Drug, rdfs_subclassof, Thing).comment = ["A comment on an is-a relation"]


Annotation values are usually lists of values. However, in many cases, a single value is used.
Owlready2 accepts to set an annotation property to a single value, for example:

::
   
   >>> acetaminophen.comment = "This comment replaces all existing comments on acetaminophen"


Querying annotations
--------------------

Annotation values can be obtained using the dot notation, as if they were attributes of the entity:

::
   
   >>> print(Drug.comment)
   ['A first comment on the Drug class', 'A second comment', 'A third comment']
   
   >>> print(AnnotatedRelation(acetaminophen, is_prescribed_for, pain).comment)
   ['A comment on the acetaminophen-pain relation']
   
   >>> print(AnnotatedRelation(Drug, rdfs_subclassof, Thing).comment)
   ['A comment on an is-a relation']

If you expect a single value, the .first() method of the list can be used. It returns the first value of
the list, or None if the list is empty.

::

   >>> acetaminophen.comment.first()
   'This comment replaces all existing comments on acetaminophen'


.. note::

   The following, old, syntax remains supported:

   ::

      >>> comment[acetaminophen, is_prescribed_for, pain]


Deleting annotations
--------------------

To delete an annotation, simply remove it from the list.

::
   
   >>> Drug.comment.remove("A second comment")


For removing **all** annotations of a given type:

::
   
   >>> Drug.comment = []


Nested annotated relations
--------------------------

AnnotatedRelation can be nested if desired, as follows:

::
   
   >>> annotr = AnnotatedRelation(acetaminophen, is_prescribed_for, pain)
   >>> nested = AnnotatedRelation(annotr, comment, "A comment on the acetaminophen-pain relation")
   >>> nested.comment = ["A comment on the previous comment"]

   
Custom rendering of entities
----------------------------

The set_render_func() global function can be used to specify how Owlready2 renders entities, i.e. how they are
converted to text when printing them. set_render_func() accepts a single param, a function which takes
one entity and return a string.

The 'label' annotation is commonly used for rendering entities.
The following example renders entities using their 'label' annotation, defaulting to their name:

::
   
   >>> def render_using_label(entity):
   ...     return entity.label.first() or entity.name
   
   >>> set_render_func(render_using_label)
   
   >>> Drug    # No label defined yet => use entity.name
   Drug
   
   >>> Drug.label = "The drug class"
   
   >>> Drug
   The drug class


The following example renders entities using their IRI:

::
   
   >>> def render_using_iri(entity):
   ...     return entity.iri
   
   >>> set_render_func(render_using_iri)

   >>> Drug
   http://test.org/onto.owl#Drug


Language-specific annotations
-----------------------------

To specify the language of textual annotations, the 'locstr' (localized string) type can be used:

::
   
   >>> Drug.comment = [ locstr("Un commentaire en Français", lang = "fr"),
   ...                  locstr("A comment in English", lang = "en") ]
   >>> Drug.comment[0]
   'Un commentaire en Français'
   >>> Drug.comment[0].lang
   'fr'
   
In addition, the list of values support language-specific sublists, available as '.<language code>'
(e.g. .fr, .en, .es, .de,...).
These sublists contain normal string (not locstr), and they can be modified.

::

   >>> Drug.comment.fr
   ['Un commentaire en Français']
   
   >>> Drug.comment.en
   ['A comment in English']
   
   >>> Drug.comment.en.first()
   'A comment in English'
   
   >>> Drug.comment.en.append("A second English comment")

The get_lang() method does the same (but is easier to call if the lang is in a variable):

::

   >>> lang = "fr"
   >>> Drug.comment.get_lang(lang)
   ['Un commentaire en Français']

The get_lang_first() method return only the first language-specific string found (it is equivalent to get_lang().first()):

::

   >>> lang = "fr"
   >>> Drug.comment.get_lang_first(lang)
   'Un commentaire en Français'

.. warning::
   
   Modifying the language-specific sublist will automatically update the list of values (and the quad store).
   However, the contrary is not true: modifying the list of values does **not** update language-specific sublists.
   

Plain literal
-------------

The plainliteral Python datatype can be used to create RDF plain literal (or to test whether a value is a plain literal):

::
   >>> Drug.comment.append(plainliteral("A plain literal comment."))



Creating new classes of annotation
----------------------------------

The AnnotationProperty class can be subclasses to create a new class of annotation:

::

   >>> with onto:
   ...     class my_annotation(AnnotationProperty):
   ...         pass

You can also create a subclass of an existing annotation class:

::
   
   >>> with onto:
   ...     class pharmaceutical_comment(comment):
   ...         pass
   
   >>> acetaminophen.pharmaceutical_comment = "A comment related to pharmacology of acetaminophen"


Full-text search (FTS)
----------------------

Full-text search (FTS) can optimize search in textual properties and annotations.
FTS uses Sqlite3 FTS5 implementation.

First, FTS needs to be enabled on the desired properties, by adding them to default_world.full_text_search_properties,
for example for label:

::

   >>> default_world.full_text_search_properties.append(label)

Then, FTS can be used in search as follows:

::

   >>> default_world.search(label = FTS("keyword1 keyword2*"))

Stars can be used as joker, but only at the END of the keyword.

When using full-text search, the _bm25 argument can be used to obtain the BM25 relevance score for each entity found:

::

   >>> default_world.search(label = FTS("keyword1 keyword2*"), _bm25 = True)



================================================
File: doc/class.rst
================================================
Classes and Individuals (Instances)
===================================

Creating a Class
----------------

A new Class can be created in an ontology by inheriting the owlready2.Thing class.

The ontology class attribute can be used to associate your class to the given ontology. If not specified,
this attribute is inherited from the parent class (in the example below, the parent class is Thing,
which is defined in the 'owl' ontology).

::

   >>> from owlready2 import *
   
   >>> onto = get_ontology("http://test.org/onto.owl")
   
   >>> class Drug(Thing):
   ...     namespace = onto

The namespace Class attribute is used to build the full IRI of the Class,
and can be an ontology or a namespace (see :doc:`namespace`).
The 'with' statement can also be used to provide the ontology (or namespace):

::

   >>> onto = get_ontology("http://test.org/onto.owl")
   
   >>> with onto:
   ...     class Drug(Thing):
   ...         pass


The .iri attribute of the Class can be used to obtain the full IRI of the class.

::

   >>> print(Drug.iri)
   http://test.org/onto.owl#Drug

.name and .iri attributes are writable and can be modified (this allows to change the IRI of an entity,
which is sometimes called "refactoring").

   
Creating and managing subclasses
--------------------------------

Subclasses can be created by inheriting an ontology class. Multiple inheritance is supported.

::

   >>> class DrugAssociation(Drug): # A drug associating several active principles
   ...     pass

Owlready2 provides the .is_a attribute for getting the list of superclasses (__bases__ can be used, but
with some limits described in :doc:`restriction`). It can also be modified for adding or removing superclasses.

::

   >>> print(DrugAssociation.is_a)
   [onto.Drug]

The .subclasses() method returns the list of direct subclasses of a class.

::

   >>> print(Drug.subclasses())
   [onto.DrugAssociation]

The .descendants() and .ancestors() Class methods return a set of the descendant and ancestor Classes
(including self, but excluding non-entity classes such as restrictions).

::

   >>> DrugAssociation.ancestors()
   {onto.DrugAssociation, owl.Thing, onto.Drug}


Creating classes dynamically
----------------------------

The 'types' Python module can be used to create classes and subclasses dynamically:

::

   >>> import types

   >>> with my_ontology:
   ...     NewClass = types.new_class("NewClassName", (SuperClass,))

   
Creating equivalent classes
---------------------------

The .equivalent_to Class attribute is a list of equivalent classes. It behaves like .is_a (programmatically).

To obtain all equivalent classes, including indirect ones (due to transitivity), use .INDIRECT_equivalent_to.


Creating Individuals
--------------------

Individuals are instances in ontologies. They are created as any other Python instances.
The first parameter is the name (or identifier) of the Individual;
it corresponds to the .name attribute in Owlready2.
If not given, the name if automatically generated from the Class name and a number.

::
   
   >>> my_drug = Drug("my_drug")
   >>> print(my_drug.name)
   my_drug
   >>> print(my_drug.iri)
   http://test.org/onto.owl#my_drug

   >>> unamed_drug = Drug()
   >>> print(unamed_drug.name)
   drug_1

Additional keyword parameters can be given when creating an Individual, and they will be associated to the
corresponding Properties (for more information on Properties, see :doc:`properties`).

::

   my_drug = Drug("my_drug2", namespace = onto, has_for_active_principle = [],...)


The Instances are immediately available in the ontology:

::

   >>> print(onto.drug_1)
   onto.drug_1
   
The .instances() class method can be used to iterate through all Instances of a Class (including its
subclasses). It returns a generator.

::

   >>> for i in Drug.instances(): print(i)

Multiple calls with the individual name and namespace will returns the same individual
(without creating a dupplicate), and update the individual if property values are given.
   
::

   >>> assert Drug("my_drug3") is Drug("my_drug3") 

Finally, Individuals also have the .equivalent_to attribute (which correspond to the "same as" relation).


Querying Individual relations
-----------------------------

For a given Individual, the values of a property can be obtained with the usual
"object.property" dot notation. See :doc:`properties` for more details.

::

   >>> print(onto.my_drug.has_for_active_principle)

Property name can be prefixed with "INDIRECT_" to obtain all indirect relations
(i.e. those asserted at the class level with restriction, implied by transistive properties, subproperties, equivalences, etc):

::

   >>> print(onto.my_drug.INDIRECT_has_for_active_principle)

   
Introspecting Individuals
-------------------------

The list of properties that exist for a given individual can be obtained by the .get_properties() method.
It returns a generator that yields the properties (without dupplicates).

::
   
   >>> onto.drug_1.get_properties()

The following example shows how to list the properties of a given individual, and the associated values:

::
   
   >>> for prop in onto.drug_1.get_properties():
   >>>     for value in prop[onto.drug_1]:
   >>>         print(".%s == %s" % (prop.python_name, value))

Notice the "Property[individual]" syntax. It allows to get the values as a list, even for functional properties
(contrary to getattr(individual, Property.python_name).

   
Inverse properties can be obtained by the .get_inverse_properties() method.
It returns a generator that yields (subject, property) tuples.

::
   
   >>> onto.drug_1.get_inverse_properties()


Mutli-Class Individuals
-----------------------

In ontologies, an Individual can belong to more than one Class. This is supported in Owlready2.

Individuals have a .is_a atribute that behaves similarly to Class .is_a,
but with the Classes of the Individual. In order to create a mutli-Class Individual,
you need to create the Individual as a single-Class Instance first,
and then to add the other Class(ses) in its .is_a attribute:

::
   
   >>> class BloodBasedProduct(Thing):
   ...     ontology = onto
   
   >>> a_blood_based_drug = Drug()
   >>> a_blood_based_drug.is_a.append(BloodBasedProduct)

Owlready2 will automatically create a hidden Class that inherits from both Drug and BloodBasedProduct. This
hidden class is visible in a_blood_based_drug.__class__, but not in a_blood_based_drug.is_a.
   

Equivalent (identical, SameAs) individuals
------------------------------------------

The .equivalent_to Individual attribute is a list of equivalent individuals (corresponding to OWL SameAs relation).
This list can be modified.

To obtain all equivalent individuals, including indirect ones (due to transitivity), use .INDIRECT_equivalent_to.


Destroying entities
-------------------

The destroy_entity() global function can be used to destroy an entity, i.e. to remove it from the ontology and
the quad store.
Owlready2 behaves similarly to Protege4 when destroying entities: all relations involving the destroyed entity
are destroyed too, as well as all class constructs and blank nodes that refer it.

::

   >>> destroy_entity(individual)
   >>> destroy_entity(Klass)
   >>> destroy_entity(Property)



================================================
File: doc/conf.py
================================================
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# Owlready documentation build configuration file, created by
# sphinx-quickstart on Sun May  4 15:22:45 2014.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys
import os
import sphinx_rtd_theme


# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration ------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = [
    'sphinx.ext.autodoc',
    'sphinx.ext.intersphinx',
    "sphinx_rtd_theme",
]


# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = 'Owlready2'
copyright = '2014-2023, Jean-Baptiste LAMY'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The full version, including alpha/beta/rc tags.
import os.path, re
s = open(os.path.join(os.path.dirname(__file__), "..", "__init__.py")).read()
release = re.findall('VERSION\\s*=\\s*"(.*?)"', s)[0]
# The short X.Y version.
version = ".".join(release.split(".")[:2])

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = []

# The reST default role (used for this markup: `text`) to use for all
# documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built documents.
#keep_warnings = False


# -- Options for HTML output ----------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
#html_theme = 'alabaster'
html_theme = "sphinx_rtd_theme"

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# Add any extra paths that contain custom files (such as robots.txt or
# .htaccess) here, relative to this directory. These files are copied
# directly to the root of the documentation.
#html_extra_path = []

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
html_use_index = False

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Owlready2doc'


# -- Options for LaTeX output ---------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title,
#  author, documentclass [howto, manual, or own class]).
latex_documents = [
  ('index', 'Owlready2.tex', 'Owlready2 Documentation',
   'Jean-Baptiste LAMY', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output ---------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'owlready2', 'Owlready2 Documentation',
     ['Jean-Baptiste LAMY'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output -------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Owlready2', 'Owlready2 Documentation',
   'Jean-Baptiste LAMY', 'Owlready2', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

# If true, do not generate a @detailmenu in the "Top" node's menu.
#texinfo_no_detailmenu = False

#intersphinx_mapping = {'http://docs.python.org/': None}
intersphinx_mapping = {}



================================================
File: doc/contact.rst
================================================

Contact and links
=================

A forum/mailing list is available for Owlready on Nabble: http://owlready.306.s1.nabble.com

In case of trouble, please write to the forum or contact Jean-Baptiste Lamy <jean-baptiste.lamy *@* univ-paris13 *.* fr>

::

  LIMICS
  University Paris 13, Sorbonne Paris Cité
  Bureau 149
  74 rue Marcel Cachin
  93017 BOBIGNY
  FRANCE

Owlready on BitBucket (Git development repository): https://bitbucket.org/jibalamy/owlready2



================================================
File: doc/datatype.rst
================================================
Datatypes
=========

Owlready automatically recognizes and translates basic datatypes to Python, such as string, int, float, etc.

Binary data, i.e. Python's bytes, are mapped to XML base64Binary, and thus they are base64-encoded in RDF / XML files.


Creating enumerated datatypes
-----------------------------

Enumerated datatype can be created as follows with Owlready:

::
   
   >>> with onto:
   ...   class MyEnum(Datatype):
   ...     equivalent_to = [ OneOf(["Male", "Female", "Other"]) ]

The enumerated datatype can be used in data property ranges:

::
   
   >>> with onto:
   ...   class my_prop(DataProperty):
   ...     range = [ MyEnum ]


The list of enumerated values can be queried as follows:
   
::
   
   >>> onto.MyEnum.equivalent_to[0].instances
   ["Male", "Female", "Other"]

   
Creating custom datatypes
-------------------------

The declare_datatype() global function allows to declare a new datatype. It takes 4 arguments:

 * datatype: the Python datatype (for example, a Python type or class)
 * iri: the IRI used to represent the datatype in ontologies
 * parser: a function that takes a serialized string and returns the corresponding datatype
 * unparser: a function that takes a datatype and returns its serialization in a string

The function returns the storid associated to the datatype.

**Warning:** The datatype must be declared **BEFORE** loading any ontology that uses it.

Here is an example for adding support for the XSD "hexBinary" datatype:

::
   
   >>> class Hex(object):
   ...   def __init__(self, value):
   ...     self.value = value
   
   >>> def parser(s):
   ...   return Hex(int(s, 16))
   
   >>> def unparser(x):
   ...   h = hex(x.value)[2:]
   ...   if len(h) % 2 != 0: return "0%s" % h
   ...   return h
   
   >>> declare_datatype(Hex, "http://www.w3.org/2001/XMLSchema#hexBinary", parser, unparser)


The new datatype can then be used as any others:

::
   
   >>> onto = world.get_ontology("http://www.test.org/t.owl")
   
   >>> with onto:
   ...   class p(Thing >> Hex): pass
   
   ...   class C(Thing): pass
   
   ...   c1 = C()
   ...   c1.p.append(Hex(14))




In addition, the define_datatype_in_ontology() function allows to define the datatype in a given ontology.
This was not needed for hexBinary above, because it is already defined in XMLSchema.
However, for user-defined datatype, it is recommended to define them in an ontology
(Owlready does not strictly require that, but other tools like Protégé do).

The following example (re)define the hexBinary datatype in our ontology:

::
   
   >>> define_datatype_in_ontology(Hex, "http://www.w3.org/2001/XMLSchema#hexBinary", onto)
   
This add the (xsd:hexBinary, rdf:type, rdfs:datatype) RDF triple in the quadstore.

As said above, declare_datatype() must be called * before * using the datatype.
On the contrary, define_datatype_in_ontology() may be called after loading an ontology that use the datatype.




================================================
File: doc/development.rst
================================================
Development
===========

Development installation
------------------------

Due due legacy compatibility, the development installation needs to be done

* either manually, by following these steps:

  1. Create a directory (e.g. ``src/``).
     
  2. Add this directory to the $PYTHONPATH shell variable (= traditional way).
     
  3. Put Owlready sources in that directory (in a subdirectory named ``src/owlready2/``).

* or with pip by following these steps:

  1. Create a virtual environment for development and activate it. 

  2. Create an directory with an arbitrary name, e.g. ``mkdir owlready_dev``.

  3. Move or cloning the Owlready2 repository into this directory and change into it.

  4. Run ``pip install -e .[test]`` inside of this Owlready directory.

  5. In case *Python.h* is missing, install python3-dev (e.g. ``sudo apt-get install python3-dev``).

  6. Run the *setup_develop_mode.py* script :
     ``python setup_develop_mode.py`` 
     inside of this Owlready directory (there are explainations in the script, why this is necessary).
     

Finally, To test everything, cd into the **'test'** directory and run ``python regtest.py``.



================================================
File: doc/disjoint.rst
================================================
Disjointness, open and local closed world reasoning
===================================================

By default, OWL considers the world as 'open', *i.e.* everything that is not stated in the ontology is
not 'false' but 'possible' (this is known as *open world assumption*).
Therfore, things and facts that are 'false' or 'impossible' must be clearly stated as so in the ontology.

Disjoint Classes
----------------

Two (or more) Classes are disjoint if there is no Individual belonging to all these Classes (remember that,
contrary to Python instances, an Individual can have several Classes, see :doc:`class`).

A Classes disjointness is created with the AllDisjoint() function, which takes a list of Classes
as parameter. In the example below, we have two Classes, Drug and ActivePrinciple, and we assert that they
are disjoint (yes, we need to specify that explicitely -- sometimes ontologies seem a little dumb!).

::

   >>> from owlready2 import *
   
   >>> onto = get_ontology("http://test.org/onto.owl")
   
   >>> with onto:
   ...     class Drug(Thing):
   ...         pass
   ...     class ActivePrinciple(Thing):
   ...         pass
   ...     AllDisjoint([Drug, ActivePrinciple])


Disjoint Properties
-------------------

OWL also introduces Disjoint Properties.
Disjoint Properties can also be created using AllDisjoint().


Different Individuals
---------------------

Two Individuals are different if they are distinct. In OWL, two Individuals might be considered as being actually
the same, single, Individual, unless they are stated different.
Difference is to Individuals what disjointness is to Classes.

The following example creates two active principles and asserts that they are different (yes, we also need
to state explicitely that acetaminophen and aspirin are not the same!)

::

   >>> acetaminophen = ActivePrinciple("acetaminophen")
   >>> aspirin       = ActivePrinciple("aspirin")
   
   >>> AllDifferent([acetaminophen, aspirin])

.. note::

   In Owlready2, AllDifferent is actually the same function as AllDisjoint -- the exact meaning depends on the
   parameters (AllDisjoint if you provide Classes, AllDifferent if you provide Instances,
   and disjoint Properties if you provide Properties).
   
   
Querying and modifying disjoints
--------------------------------

The .disjoints() method returns a generator for iterating over AllDisjoint constructs involving the given Class
or Property. For Individuals, .differents() behaves similarly.

::

   >>> for d in Drug.disjoints():
   ...     print(d.entities)
   [onto.Drug, onto.ActivePrinciple]

The 'entities' attribute of an AllDisjoint is writable, so you can modify the AllDisjoint construct by adding
or removing entities.

OWL also provides the 'disjointWith' and 'propertyDisjointWith' relations for pairwise disjoints (involving
only two elements). Owlready2 exposes **all** disjoints as AllDisjoints, *including* those declared with 
the 'disjointWith' or 'propertyDisjointWith' relations. In the quad store (or when saving OWL files),
disjoints involving 2 entities are defined using the 'disjointWith' or 'propertyDisjointWith' relations,
while others are defined using AllDisjoint or AllDifferent.


Closing Individuals
-------------------

The open world assumption also implies that the properties of a given Individual are not limited to the
ones that are explicitely stated. For example, if you create a Drug Individual with a single Active
Principle, it does not mean that it has *only* a single Active Principle.

::

   >>> with onto:
   ...     class has_for_active_principle(Drug >> ActivePrinciple): pass
   
   >>> my_acetaminophen_drug = Drug(has_for_active_principle = [acetaminophen])

In the example above, 'my_acetaminophen_drug' has an acetaminophen Active Principle (this fact is true) and it
may have other Active Principle(s) (this fact is possible).

If you want 'my_acetaminophen_drug' to be a Drug with acetaminophen and no other Active Principle, you have to
state it explicitely using a restriction (see :doc:`restriction`):

::

   >>> my_acetaminophen_drug.is_a.append(has_for_active_principle.only(OneOf([acetaminophen])))

Notice that we used OneOf() to 'turn' the acetaminophen Individual into a Class that we can use in the restriction.

You'll quickly find that the open world assumption often leads to tedious and long lists
of AllDifference and Restrictions. Hopefully, Owlready2 provides the close_world() function for automatically
'closing' an Individual. close_world() will automatically add ONLY restrictions as needed; it accepts an
optional parameter: a list of the Properties to 'close' (defaults to all Properties whose domain is
compatible with the Individual).

::

   >>> close_world(my_acetaminophen_drug)


Closing Classes
---------------

close_world() also accepts a Class. In this case, it closes the Class, its subclasses, and all their Individuals.

By default, when close_world() is not called, the ontology performs **open world reasoning**.
By selecting the Classes and the Individuals you want to 'close',
the close_world() function enables **local closed world reasoning** with OWL.

Closing an ontology
-------------------

Finally, close_world() also accepts an ontology. In this case, it closes all the Classes defined in the ontology.
This corresponds to fully **closed world reasoning**.




================================================
File: doc/general_class_axioms.rst
================================================
General class axioms
====================

General class axioms are axioms of the form "A is a B" where "A" is not a named class, but a class construct
(e.g. an intersection, a union or a restriction).


Creating a general class axiom
------------------------------

One can create a general class axiom as follows:

::

   >>> with onto:
   ...     gca = GeneralClassAxiom(onto.Disorder & onto.has_location.some(onto.Heart)) # Left side
   ...     gca.is_a.append(onto.CardiacDisorder) # Right side


The GeneralClassAxiom class take as parameter the left side class construct.

The right side is available as the .is_a attribute.
Notice that one may add several right sides, by calling is_a.append multiple times.

The left side is available as the .left_side attribute.


Accessing general class axioms
------------------------------

One can list general class axioms with Ontology.general_class_axioms:


::

   >>> gcas = list(onto.general_class_axioms())

One can then test the left side by comparison, for example:



::

   >>> searched_left_side = onto.Disorder & onto.has_location.some(onto.Heart)
   >>> for gca in gcas:
   ...     if gca.left_side == searched_left_side: print("Found!")




================================================
File: doc/index.rst
================================================
Welcome to Owlready2's documentation!
*************************************

Owlready2 is a package for ontology-oriented programming in Python. It can load OWL 2.0 ontologies
as Python objects, modify them, save them, and perform reasoning via HermiT
(included). Owlready2 allows a transparent access to OWL ontologies (contrary
to usual Java-based API).

Owlready version 2 includes an optimized triplestore / quadstore, based on SQLite3.
This quadstore is optimized both for performance and memory consumption. Contrary to version 1,
Owlready2 can deal with big ontologies. Owlready2 can also access to UMLS and medical terminology
(using the integrated PyMedTermino2 submodule).

Owlready2 has been created at the LIMICS reseach lab,
University Paris 13, Sorbonne Paris Cité, INSERM UMRS 1142, Paris 6 University, by
Jean-Baptiste Lamy. It was initially developed during the VIIIP research project funded by ANSM,
the French Drug Agency;
this is why some examples in this documentation relate to drug ;).

Owlready2 is available under the GNU LGPL licence v3.
If you use Owlready2 in scientific works, **please cite the following article**:

   **Lamy JB**.
   `Owlready: Ontology-oriented programming in Python with automatic classification and high level constructs for biomedical ontologies. <http://www.lesfleursdunormal.fr/_downloads/article_owlready_aim_2017.pdf>`_
   **Artificial Intelligence In Medicine 2017**;80:11-28
   
In case of troubles, questions or comments, please use this Forum/Mailing list: http://owlready.306.s1.nabble.com


Table of content
----------------

.. toctree::
   intro.rst
   install.rst
   onto.rst
   class.rst
   properties.rst
   datatype.rst
   restriction.rst
   disjoint.rst
   mixing_python_owl.rst
   reasoning.rst
   annotations.rst
   namespace.rst
   sparql.rst
   world.rst
   sync.rst
   rule.rst
   general_class_axioms.rst
   pymedtermino2.rst
   observe.rst
   development.rst
   porting1.rst
   contact.rst



================================================
File: doc/install.rst
================================================
Owlready2 Installation
======================

Owlready2 can be installed with 'pip', the Python Package Installer.

Owlready2 include an optimized Cython module. This module speeds up by about 20% the loading of large ontologies,
but its use is entirely optional.
To build this module, you need a C compiler, and to install the 'cython' Python package.

On the contrary, if you don't have a C compiler, to **not build** the optimized module you need to uninstall
Cython if it is already installed (or to use the manual installation described below).

Owlready2 can be installed from terminal, from Python, or manually.


Installation from terminal (Bash under Linux or DOS under Windows)
------------------------------------------------------------------

You can use the following Bash / DOS commands to install Owlready2 in a terminal:

::

   pip install owlready2

.. figure:: _images/terminal_installation.png

   
If you don't have the permissions for writing in system files,
you can install Owlready2 in your user directory with this command:

::

   pip install --user owlready2



Installation in Spyder / IDLE (or any other Python console)
-----------------------------------------------------------

You can use the following Python commands to install Owlready2 from a Python 3.7.x console
(including those found in Spyder3 or IDLE):

::

   >>> import pip.__main__
   >>> pip.__main__._main(["install", "--user", "owlready2"])

.. figure:: _images/spyder_installation.png

   
Manual installation
-------------------

Owlready2 can also be installed manually in 3 steps:

# Uncompress the Owlready2-0.21.tar.gz source release file (or any other version), for example in C:\\ under Windows

# Rename the directory C:\\Owlready2-0.21 as C:\\owlready2

# Add the C:\\ directory in your PYTHONPATH; this can be done in Python as follows:

  ::

     import sys
     sys.path.append("C:\")
     import owlready2


In the following screenshot, I used /home/jiba/src instead of C:\\, under Linux:

.. figure:: _images/manual_installation.png



================================================
File: doc/intro.rst
================================================
Introduction
============

Owlready2 is a package for manipulating OWL 2.0 ontologies in Python. It can load, modify, save ontologies, and
it supports reasoning via HermiT (included). Owlready allows a transparent access to OWL ontologies.

Owlready2 can:

 - Import ontologies in RDF/XML, OWL/XML or NTriples format.

 - Manipulates ontology classes, instances and annotations as if they were Python objects.

 - Add Python methods to ontology classes.

 - Re-classify instances automatically, using the HermiT reasoner.

 - Import medical terminologies from UMLS (see :doc:`pymedtermino2`).

   
If you need to "convert" formulas between Protégé, Owlready2 and/or Description Logics, the following cheat sheet may be of interest:

`The great table of Description Logics and formal ontology notations <http://www.lesfleursdunormal.fr/static/_downloads/great_ontology_table.pdf>`_


Short example: What can I do with Owlready?
-------------------------------------------

Load an ontology from a local repository, or from Internet:

::
   
   >>> from owlready2 import *
   >>> onto_path.append("/path/to/your/local/ontology/repository")
   >>> onto = get_ontology("http://www.lesfleursdunormal.fr/static/_downloads/pizza_onto.owl")
   >>> onto.load()

Create new classes in the ontology, possibly mixing OWL constructs and Python methods:

::
   
   >>> class NonVegetarianPizza(onto.Pizza):
   ...   equivalent_to = [
   ...     onto.Pizza
   ...   & ( onto.has_topping.some(onto.MeatTopping)
   ...     | onto.has_topping.some(onto.FishTopping)
   ...     ) ]
   
   ...   def eat(self): print("Beurk! I'm vegetarian!")
   
Access the classes of the ontology, and create new instances / individuals:

::
   
   >>> onto.Pizza
   pizza_onto.Pizza
   
   >>> test_pizza = onto.Pizza("test_pizza_owl_identifier")
   >>> test_pizza.has_topping = [ onto.CheeseTopping(),
   ...                            onto.TomatoTopping() ]

In Owlready2, almost any lists can be modified *in place*,
for example by appending/removing items from lists.
Owlready2 automatically updates the RDF quadstore.

::

  >>> test_pizza.has_topping.append(onto.MeatTopping())
   
Perform reasoning, and classify instances and classes:

::
  
  >>> test_pizza.__class__
  onto.Pizza
   
  >>> # Execute HermiT and reparent instances and classes
  >>> sync_reasoner()
  
  >>> test_pizza.__class__
  onto.NonVegetarianPizza
  >>> test_pizza.eat()
  Beurk! I'm vegetarian !

Export to OWL file:

::

  >>> onto.save()

Load Gene Ontology (GO), a large ontology (~ 170 Mb, can take a moment!):
  
::
   
   >>> go = get_ontology("http://purl.obolibrary.org/obo/go.owl").load()

Access entities with an IRI that does not start with the ontology's IRI, by creating a Namespace:

::

   >>> obo = get_namespace("http://purl.obolibrary.org/obo/")
   
   >>> print(obo.GO_0000001.label)
   ['mitochondrion inheritance']


Architecture
------------

Owlready2 maintains a RDF quadstore in an optimized database (SQLite3),
either in memory or on the disk (see :doc:`world`). It provides a high-level access to the Classes and the
objects in the ontology (aka. ontology-oriented programming). Classes and Invididuals are loaded
dynamically from the quadstore as needed, cached in memory and destroyed when no longer needed.



================================================
File: doc/mixing_python_owl.rst
================================================
Mixing Python and OWL
=====================

Adding Python methods to an OWL Class
-------------------------------------

Python methods can be defined in ontology Classes as usual in Python. In the example below, the Drug Class
has a Python method for computing the per-tablet cost of a Drug, using two OWL Properties (which have been
renamed in Python, see :ref:`associating-python-alias-name-to-properties`):

::

   >>> from owlready2 import *
   
   >>> onto = get_ontology("http://test.org/onto.owl")
   
   >>> with onto:
   ...     class Drug(Thing):
   ...         def get_per_tablet_cost(self):
   ...             return self.cost / self.number_of_tablets
   
   ...     class has_for_cost(Drug >> float, FunctionalProperty):
   ...         python_name = "cost"
   
   ...     class has_for_number_of_tablets(Drug >> int, FunctionalProperty):
   ...         python_name = "number_of_tablets"
   
   >>> my_drug = Drug(cost = 10.0, number_of_tablets = 5)
   >>> print(my_drug.get_per_tablet_cost())
   2.0


Forward declarations
--------------------

Sometimes, you may need to forward-declare a Class or a Property.
If the same Class or Property (same name, same namespace) is redefined, the new definition **extends**
the previous one (and do not replace it!).

For example:

::
   
   >>> class has_for_active_principle(Property): pass
   
   >>> with onto:
   ...     class Drug(Thing): pass
   
   ...     class has_for_active_principle(Drug >> ActivePrinciple): pass
   
   ...     class Drug(Thing): # Extends the previous definition of Drug
   ...         is_a = [has_for_active_principle.some(ActivePrinciple)]
   
(Notice that this definition of drug exclude Placebo).



Associating a Python module to an OWL ontology
----------------------------------------------

It is possible to associate a Python module with an OWL ontology. When Owlready2 loads the ontology,
it will automatically import the Python module.
This is done with the 'python_module' annotation, which should be set on the ontology itself.
The value should be the name of your Python module, *e.g.* 'my_package.my_module'.
This annotation can be set with editor like Protégé, after importing the 'owlready_ontology.owl' ontology
(file 'owlready2/owlready_ontology.owl' in Owlready2 sources, URI http://www.lesfleursdunormal.fr/static/_downloads/owlready_ontology.owl):

.. figure:: _images/protege_python_module_annotation.png

The Python module can countain Class and Properties definitions, and methods.
However, it does not need to include all the is-a relations, domain, range,...: any such relation
defined in OWL does not need to be specified again in Python. Therefore, if your Class hierarchy is
defined in OWL, you can create all Classes as child of Thing.

For example, in file 'my_python_module.py':

::

   >>> from owlready2 import *
   
   >>> onto = get_ontology("http://test.org/onto.owl") # Do not load the ontology here!
   
   >>> with onto:
   ...     class Drug(Thing):
   ...         def get_per_tablet_cost(self):
   ...             return self.cost / self.number_of_tablets


And then, in OWL file 'onto.owl', you can define:

 * The 'python_module' annotation (value: 'my_python_module')
 * The 'Drug' Class with superclasses if needed
 * The 'has_for_cost' Property (ommitted in Python -- not needed because it has no method)
 * The 'has_for_number_of_tablets' Property (also ommitted)

In this way, Owlready2 allows you to take the best of Python and OWL!



================================================
File: doc/namespace.rst
================================================
Namespaces
==========

Ontologies can define entities located in other namespaces.
An example is Gene Ontology (GO): the ontology IRI is 'http://purl.obolibrary.org/obo/go.owl',
but the IRI of GO entities are not of the form 'http://purl.obolibrary.org/obo/go.owl#GO_entity' but
'http://purl.obolibrary.org/obo/GO_entity' (note the missing 'go.owl#').


Accessing entities defined in another namespace
-----------------------------------------------

These entities can be accessed in Owlready2 using a namespace. The get_namepace(base_iri) global function
returns a namespace for the given base IRI.

The namespace can then be used with the dot notation, similarly to the ontology.

::
   
   >>> # Loads Gene Ontology (~ 170 Mb), can take a moment!
   >>> go = get_ontology("http://purl.obolibrary.org/obo/go.owl").load()
   
   >>> print(go.GO_0000001) # Not in the right namespace
   None
   
   >>> obo = get_namespace("http://purl.obolibrary.org/obo/")
   
   >>> print(obo.GO_0000001)
   obo.GO_0000001
   
   >>> print(obo.GO_0000001.iri)
   http://purl.obolibrary.org/obo/obo.GO_0000001
   
   >>> print(obo.GO_0000001.label)
   ['mitochondrion inheritance']

   
.get_namepace(base_iri) can also be called on an Ontology, for example:

::
   
   >>> obo = go.get_namespace("http://purl.obolibrary.org/obo/")

Namespaces created on an Ontology can also be used for asserting facts and creating classes, instances,...:

::

   >>> with obo:
   >>>     class MyNewClass(Thing): pass # Create http://purl.obolibrary.org/obo/MyNewClass
   

Creating classes in a specific namespace
----------------------------------------

When creating a Class or a Property,
the namespace attribute is used to build the full IRI of the Class,
and to define in which ontology the Class is defined
(RDF triples are added to this ontology).
The Class IRI is equals to the namespace's base IRI (base_iri) + the Class name.

An ontology can always be used as a namespace, as seen in :doc:`class`.
A namespace object can be used if you want to locate the Class at a different IRI.
For example:

::

   >>> onto      = get_ontology("http://test.org/onto/")
   >>> namespace = onto.get_namespace("http://test.org/onto/pharmaco")
   
   >>> class Drug(Thing):
   ...     namespace = namespace


In the example above, the Drug Class IRI is "http://test.org/pharmaco/Drug", but the Drug Class
belongs to the 'http://test.org/onto' ontology.

Owlready2 proposes 3 methods for indicating the namespace:

 * the 'namespace' Class attribute
 * the 'with namespace' statement
 * if not provided, the namespace is inherited from the first parent Class

The following examples illustrate the 3 methods:
   
::

   >>> class Drug(Thing):
   ...     namespace = namespace

   >>> with namespace:
   ...     class Drug(Thing):
   ...         pass

   >>> class Drug2(Drug):
   ...     # namespace is implicitely Drug.namespace
   ...     pass

   
Modifying a class defined in another ontology
---------------------------------------------

In OWL, an ontology can also *modify* a Class already defined in another ontology.

In Owlready2, this can be done using the 'with namespace' statement.
Every RDF triples added (or deleted) inside a 'with namespace' statement
goes in the ontology corresponding to the namespace of the 'with namespace' statement.

The following example creates the Drug Class in a first ontology,
and then asserts that Drug is a subclass of Substance in a second ontology.

::
   
   >>> onto1 = get_ontology("http://test.org/my_first_ontology.owl")
   >>> onto2 = get_ontology("http://test.org/my_second_ontology.owl")
   
   >>> with onto1:
   ...     class Drug(Thing):
   ...         pass

   >>> with onto2:
   ...     class Substance(Thing):
   ...         pass
   
   ...     Drug.is_a.append(Substance)


   
Renaming entities defined in a namespace
----------------------------------------

Owlready has no direct support for renaming entities defined in a namespace that do not correspond to an ontology.
However, a simple workaround is to create an ontology with the same base IRI as the namespace, change this ontology
base iri (with Ontoloy.base_iri = ...), and then destroy the ontology.




================================================
File: doc/observe.rst
================================================
Observation framework
=====================

Owlready2 provides an observation framework in the owlready2.observe module. It allows adding listeners to any entity
of an ontology, in order to be notified when the entity is modified.


Adding and removing listeners
-----------------------------

Let us create a (very) small ontology:

::
   
   >>> onto = get_ontology("http://test.org/test.owl")
   >>> with onto:
   ...   class Pizza(Thing): pass
   ...   class price(Thing >> float): pass
   ...   pizza = Pizza()

And then import the observe module and add a listener to pizza:

::

   >>> from owlready2.observe import *
   >>> def listener(entity, props):
   ...     print("Listener:", entity, props)
   >>> observe(pizza, listener)

The observe() function is used to add a listener to an entity.
   
Whenever relation are added or removed to the entity, listener is called:

::

   >>> pizza.price = [11.0]
   Listener: 305 [304]

The listener receives two arguments: the entity and a list of properties (NB unless you coalesce event as explained below,
the list includes a single value). For performance purpose, Observe uses "store-IDs" as argument for the entity
and the properties, and not Python objects (hence you see integer values above). Here, 305 is the "store-ID" of the pizza
entity and 304 the "store-ID" of the price property (NB the number may differ).

You may convert store-IDs to Python objects with World._get_by_storid(storid).
Here is a modified listener that shows entity and property objects instead of store-IDs:

::

   >>> def listener(entity, props):
   ...     entity =   default_world._get_by_storid(entity)
   ...     props  = [ default_world._get_by_storid(prop) for prop in props ]
   ...     print("Listener:", entity, props)
   
   >>> unobserve(pizza) # Remove previous listener
   >>> observe(pizza, listener)
   
   >>> pizza.price = [11.0]
   Listener: onto.pizza [onto.price]

The unobserve() function is used to remove a listener from an entity (if no listener is given, all listeners are removed).



Coalescing events
-----------------

The coalesced_observations environment can be used to coalesce events and listener calls.

For instance, the following code generates 3 calls to the listener:

::

   >>> pizza.price.append(12.0)
   Listener: onto.pizza [onto.price]
   >>> pizza.label = ["Pizz", "Test pizza"]
   Listener: onto.pizza [rdf-schema.label]
   Listener: onto.pizza [rdf-schema.label]

Since two labels are added, there are 2 calls for the set label operation.
These multiple calls can be problematic if the listener has a performance cost (e.g. updating the user interface).

Multiple calls can be coalesced and merged using the coalesced_observations environment, as follows:

::

   >>> with coalesced_observations:
   ...     pizza.price.append(13.0)
   ...     pizza.label = ["Pizz2", "Test pizza2"]
   Listener: onto.pizza [onto.price, rdf-schema.label]

No call to listeners are emitted inside the "with coalesced_observations" block, and a single call is emitted at the end,
possibly with more than one property.

In addition, you can add/remove general listener to coalesced_observations, with the add_listener() and remove_listener()
methods. The general listener is called without argument, whenever a change is done in the quadstore.


Stopping observation
--------------------

Using the observation framework may have a performance cost. After using it, if you no longer need it,
you should stop it by calling stop_observing(), as follows:

::
   
   >>> stop_observing(default_world)




================================================
File: doc/onto.rst
================================================
Managing ontologies
===================

Creating an ontology
--------------------

A new empty ontology can be obtained with the get_ontology() function; it takes a single parameter,
the IRI of the ontology.
The IRI is a sort of URL; IRIs are used as identifier for ontologies.

::

   >>> from owlready2 import *
   
   >>> onto = get_ontology("http://test.org/onto.owl")


.. note::
   
   If an ontology has already been created for the same IRI, it will be returned.
   
.. note::
   
   Some ontologies use a # character in IRI to separate the name of the ontology from the name of the
   entities, while some others uses a /. By default, Owlready2 uses a #, if you want to use a /, the IRI
   should ends with /.

   Examples:

   ::

      >>> onto = get_ontology("http://test.org/onto.owl") # => http://test.org/onto.owl#entity

      >>> onto = get_ontology("http://test.org/onto") # => http://test.org/onto#entity
      
      >>> onto = get_ontology("http://test.org/onto/") # => http://test.org/onto/entity
  



Loading an ontology from OWL files
----------------------------------

Use the .load() method of an ontology for loading it.

The easiest way to load the ontology is to load a local copy. In this case, the IRI is the
local filename prefixed with "file://", for example:

::

   >>> onto = get_ontology("file:///home/jiba/onto/pizza_onto.owl").load()

   
If an URL is given, Owlready2 first searches for a local copy of the OWL file and,
if not found, tries to download it from the Internet. For example:

::

   >>> onto_path.append("/path/to/owlready/onto/")
   
   >>> onto = get_ontology("http://www.lesfleursdunormal.fr/static/_downloads/pizza_onto.owl").load()

The onto_path global variable contains a list of directories for searching local copies of ontologies.
It behaves similarly to sys.path (for Python modules / packages).

The get_ontology() function returns an ontology from its IRI, and creates a new empty ontology if needed.

The .load() method loads the ontology from a local copy or from Internet.
It is **safe** to call .load() several times on the same ontology.
It will be loaded only once.

.. note::
   
   Owlready2 currently reads the following file format: RDF/XML, OWL/XML, NTriples.
   The file format is automatically detected.

   NTriples is a very simple format and is natively supported by Owlready2.
   
   RDF/XML is the most common format; it is also natively supported by Owlready2 (since version 0.2).
   
   OWL/XML is supported using a specific parser integrated to Owlready2.
   This parser supports a large subset of OWL, but is not complete.
   It has been tested mostly with OWL files created with the Protégé editor or with Owlready itself.
   Consequently, preferred formats are RDF/XML and NTriples.

   
In complement to the onto_path global variable, the PREDEFINED_ONTOLOGIES global dict can be used to map ontology IRI
to local files or arbitrary URL. You can add your own mapping to PREDEFINED_ONTOLOGIES. For instance, if the ontology
"http://rds.posccaesar.org/ontology/lis14/ont/core" should actually be loaded from the URL "http://rds.posccaesar.org/ontology/lis14/ont/core/1.0",
you can define it as follows:

::

   >>> PREDEFINED_ONTOLOGIES["http://rds.posccaesar.org/ontology/lis14/ont/core"] = "http://rds.posccaesar.org/ontology/lis14/ont/core/1.0"
   


Accessing the content of an ontology
------------------------------------

You can access to the content of an ontology using the 'dot' notation, as usual in Python or more generally
in Object-Oriented Programming. In this way, you can access the Classes, Instances, Properties,
Annotation Properties,... defined in the ontology.
The [] syntax is also accepted.

::

   >>> print(onto.Pizza)
   onto.Pizza
   
   >>> print(onto["Pizza"])
   onto.Pizza

An ontology has the following attributes:

 * .base_iri : base IRI for the ontology
 * .imported_ontologies : the list of imported ontologies (see below)

and the following methods:

 * .classes() : returns a generator for the Classes defined in the ontology (see :doc:`class`)
 * .individuals() : returns a generator for the individuals (or instances) defined in the ontology (see :doc:`class`)
 * .object_properties() : returns a generator for ObjectProperties defined in the ontology (see :doc:`properties`)
 * .data_properties() : returns a generator for DataProperties defined in the ontology (see :doc:`properties`)
 * .annotation_properties() : returns a generator for AnnotationProperties defined in the ontology (see :doc:`annotations`)
 * .properties() : returns a generator for all Properties (object-, data- and annotation-) defined in the ontology
 * .disjoint_classes() : returns a generator for AllDisjoint constructs for Classes defined in the ontology (see :doc:`disjoint`)
 * .disjoint_properties() : returns a generator for AllDisjoint constructs for Properties defined in the ontology (see :doc:`disjoint`)
 * .disjoints() : returns a generator for AllDisjoint constructs (for Classes and Properties) defined in the ontology
 * .different_individuals() : returns a generator for AllDifferent constructs for individuals defined in the ontology (see :doc:`disjoint`)
 * .get_namepace(base_iri) : returns a namespace for the ontology and the given base IRI (see namespaces below, in the next section)
   
.. note::

   Many methods returns a generator. Generators allows iterating over the values without creating a list,
   which can improve performande. However, they are often not very convenient when exploring the ontology:

   ::

      >>> onto.classes()
      <generator object _GraphManager.classes at 0x7f854a677728>
      
   A generator can be trandformed into a list with the list() Python function:

   ::
      
      >>> list(onto.classes())
      [pizza_onto.CheeseTopping, pizza_onto.FishTopping, pizza_onto.MeatTopping,
      pizza_onto.Pizza, pizza_onto.TomatoTopping, pizza_onto.Topping,
      pizza_onto.NonVegetarianPizza]
      
      
The IRIS pseudo-dictionary can be used for accessing an entity from its full IRI:

::

   >>> IRIS["http://www.lesfleursdunormal.fr/static/_downloads/pizza_onto.owl#Pizza"]
   pizza_onto.Pizza


Ontologies can also define entities located in other namespaces, for example
Gene Ontology (GO) has the following IRI: 'http://purl.obolibrary.org/obo/go.owl',
but the IRI of GO entities are of the form 'http://purl.obolibrary.org/obo/GO_entity' (note the missing 'go.owl#').
See :doc:`namespace` to learn how to access such entities.


Simple queries
--------------


Simple queries can be performed with the .search() method of the ontology. It expects one or several keyword
arguments. The supported keywords are:

* **iri**, for searching entities by its full IRI
* **type**, for searching Individuals of a given Class
* **subclass_of**, for searching subclasses of a given Class
* **is_a**, for searching both Individuals and subclasses of a given Class
* **subproperty_of**, for searching subproperty of a given Property
* any object, data or annotation property name

Special arguments are:

* **_use_str_as_loc_str**: whether to treats plain Python strings as strings in any language (default is True)
* **_case_sensitive**: whether to take lower/upper case into consideration (default is True)
* **_bm25**: if True, returns a list of (entity, relevance) pairs instead of just the entities (default is False)

The value associated to each keyword can be a single value or a list of several values.
A star * can be used as a jocker in string values.

.. warning::

   .search() does not perform any kind of reasoning, it just searches in asserted facts.
   In addition, it cannot find Classes through SOME or ONLY restrictions.

For example, for searching for all entities with an IRI ending with 'Topping':

::

   >>> onto.search(iri = "*Topping")
   [pizza_onto.CheeseTopping, pizza_onto.FishTopping, pizza_onto.MeatTopping,
   pizza_onto.TomatoTopping, pizza_onto.Topping]

In addition, the special value "*" can be used as a wildcard for any object.
For example, the following line searches for all individuals that are related
to another one with the 'has_topping' relation (NB there is none in the default pizza_onto.owl file):

::

   >>> onto.search(has_topping = "*")

When a single return value is expected, the .search_one() method can be used. It works similarly:

::

   >>> onto.search_one(label = "my label")
   

Owlready classes and individuals can be used as values within search(), as follows:

::

   >>> onto.search_one(is_a = onto.Pizza)
   
   
Finally, search() can be nested, as in the following example:

::

   >>> onto.search(is_a = onto.Pizza, has_topping = onto.search(is_a = onto.TomatoTopping))

Owlready automatically combines nested searches in a single, optimized, search.

For more complex queries, SQPARQL can be used with RDFlib (see :doc:`world`).


Ontology metadata
-----------------

The metadata of the ontology can be accessed with .metadata, in read and write access:

::

   >>> print(onto.metadata.comment)
   [...]
   >>> onto.metadata.comment.append("my first comment")

Any annotation can be used with .metadata.

In addition, you can list the available annotions by iterating through .metadata, for example:

::

   >>> for annot_prop in onto.metadata:
   ...         print(annot_prop, ":", annot_prop[onto.metadata])


Importing other ontologies
--------------------------

An ontology can import other ontologies, like a Python module can import other modules.

The imported_ontologies attribute of an ontology is a list of the ontology it imports. You can add
or remove items in that list:

::

   >>> onto.imported_ontologies.append(owlready_ontology)


Saving an ontology to an OWL file
---------------------------------

The .save() method of an ontology can be used to save it.
It will be saved in the first directory in onto_path.

::

   >>> onto.save()
   >>> onto.save(file = "filename or fileobj", format = "rdfxml")

.save() accepts two optional parameters: 'file', a file object or a filename for saving the ontology,
and 'format', the file format (default is RDF/XML).

.. note::
   
   Owlready2 currently writes the following file format: "rdf/xml", "ntriples".
   
   NTriples is a very simple format and is natively supported by Owlready2.
   
   RDF/XML is the most common format; it is also natively supported by Owlready2 (since version 0.2).
   
   OWL/XML is not yet supported for writing.


Changing the ontology base IRI
------------------------------

You can change the ontology base IRI as follows:

::

   >>> onto.base_iri = "http://test.org/new_base_iri.owl#"

This will also change the IRI or all entities in the ontology.
If you don't want to change IRI entities, you can use the set_base_iri() method:

::

   >>> onto.set_base_iri("http://test.org/new_base_iri.owl#", rename_entities = False)


Destroying an ontology
----------------------

You can destroy an ontology as follows:

::

   >>> onto.destroy()

By default, Owlready does not update the Python object in memory. This may cause problem in some situations,
e.g. if you continue using a class from another ontology that inherits from a class in the destroyed ontology.

You can destroy the ontology and update the Python objet as follows:

::

   >>> onto.destroy(update_relation = True, update_is_a = True)

The update_is_a optional argument updates is-a relation (subClassOf, subPropertyOf and RDF type), while update_relation
updates other relations.



================================================
File: doc/porting1.rst
================================================
Differences between Owlready version 1 and 2
============================================

This section summarizes the major differences between Owlready version 1 and 2.


Creation of Classes, Properties and Individuals
-----------------------------------------------

The 'ontology' parameters is now called 'namespace' in Owlready2. It accepts a namespace or an ontology.

Owlready 1:

::

   >>> class Drug(Thing):
   ...     ontology = onto

Owlready 2:

::

   >>> class Drug(Thing):
   ...     namespace = onto


Generated Individual names
--------------------------

Owlready 1 permitted to generate dynamically Individual names, depending on their relations.
This is no longer possible in Owlready 2, due to the different architecture.


Functional properties
---------------------

In Owlready 1, functional properties had default values depending on their range. For example,
if the range was float, the default value was 0.0.

In Owlready 2, functional properties always returns None if not relation has been asserted.


Creation of restrictions
------------------------

In Owlready 1, restrictions were created by calling the property:

::
   
   >> Property(SOME, Range_Class)
   >> Property(ONLY, Range_Class)
   >> Property(MIN, cardinality, Range_Class)
   >> Property(MAX, cardinality, Range_Class)
   >> Property(EXACTLY, cardinality, Range_Class)
   >> Property(VALUE, Range_Instance)

In Owlready 2, they are created by calling the .some(), .only(), .min(), .max(), .exactly() and .value()
methods of the Property:

::
   
   >> Property.some(Range_Class)
   >> Property.only(Range_Class)
   >> Property.min(cardinality, Range_Class)
   >> Property.max(cardinality, Range_Class)
   >> Property.exactly(cardinality, Range_Class)
   >> Property.value(Range_Individual)

   
Logical operators and 'One of' constructs
-----------------------------------------

In Owlready 1, the negation was called 'NOT()'.
In Owlready 2, the negation is now called 'Not()'.

In Owlready 1, the logical operators (Or and And) and the one_of construct expect several values as parameters.

::

   >>> Or(ClassA, ClassB,...)
   
In Owlready 2, the logical operators (Or and And) and the OneOf construct expect a list of values.

::

   >>> Or([ClassA, ClassB,...])


Reasoning
---------

In Owlready 1, the reasoner was executed by calling ontology.sync_reasoner().

::

   >>> onto.sync_reasoner()

In Owlready 2, the reasoner is executed by calling sync_reasoner(). The reasoning can involve several ontologies
(all those that have been loaded). sync_reasoner() actually acts on a World (see :doc:`world`).

::

   >>> sync_reasoner()


Annotations
-----------

In Owlready 1, annotations were available through the ANNOTATIONS pseudo-dictionary.

::

   >>> ANNOTATIONS[Drug]["label"] = "Label for Class Drug"

   

In Owlready 2, annotations are available as normal attributes.

::

   >>> Drug.label = "Label for Class Drug"




================================================
File: doc/properties.rst
================================================
Properties
==========


Creating a new class of property
--------------------------------

A new property can be created by sublcassing the ObjectProperty or DataProperty class.
The 'domain' and 'range' properties can be used to specify the domain and the range of the property.
Domain and range must be given in list, since OWL allows to specify several domains or ranges for a given
property (if multiple domains or ranges are specified, the domain or range is the intersection of them,
*i.e.* the items in the list are combined with an AND logical operator).

The following example creates two Classes, Drug and Ingredient, and then an ObjectProperty that relates them.

::

   >>> from owlready2 import *
   
   >>> onto = get_ontology("http://test.org/onto.owl")

   >>> with onto:
   ...     class Drug(Thing):
   ...         pass
   ...     class Ingredient(Thing):
   ...         pass
   ...     class has_for_ingredient(ObjectProperty):
   ...         domain    = [Drug]
   ...         range     = [Ingredient]

In addition, the 'domain >> range' syntax can be used when creating property. It replaces the ObjectProperty
or DataProperty parent Class, as follows:

::

   >>> with onto:
   ...     class has_for_ingredient(Drug >> Ingredient):
   ...         pass

   


In addition, the following subclasses of Property are available: FunctionalProperty, InverseFunctionalProperty,
TransitiveProperty, SymmetricProperty, AsymmetricProperty, ReflexiveProperty, IrreflexiveProperty.
They should be used in addition to ObjectProperty or DataProperty (or the 'domain >> range' syntax).


Getting domain and range
------------------------

The .domain and .range attributes of a Property can be used to query its domain and range.
They returns a list.

::

   >>> has_for_ingredient.domain
   [Drug]
   
   >>> has_for_ingredient.range
   [Ingredient]




Creating a relation
-------------------

A relation is a triple (subject, property, object) where property is a Property class, and subject and object
are instances (or literal, such as string or numbers) which are subclasses of the domain and range
defined for the property class.
A relation can be get or set using Python attribute of the subject, the attribute name being the same as
the Property class name: 

::

   >>> my_drug = Drug("my_drug")
   
   >>> acetaminophen = Ingredient("acetaminophen")
   
   >>> my_drug.has_for_ingredient = [acetaminophen]

The attribute contains a list of the subjects:

::

   >>> print(my_drug.has_for_ingredient)
   [onto.acetaminophen]

This list can be modifed *in place* or set to a new value;
Owlready2 will automatically add or delete RDF triples in the quadstore as needed:

::

   >>> codeine = Ingredient("codeine")
   
   >>> my_drug.has_for_ingredient.append(codeine)
   
   >>> print(my_drug.has_for_ingredient)
   [onto.acetaminophen, onto.codeine]
   

Data Property
-------------

Data Properties are Properties with a data type in their range. The following data types
are currently supported by Owlready2:

 * int
 * float
 * bool
 * str (string)
 * owlready2.normstr (normalized string, a single-line string)
 * owlready2.locstr  (localized string, a string with a language associated)
 * datetime.date
 * datetime.time
 * datetime.datetime

Here is an example of a string Data Property:

::

   >>> with onto:
   ...     class has_for_synonym(DataProperty):
   ...         range = [str]

   >>> acetaminophen.has_for_synonym = ["acetaminophen", "paracétamol"]

The 'domain >> range' syntax can also be used:

::

   >>> with onto:
   ...     class has_for_synonym(Thing >> str):
   ...         pass


Inverse Properties
------------------

Two properties are inverse if they express the same meaning, but in a reversed way. 
For example the 'is_ingredient_of' Property is the inverse of the 'has_for_ingredient' Property created above:
saying "a drug A has for ingredient B" is equivalent to "B is ingredient of drug A".

In Owlready2, inverse Properties are defined using the 'inverse_property' attribute.

::

   >>> with onto:
   ...     class is_ingredient_of(ObjectProperty):
   ...         domain           = [Ingredient]
   ...         range            = [Drug]
   ...         inverse_property = has_for_ingredient

Owlready automatically handles Inverse Properties. It will automatically set has_for_ingredient.inverse_property,
and automatically update relations when the inverse relation is modified.

::

   >>> my_drug2 = Drug("my_drug2")
   
   >>> aspirin = Ingredient("aspirin")
   
   >>> my_drug2.has_for_ingredient.append(aspirin)
   
   >>> print(my_drug2.has_for_ingredient)
   [onto.aspirin]
   
   >>> print(aspirin.is_ingredient_of)
   [onto.my_drug2]


   >>> aspirin.is_ingredient_of = []

   >>> print(my_drug2.has_for_ingredient)
   []

.. note::

   This won't work for the drug created previously, because we created the inverse property
   **after** we created the relation between my_drug and acetaminophen.


Functional and Inverse Functional properties
--------------------------------------------

A functional property is a property that has a single value for a given instance. Functional properties
are created by inheriting the FunctionalProperty class.

::

   >>> with onto:
   ...     class has_for_cost(DataProperty, FunctionalProperty): # Each drug has a single cost
   ...         domain    = [Drug]
   ...         range     = [float]
   
   >>> my_drug.has_for_cost = 4.2
   
   >>> print(my_drug.has_for_cost)
   4.2

Contrary to other properties, a functional property returns
a single value instead of a list of values. If no value is defined, they returns None.

::

   >>> print(my_drug2.has_for_cost)
   None

Owlready2 is also able to guess when a Property is functional with respect to a given class.
In the following example, the 'prop' Property is not functional, but Owlready2 guesses that, for Individuals
of Class B, there can be only a single value. Consequently, Owlready2 considers prop as functional
for Class B.

::

   >>> with onto:
   ...     class prop(ObjectProperty): pass
   ...     class A(Thing): pass
   ...     class B(Thing):
   ...         is_a = [ prop.max(1) ]

   >>> A().prop
   []
   >>> B().prop
   None
   
An Inverse Functional Property is a property whose inverse property is functional.
They are created by inheriting the InverseFunctionalProperty class.


Creating a subproperty
----------------------

A subproperty can be created by subclassing a Property class.

::

   >>> with onto:
   ...     class ActivePrinciple(Ingredient):
   ...         pass
   ...     class has_for_active_principle(has_for_ingredient):
   ...         domain    = [Drug]
   ...         range     = [ActivePrinciple]

.. note::
   
   Owlready2 currently does not automatically update parent properties when a child property is defined.
   This might be added in a future version, though.

   
Obtaining indirect relations (considering subproperty, transitivity, etc)
-------------------------------------------------------------------------

Property name can be prefixed by "INDIRECT_" to obtain all indirectly
related entities. It takes into account:

 * transitive, symmetric and reflexive properties,
 * property inheritance (i.e. subproperties),
 * classes of an individual (i.e. values asserted at the class level),
 * class inheritance (i.e. parent classes).
 * equivalences (i.e. equivalent classes, identical "same-as" individuals,...)

::

   >>> with onto:
   ...     class BodyPart(Thing): pass
   ...     class part_of(BodyPart >> BodyPart, TransitiveProperty): pass
   ...     abdomen          = BodyPart("abdomen")
   ...     heart            = BodyPart("heart"           , part_of = [abdomen])
   ...     left_ventricular = BodyPart("left_ventricular", part_of = [heart])
   ...     kidney           = BodyPart("kidney"          , part_of = [abdomen])
    
   ... print(left_ventricular.part_of)
   [heart]
   
   ... print(left_ventricular.INDIRECT_part_of)
   [heart, abdomen]


.. _associating-python-alias-name-to-properties:

Associating Python alias name to Properties
-------------------------------------------

In ontologies, properties are usually given long names, *e.g.* "has_for_ingredient", while in programming
languages like Python, shorter attribute names are more common, *e.g.* "ingredients" (notice also the use
of a plural form, since it is actually a list of several ingredients).

Owlready2 allows to rename Properties with more Pythonic name through the 'python_name' annotation (defined
in the Owlready ontology, file 'owlready2/owlready_ontology.owl' in Owlready2 sources, URI http://www.lesfleursdunormal.fr/static/_downloads/owlready_ontology.owl):

::

   >>> has_for_ingredient.python_name = "ingredients"
   
   >>> my_drug3 = Drug()
   
   >>> cetirizin = Ingredient("cetirizin")
   
   >>> my_drug3.ingredients = [cetirizin]
   
.. note::
   
   The Property class is still considered to be called 'has_for_ingredient', for example it is still
   available as 'onto.has_for_ingredient', but not as 'onto.ingredients'.

For more information about the use of annotations, see :doc:`annotations`.

The 'python_name' annotations can also be defined in ontology editors like Protégé, by importing the Owlready
ontology (file 'owlready2/owlready_ontology.owl' in Owlready2 sources, URI http://www.lesfleursdunormal.fr/static/_downloads/owlready_ontology.owl).


Getting relation instances
--------------------------

The list of relations that exist for a given property can be obtained by the .get_relations() method.
It returns a generator that yields (subject, object) tuples.

::
   
   >>> onto.has_for_active_principle.get_relations()

.. warning::
   
   The quadstore is not indexed for the .get_relations() method. Thus, it can be slow on huge ontologies.



================================================
File: doc/pymedtermino2.rst
================================================
PyMedTermino2
=============

Introduction
************

PyMedTermino (Medical Terminologies for Python) is a Python module for easy access to the main medical
terminologies in Python. The following terminologies are supported:

 - All terminologies in UMLS, including:
   - SNOMED CT
   - ICD10
   - MedDRA
 - ICD10 in French (CIM10)

The main features of PyMedTermino are:

 - A single API for accessing all terminologies
 - Optimized full-text search
 - Access to terms, synonyms and translations
 - Manage concepts and relations between concepts
 - Mappings between terminologies (e.g. via UMLS or manual mapping)

PyMedTermino has been designed for "batch" access to terminologies; it is *not* a terminology browser
(althought it can be used to write a terminology browser in Python).

The first version of PyMedTermino was an independent Python package.
The second version (PyMedTermino2) is integrated with Owlready2, and store medical terminologies as OWL ontlogies.
This allows relating medical terms from terminologies with user created concepts.

UMLS data is not included, but can be downloaded for free (see Intallation below). Contrary to PyMedTermino1,
PyMedTermino2 do not require a connection to an external UMLS database: it imports UMLS data in its own local
database, automatically.

If you use PyMedTermino in scientific works, **please cite the following article**:

   **Lamy JB**, Venot A, Duclos C.
   `PyMedTermino: an open-source generic API for advanced terminology services. <http://ebooks.iospress.nl/volumearticle/39485>`_
   **Studies in health technology and informatics 2015**;210:924-928


Installation
************

#. Install Python 3.7 and Owlready2 (if not already done).
   **PyMedTermino2 requires Python >= 3.7 for importing UMLS** (However, after importing the data in the quadstore, it can be used with Python 3.6 if you really need to).

#. After registration with NLM, download UMLS data (Warning: some restriction may apply depending on country; see UMLS licence and its SNOMED CT appendix):

   - https://www.nlm.nih.gov/research/umls/licensedcontent/umlsknowledgesources.html

     PyMedTermino2 suports both the "Full UMLS Release Files" and the "UMLS Metathesaurus Files", but the latter
     is recommended since it is faster to uncompress.
     E.g. download “umls-2019AA-metathesaurus.zip”. Do not unzip it!

#. Import UMLS data in Python as follows:

>>> from owlready2 import *
>>> from owlready2.pymedtermino2 import *
>>> from owlready2.pymedtermino2.umls import *
>>> default_world.set_backend(filename = "pym.sqlite3")
>>> import_umls("umls-2019AA-metathesaurus.zip", terminologies = ["ICD10", "SNOMEDCT_US", "CUI"])
>>> default_world.save()

were:
 - "pym.sqlite3" is the quadstore file in which the data are stored.
 - ["ICD10", "SNOMEDCT_US", "CUI"] are the terminologies imported (valid codes are UMLS code, plus "CUI" for CUI).
   If the 'terminologies' parameter is missing, all terminologies are imported.

To import also suppressed/deprecated concept, add the following parameter: remove_suppressed = "".

The importation can take several minutes or hours, depending on the number of terminologies imported.

4. Import French ICD10 (optional):

>>> from owlready2.pymedtermino2.icd10_french import *
>>> import_icd10_french()
>>> default_world.save()

   
SNOMED CT
*********

Loading
-------

To load SNOMED CT in Python:

>>> from owlready2 import *
>>> default_world.set_backend(filename = "pym.sqlite3")
>>> PYM = get_ontology("http://PYM/").load()
>>> SNOMEDCT_US = PYM["SNOMEDCT_US"]

Here, 'PYM' is the abbreviation for PyMedTermino. PYM can be indiced with a terminology code, to obtain
the corresponding terminology object (here, SNOMEDCT_US).


Concepts
--------

The SNOMEDCT_US object represents the SNOMED CT terminology. A SNOMED CT concept can be obtained from its
code (in the following example, 302509004, which is the code for the heart concept) by indexing this
object with curly brackets:

>>> concept = SNOMEDCT_US[302509004]
>>> concept
SNOMEDCT_US["302509004"] # Entire heart

The has_concept() method can be used to verify if a code corresponds to a concept or not:

>>> SNOMEDCT_US.has_concept("invalid_code")
False

Each concept has a code, available as the name of the entity, and a preferred term, available as the label RDF annotation:

>>> concept.name
'302509004'
>>> concept.label
['Entire heart']
>>> concept.label.first()
'Entire heart'

SNOMED CT also proposes synonym terms, available via the 'synonyms' annotation :

>>> concept.synonyms
['Entire heart (body structure)']

The 'terminology' attribute contains the terminology of the concept:

>>> concept.terminology
PYM["SNOMEDCT_US"] # US Edition of SNOMED CT


Full-text search
----------------

The search() method allows full-text search in SNOMED CT terms (including synonyms):

>>> SNOMEDCT_US.search("Cardiac structure")
[SNOMEDCT_US["24964005"] # Cardiac conducting system structure
, SNOMEDCT_US["10746000"] # Cardiac septum structure
...]

Full-text search uses the FTS engine of SQLite, it is thus possible to use its functionalities.
For example, for searching for all words beginning by a given prefix:

>>> SNOMEDCT_US.search("osteo*")
[SNOMEDCT_US["66467005"] # Osteochondromatosis
, SNOMEDCT_US["40970001"] # Chronic osteomyelitis
...]

Is-a relations: parent and child concepts
-----------------------------------------

The “parents” and “children” attributes return the list of parent and child concepts (i.e. the concepts
with is-a relations):

>>> concept.parents
[SNOMEDCT_US["116004006"] # Entire hollow viscus
, SNOMEDCT_US["187639008"] # Entire thoracic viscus
, SNOMEDCT_US["80891009"] # Heart structure
]
>>> concept.children
[SNOMEDCT_US["195591003"] # Entire transplanted heart
]

The ancestor_concepts() and descendant_concepts() methods return all the ancestor concepts
(parents, parents of parents, and so on) and the descendant concepts (children, children of children, and so on) :

>>> concept.ancestor_concepts()
[SNOMEDCT_US["302509004"] # Entire heart
, SNOMEDCT_US["116004006"] # Entire hollow viscus
, SNOMEDCT_US["118760003"] # Entire viscus
...]
>>> concept.descendant_concepts()
[SNOMEDCT_US["302509004"] # Entire heart
, SNOMEDCT_US["195591003"] # Entire transplanted heart
]

Both methods remove dupplicates automatically. They also include the starting concept in the results.
If you do not want it, use the 'include_self' parameter:

>>> concept.descendant_concepts(include_self = False)
[SNOMEDCT_US["195591003"] # Entire transplanted heart
]

PyMedTermino2 concepts are OWL and Python classes. As a consequence, you can use the Python issubclass() function
to test whether a concept is a descendant of another:

>>> issubclass(concept, SNOMEDCT_US["272625005"])
True


Part-of relations
-----------------

“part_of” and “has_part” attributes provide access to subparts or superpart of the concept:

>>> concept.part_of
[SNOMEDCT_US["362010009"] # Entire heart AND pericardium
]
>>> concept.has_part
[SNOMEDCT_US["244258000"] # Entire marginal branch of right coronary artery
, SNOMEDCT_US["261405004"] # Entire atrium
, SNOMEDCT_US["244378006"] # Lateral atrioventricular leaflet
...]


Other relations
---------------

The “get_class_properties” method returns the set of relations available for a given concept. Is-a relations
are never included in this list, and are handled with the “parents” and “children” attributes previously
seen, however part-of relations are included.

>>> concept = SNOMEDCT_US["3424008"]
>>> concept
SNOMEDCT_US["3424008"] # Tachycardia
>>> concept.get_class_properties()
{PYM.mapped_to, PYM.case_significance_id, PYM.unifieds, PYM.terminology, rdf-schema.label, PYM.subset_member, PYM.definition_status_id, PYM.synonyms, PYM.has_interpretation, PYM.active, PYM.interprets, PYM.effective_time, PYM.ctv3id, PYM.groups, PYM.has_finding_site, PYM.type_id}

Each relation corresponds to an attribute in the concept. The name of the attribute is the part after the '.',
e.g. for 'PYM.interprets' the name is 'interprets'.
The attribute's value is a list with the corresponding values:

>>> concept.has_finding_site
[SNOMEDCT_US["24964005"] # Cardiac conducting system structure
]
>>> concept.interprets
[SNOMEDCT_US["364075005"] # Heart rate
]


Relation groups
---------------

In SNOMED CT, relations can be grouped together. The “groups” attribute returns the list of groups. It is
then possible to access to the group's relation.

>>> concept = SNOMEDCT_US["186675001"]
>>> concept
SNOMEDCT_US["186675001"] # Viral pharyngoconjunctivitis
>>> concept.groups
[<Group 453170_0> # mapped_to=Viral conjunctivitis, unspecified
, <Group 453170_3> # has_causative_agent=Virus ; has_associated_morphology=Inflammation ; has_finding_site=Pharyngeal structure ; has_pathological_process=Infectious process
, <Group 453170_4> # has_causative_agent=Virus ; has_associated_morphology=Inflammation ; has_finding_site=Conjunctival structure ; has_pathological_process=Infectious process
>>> concept.groups[2].get_class_properties()
{PYM.has_causative_agent, PYM.has_associated_morphology, PYM.has_finding_site, PYM.has_pathological_process}
>>> concept.groups[2].has_finding_site
[SNOMEDCT_US["29445007"] # Conjunctival structure
]
>>> concept.groups[2].has_associated_morphology
[SNOMEDCT_US["23583003"] # Inflammation
]


Iterating over SNOMED CT
------------------------

To obtain the terminology's first level concepts (i.e. the root concepts), use the children attribute of the terminology:

>>> SNOMEDCT_US.children
[SNOMEDCT_US["138875005"] # SNOMED CT Concept
]

The descendant_concepts() method returns all concepts in SNOMED CT.

>>> for concept in SNOMEDCT_US.descendant_concepts(): [...]



ICD10
*****

Loading modules
---------------

To load SNOMED CT in Python:

>>> from owlready2 import *
>>> default_world.set_backend(filename = "pym.sqlite3")
>>> PYM = get_ontology("http://PYM/").load()
>>> ICD10 = PYM["ICD10"]

Or, for the French version (if you imported it during installation):

>>> CIM10 = PYM["CIM10"]

CIM10 can be used as ICD10.


Concepts
--------

The ICD10 object allows to access to ICD10 concepts. This object behaves similarly to the SNOMED CT
terminology previously described (see `SNOMED CT`_).

>>> ICD10["E10"]
ICD10["E10"] # Insulin-dependent diabetes mellitus
>>> ICD10["E10"].parents
[ICD10["E10-E14.9"] # Diabetes mellitus
]
>>> ICD10["E10"].ancestor_concepts()
[ICD10["E10"] # Insulin-dependent diabetes mellitus
, ICD10["E10-E14.9"] # Diabetes mellitus
, ICD10["E00-E90.9"] # Endocrine, nutritional and metabolic diseases
]

ICD10 being monoaxial, the parents list always includes at most one parent.


UMLS
****

Loading modules
---------------

>>> from owlready2 import *
>>> default_world.set_backend(filename = "pym.sqlite3")
>>> PYM = get_ontology("http://PYM/").load()
>>> CUI = PYM["CUI"]

UMLS concepts (CUI)
-------------------

In UMLS, CUI correspond to concepts: a given concept gathers equivalent terms or codes from various
terminologies.

CUI can be accessed with the UMLS_CUI terminology:

>>> concept = CUI["C0085580"]
>>> concept
CUI["C0085580"] # Essential hypertension
>>> concept.name
'C0085580'
>>> concept.label
['Essential hypertension']
>>> concept.synonyms
['Essential (primary) hypertension', 'Idiopathic hypertension', 'Primary hypertension', 'Systemic primary arterial hypertension', 'Essential hypertension (disorder)']

Relations of CUI are handled in the same way than for SNOMED CT (see above), for example:

>>> concept.get_class_properties()
{PYM.originals, PYM.terminology, rdf-schema.label, PYM.synonyms}


Relation with source terminologies
----------------------------------

The originals attribute of a CUI concept contains the corresponding concepts in UMLS sources terminologies:

>>> concept.originals
[SNOMEDCT_US["59621000"] # Essential hypertension
, CIM10["I10"] # Hypertension essentielle (primitive)
, ICD10["I10"] # Essential (primary) hypertension
]

The inverse attribute is unifieds. For concepts in the source terminologies, it contains the corresponding CUI
(some concepts may be associated with several CUI):

>>> ICD10["I10"].unifieds
[CUI["C0085580"] # Essential hypertension
]


Mapping between terminologies
-----------------------------

PyMedTermino uses the '>>' operator for mapping from a terminology to another.
For example, you can map a SNOMED CT concept to UMLS as follows:

>>> SNOMEDCT_US[186675001]
SNOMEDCT_US["186675001"] # Viral pharyngoconjunctivitis
>>> SNOMEDCT_US[186675001] >> CUI
Concepts([
  CUI["C0542430"] # Viral pharyngoconjunctivitis
])

Or you can map a UMLS concept to ICD10:

>>> CUI["C0542430"] >> ICD10
Concepts([
  ICD10["B30.2"] # Viral pharyngoconjunctivitis
])

Finally, you can map directly from a terminology in UMLS to another terminology in UMLS,
for example from SNOMED CT to ICD10:

>>> SNOMEDCT_US[186675001] >> ICD10
Concepts([
  ICD10["B30.9"] # Viral conjunctivitis, unspecified
])

The direct mapping considers 'mapped_to' relations available first, and default to mapping using CUI.



Set of concepts
***************

The Concepts class implements a set of concepts.

>>> concepts = PYM.Concepts([ ICD10["E10"], ICD10["E11"], ICD10["E12"] ])
>>> concepts
Concepts([
  ICD10["E10"] # Insulin-dependent diabetes mellitus
, ICD10["E12"] # Malnutrition-related diabetes mellitus
, ICD10["E11"] # Non-insulin-dependent diabetes mellitus
])

Concepts class inherits from Python's set and supports all its methods (such as add(), remove(), etc).

Concepts can be used to map several concepts simultaneously, using the '>>' operator, for example:

>>> PYM.Concepts([ ICD10["E10"], ICD10["E11"], ICD10["E12"] ]) >> SNOMEDCT_US
Concepts([
  SNOMEDCT_US["44054006"] # Type 2 diabetes mellitus
, SNOMEDCT_US["46635009"] # Type 1 diabetes mellitus
, SNOMEDCT_US["75524006"] # Malnutrition related diabetes mellitus
])

In addition, the Concepts class also provides advanced terminology-oriented methods:

* keep_most_generic() keeps only the most generic concepts in the set (i.e. it removes all concepts that are a descendant of another concept in the set)
* keep_most_specific() keeps only the most specific concepts in the set (i.e. it removes all concepts that are an ancestor of another concept in the set)
* lowest_common_ancestors() computes the lower common ancestors
* find(c) search the set for a concept that is a descendant of c (including c itself)
* extract(c) search the set for all concepts that are descendant of c (including c itself)
* subtract(c) return a new set with all concepts in the set, except those that are descendant of c (including c itself)
* subtract_update(c) remove from the set for all concepts that are descendant of c (including c itself)
* all_subsets() computes all subsets included in the set.
* imply(other) returns True if all concepts in the 'other' set are descendants of (at least) one of the concepts in the set
* is_semantic_subset(other) returns True if all concepts in this set are descendants of (at least) one of the concept in the 'other' set
* is_semantic_superset(other) returns True if all concepts in this set are ancestors of (at least) one of the concept in the 'other' set
* is_semantic_disjoint(other) returns True if all concepts in this set are semantically disjoint from all concepts in the 'other' set
* semantic_intersection(other) returns the intersection of the set with 'other', considering is-a relations between the concepts in the sets
* remove_entire_families(only_family_with_more_than_one_child = True) replaces concepts in the set by their parents, whenever all the children of the parent are present



================================================
File: doc/reasoning.rst
================================================
Reasoning
=========

OWL reasoners can be used to check the *consistency* of an ontology, and to deduce new fact in the ontology,
typically be *reclassing* Individuals to new Classes, and Classes to new superclasses,
depending on their relations.

Several OWL reasoners exist; Owlready2 includes:

* a modified version of the `HermiT reasoner <http://hermit-reasoner.com/>`_,
  developed by the department of Computer Science of the University of Oxford, and released under the LGPL licence.

* a modified version of the `Pellet reasoner <https://github.com/stardog-union/pellet>`_,
  released under the AGPL licence.
  
HermiT and Pellet are written in Java, and thus you need a Java Vitual Machine to perform reasoning in Owlready2.

HermiT is used by default.


Configuration
-------------

Under Linux, Owlready should automatically find Java.

Under windows, you may need to configure the location of the Java interpreter, as follows:

::

   >>> from owlready2 import *
   >>> import owlready2
   >>> owlready2.JAVA_EXE = "C:\\path\\to\\java.exe"


Setting up everything
---------------------

Before performing reasoning, you need to create all Classes, Properties and Instances, and
to ensure that restrictions and disjointnesses / differences have been defined too.

Here is an example creating a 'reasoning-ready' ontology:

::

   >>> from owlready2 import *
   
   >>> onto = get_ontology("http://test.org/onto.owl")
   
   >>> with onto:
   ...     class Drug(Thing):
   ...         def take(self): print("I took a drug")
   
   ...     class ActivePrinciple(Thing):
   ...         pass
   
   ...     class has_for_active_principle(Drug >> ActivePrinciple):
   ...         python_name = "active_principles"

   ...     class Placebo(Drug):
   ...         equivalent_to = [Drug & Not(has_for_active_principle.some(ActivePrinciple))]
   ...         def take(self): print("I took a placebo")

   ...     class SingleActivePrincipleDrug(Drug):
   ...         equivalent_to = [Drug & has_for_active_principle.exactly(1, ActivePrinciple)]
   ...         def take(self): print("I took a drug with a single active principle")
   
   ...     class DrugAssociation(Drug):
   ...         equivalent_to = [Drug & has_for_active_principle.min(2, ActivePrinciple)]
   ...         def take(self): print("I took a drug with %s active principles" % len(self.active_principles))
   
   >>> acetaminophen   = ActivePrinciple("acetaminophen")
   >>> amoxicillin     = ActivePrinciple("amoxicillin")
   >>> clavulanic_acid = ActivePrinciple("clavulanic_acid")
   
   >>> AllDifferent([acetaminophen, amoxicillin, clavulanic_acid])

   >>> drug1 = Drug(active_principles = [acetaminophen])
   >>> drug2 = Drug(active_principles = [amoxicillin, clavulanic_acid])
   >>> drug3 = Drug(active_principles = [])
   
   >>> close_world(Drug)


Running the reasoner
--------------------

The reasoner (HermiT) is simply run by calling the sync_reasoner() global function:

::

   >>> sync_reasoner()

By default, sync_reasoner() places all inferred facts in a special ontology, 'http://inferrences/'.
You can control in which ontology the inferred facts are placed using the 'with ontology' statement
(remember, all triples asserted inside a 'with ontology' statement go inside this ontology).
For example, for placing all inferred facts in the 'onto' ontology:

::

   >>> with onto:
   ...     sync_reasoner()


This allows saving the ontology with the inferred facts (using onto.save() as usual).

The reasoner can also be limited to some ontologies:

::

   >>> sync_reasoner([onto1, onto2,...])

If you also want to infer object property values, use the "infer_property_values" parameter:

::

   >>> sync_reasoner(infer_property_values = True)

If you want to ignore unsupported datatypes, use the "ignore_unsupported_datatypes" parameter:

::

   >>> sync_reasoner(ignore_unsupported_datatypes = True)

To use Pellet instead of HermiT, just use the sync_reasoner_pellet() function instead.

In addition, Pellet also supports the inference of data property values, using the "infer_data_property_values" parameter:

::

   >>> sync_reasoner_pellet(infer_property_values = True, infer_data_property_values = True)



Results of the automatic classification
---------------------------------------

Owlready automatically gets the results of the reasoning from HermiT and reclassifies Individuals and Classes,
*i.e* Owlready changes the Classes of Individuals and the superclasses of Classes.

::

   >>> print("drug2 new Classes:", drug2.__class__)
   drug2 new Classes: onto.DrugAssociation
   
   >>> drug1.take()
   I took a drug with a single active principle

   >>> drug2.take()
   I took a drug with 2 active principles

   >>> drug3.take()
   I took a placebo

In this example, drug1, drug2 and drug3 Classes have changed!
The reasoner *deduced* that drug2 is an Association Drug, and that drug3 is a Placebo.

Also notice how the example combines automatic classification of OWL Classes with polymorphism on Python Classes.


Inconsistent classes and ontologies
-----------------------------------

In case of inconsistent ontology, an OwlReadyInconsistentOntologyError is raised.

Inconcistent classes may occur without making the entire ontology inconsistent, as long as these classes have
no individuals. Inconsistent classes are inferred as equivalent to Nothing. They can
be obtained as follows:

::

   >>> list(default_world.inconsistent_classes())

In addition, the consistency of a given class can be tested by checking for Nothing in its equivalent classes,
as follows:

::

   >>> if Nothing in Drug.equivalent_to:
   ...       print("Drug is inconsistent!")

.. note::

   To debug an inconsistent ontology the ``explain`` command of the Pellet reasoner can provide some useful information.
   The output of this command is shown if for ``sync_reasoner_pellet(...)`` the keyword argument ``debug`` has a value >=2 (default is 1).
   However, note that the additional call to ``pellet explain`` might take more time than the reasoning itself.


Querying inferred classification
--------------------------------

The .get_parents_of(), .get_instances_of() and .get_children_of() methods of an ontology can be used to query the
hierarchical relations, limited to those defined in the given ontology. This is commonly used after reasoning,
to obtain the inferred hierarchical relations.

 * .get_parents_of(entity) accepts any entity (Class, property or individual), and returns
   the superclasses (for a class), the superproperties (for a property), or the classes (for an individual).
   (NB for obtaining all parents, independently of the ontology they are asserted in, use entity.is_a).
 * .get_instances_of(Class) returns the individuals that are asserted as belonging to the given Class in the ontology.
   (NB for obtaining all instances, independently of the ontology they are asserted in, use Class.instances()).
 * .get_children_of(entity) returns the subclasses (or subproperties) that are asserted for the given Class
   or property in the ontology.
   (NB for obtaining all children, independently of the ontology they are asserted in, use entity.subclasses()).

Here is an example:

::

   >>> inferences = get_ontology("http://test.org/onto_inferences.owl")
   >>> with inferences:
   ...     sync_reasoner()
   
   >>> inferences.get_parents_of(drug1)
   [onto.SingleActivePrincipleDrug]
   
   >>> drug1.is_a
   [onto.has_for_active_principle.only(OneOf([onto.acetaminophen])), onto.SingleActivePrincipleDrug]
   



================================================
File: doc/requirements.txt
================================================
sphinx
sphinx_rtd_theme



================================================
File: doc/restriction.rst
================================================
Class constructs, restrictions and logical operators
====================================================

Restrictions are special types of Classes in ontology.

Restrictions on a Property
--------------------------

::

   >>> from owlready2 import *
   
   >>> onto = get_ontology("http://test.org/onto.owl")
   
   >>> with onto:
   ...     class Drug(Thing):
   ...         pass
   ...     class ActivePrinciple(Thing):
   ...         pass
   ...     class has_for_active_principle(Drug >> ActivePrinciple):
   ...         pass


For example, a non-Placebo Drug is a Drug with an Active Principle:

::
   
   >>> class NonPlaceboDrug(Drug):
   ...     equivalent_to = [Drug & has_for_active_principle.some(ActivePrinciple)]

 
And a Placebo is a Drug with no Active Principle:

::

   >>> class Placebo(Drug):
   ...     equivalent_to = [Drug & Not(has_for_active_principle.some(ActivePrinciple))]

In the example above, 'has_for_active_principle.some(ActivePrinciple)' is the Class of all
objects that have at least one Active Principle.
The Not() function returns the negation (or complement) of a Class.
The & operator returns the intersection of two Classes.

Another example, an Association Drug is a Drug that associates two or more Active Principle:

::

   >>> with onto:
   ...     class DrugAssociation(Drug):
   ...         equivalent_to = [Drug & has_for_active_principle.min(2, ActivePrinciple)]

Owlready provides the following types of restrictions (they have the same names than in Protégé):

 * some : Property.some(Range_Class)
 * only : Property.only(Range_Class)
 * min : Property.min(cardinality, Range_Class)
 * max : Property.max(cardinality, Range_Class)
 * exactly : Property.exactly(cardinality, Range_Class)
 * value : Property.value(Range_Individual / Literal value)
 * has_self : Property.has_self(Boolean value)

When defining classes, restrictions can be used in class definition (i.e. 'equivalent_to ='),
but also as superclasses, using 'is_a =', as in the following example:

::

   >>> with onto:
   ...     class MyClass(Thing):
   ...         is_a = [my_property.some(Value)]
   
In addition, restrictions can be added to existing classes by adding them to .is_a or .equivalent_to,
as in the two following examples:

::

   >>> MyClass.is_a.append(my_property.some(Value))

   >>> MyClass.equivalent_to.append(my_property.some(Value))


Restrictions can be modified *in place* (Owlready2 updates the quadstore automatically), using the
following attributes: .property, .type (SOME, ONLY, MIN, MAX, EXACTLY or VALUE), .cardinality
and .value (a Class, an Individual, a class contruct or another restriction).

Finally, the Inverse(Property) construct can be used as the inverse of a given Property.


Restrictions as class properties
--------------------------------

Owlready allows to access restriction as class properties.

By default, existential restrictions (i.e. SOME restrictions and VALUES restrictions) can be accessed
as if they were class properties in Owlready. For example:

::
   
   >>> NonPlaceboDrug.has_for_active_principle
   [onto.ActivePrinciple]

These class attributes can also be modified (e.g. NonPlaceboDrug.has_for_active_principle.append(...) ).

The .class_property_type attribute of Properties allows to indicate how to handle class properties.
It is a list made of the following values:

 * "some": handle class properties as existential restrictions (i.e. SOME restrictions and VALUES restrictions).
 * "only": handle class properties as universal restrictions (i.e. ONLY restrictions).
 * "relation": handle class properties as relations (i.e. simple RDF triple, as in Linked Data).

When more than one value is specified, all the specified method are used when defining the value of the property
for a class.
 
The .class_property_type attribute corresponds to the "http://www.lesfleursdunormal.fr/static/_downloads/owlready_ontology.owl#class_property_type"
annotation.

The set_default_class_property_type(types) global function allows to set the default type of class property used,
when no type is specified for a given property. The default value is ["some"].


Restrictions as class properties in defined classes
---------------------------------------------------

Defined classes are classes that are defined by an "equivalent to" relation, such as Placebo and NonPlaceboDrug above.

The .defined_class Boolean attribute can be used to mark a class as "defined".
It corresponds to the "http://www.lesfleursdunormal.fr/static/_downloads/owlready_ontology.owl#defined_class" annotation.

When a class is marked as "defined", Owlready automatically generates an equivalent_to formula, taking into account
the class parents and the class properties.

The following program shows an example. It creates a drug ontology, with a Drug class and several HealthConditions.
In addition, two properties are created, for indiciations and contraindications. Here, we choose to manage indications
with SOME restrictions and contraindication with ONLY restrictions.

Then, the program creates two subclasses of Drug: Antalgic and Aspirin. Thoses subclasses are marked as defined (with
defined_class = True), and their properties are defined also.

::

   >>> onto2 = get_ontology("http://test.org/onto2.owl")
   
   >>> with onto2:
   ...     class Drug(Thing): pass
   ...     class ActivePrinciple(Thing): pass
   ...     class has_for_active_principle(Drug >> ActivePrinciple): pass
      
   ...     class HeathCondition(Thing): pass
   ...     class Pain(HeathCondition): pass
   ...     class ModeratePain(Pain): pass
   ...     class CardiacDisorder(HeathCondition): pass
   ...     class Hypertension(CardiacDisorder): pass
      
   ...     class Pregnancy(HeathCondition): pass
   ...     class Child(HeathCondition): pass
   ...     class Bleeding(HeathCondition): pass
      
   ...     class has_for_indications      (Drug >> HeathCondition): class_property_type = ["some"]
   ...     class has_for_contraindications(Drug >> HeathCondition): class_property_type = ["only"]
  
   ...     class Antalgic(Drug): 
   ...         defined_class = True
   ...         has_for_indications = [Pain]
   ...         has_for_contraindications = [Pregnancy, Child, Bleeding]
        
   ...     class Aspirin(Antalgic):
   ...         defined_class = True
   ...         has_for_indications = [ModeratePain]
   ...         has_for_contraindications = [Pregnancy, Bleeding]


Owlready automatically produces the appropriate equivalent_to formula, as we can verify:

::

   >>> print(Antalgic.equivalent_to)
   [onto.Drug
   & onto.has_for_indications.some(onto.Pain)
   & onto.has_for_contraindications.only(onto.Child | onto.Pregnancy | onto.Bleeding)]
   
   >>> print(Aspirin.equivalent_to)
   [onto.Antalgic
   & onto.has_for_indications.some(onto.ModeratePain)
   & onto.has_for_contraindications.only(onto.Pregnancy | onto.Bleeding)]


Notice that this mapping between class properties and definition is bidirectional: one can also use it to access
an existing definition as class properties. The following example illustrates that:

::

   >>> with onto2:
   ...     class Antihypertensive(Drug):
   ...         equivalent_to = [Drug
   ...                          & has_for_indications.some(Hypertension)
   ...                          &has_for_contraindications.only(Pregnancy)]
   
   >>> print(Antihypertensive.has_for_indications)
   [onto.Hypertension]
   
   >>> print(Antihypertensive.has_for_contraindications)
   [onto.Pregnancy]


   
Logical operators (intersection, union and complement)
------------------------------------------------------

Owlready provides the following operators between Classes
(normal Classes but also class constructs and restrictions):

 * '&' : And operator (intersection). For example: Class1 & Class2.
   It can also be written: And([Class1, Class2])
 * '|' : Or operator (union). For example: Class1 | Class2.
   It can also be written: Or([Class1, Class2])
 * Not() : Not operator (negation or complement). For example: Not(Class1)

The Classes used with logical operators can be normal Classes (inheriting from Thing), restrictions or
other logical operators. 

Intersections, unions and complements can be modified *in place* using
the .Classes (intersections and unions) or .Class (complement) attributes.


One-Of constructs
-----------------

In ontologies, a 'One Of' statement is used for defining a Class by extension, *i.e.* by listing its Instances
rather than by defining its properties.

::
   
   >>> with onto:
   ...     class DrugForm(Thing):
   ...         pass
   
   >>> tablet     = DrugForm()
   >>> capsule    = DrugForm()
   >>> injectable = DrugForm()
   >>> pomade     = DrugForm()
   
   # Assert that there is only four possible drug forms
   >>> DrugForm.is_a.append(OneOf([tablet, capsule, injectable, pomade]))
   
The construct be modified *in place* using the .instances attribute.


Inverse-of constructs
---------------------

Inverse-of constructs produces the inverse of a property, without creating a new property.

::
   
   Inverse(has_for_active_principle)
   
The construct be modified *in place* using the .property attribute.


ConstrainedDatatype
-------------------

A constrained datatype is a data whose value is restricted, for example an integer between 0 and 20.

The global function ConstrainedDatatype() create a constrained datatype from a base datatype,
and one or more facets:

* length
* min_length
* max_length
* pattern
* white_space
* max_inclusive
* max_exclusive
* min_inclusive
* min_exclusive
* total_digits
* fraction_digits

For example:

::

   ConstrainedDatatype(int, min_inclusive = 0, max_inclusive = 20)
   ConstrainedDatatype(str, max_length = 100)
  

Property chain
--------------

Property chain allows to chain two properties (this is sometimes noted prop1 o prop2).
The PropertyChain() function allows to create a new property chain from a list of properties:

::
   
   PropertyChain([prop1, prop2])
   
The construct be modified *in place* using the .properties attribute.




================================================
File: doc/rule.rst
================================================
SWRL rules
==========

SWRL rules can be used to integrate 'if... then...' rules in ontologies.

Note: loading SWRL rules is **only** supported from RDF/XML and NTriples files, but not from OWL/XML files.


Creating SWRL rules
-------------------

The Imp class ("Implies") represent a rule. The easiest way to create a rule is to define it
using a Protégé-like syntax, with the .set_as_rule() method.

The following example use a rule to compute the per-tablet cost of a drug:

::
   
   >>> onto = get_ontology("http://test.org/drug.owl")
   
   >>> with onto:
   ...     class Drug(Thing): pass
   ...     class number_of_tablets(Drug >> int, FunctionalProperty): pass
   ...     class price(Drug >> float, FunctionalProperty): pass
   ...     class price_per_tablet(Drug >> float, FunctionalProperty): pass
   ...
   ...     rule = Imp()
   ...     rule.set_as_rule("""Drug(?d), price(?d, ?p), number_of_tablets(?d, ?n), divide(?r, ?p, ?n) -> price_per_tablet(?d, ?r)""")

   
We can now create a drug, run the reasoner (only Pellet support inferrence on data property value)
and print the result:
::
   
   >>> drug = Drug(number_of_tablets = 10, price = 25.0)
   >>> sync_reasoner_pellet(infer_property_values = True, infer_data_property_values = True)
   >>> drug.price_per_tablet
   2.5


Displaying rules
----------------

The str() Python function can be used to format rules, for example:

::

   >>> str(rule)
   'Drug(?d), price(?d, ?p), number_of_tablets(?d, ?n), divide(?r, ?p, ?n) -> price_per_tablet(?d, ?r)'


   
Modifying rules manually
------------------------

Owlready also allows to access to the inner content of rules. Each rules have a body (= conditions)
and head (= consequences) :

::
   
   >>> rule.body
   [Drug(?d), price(?d, ?p), number_of_tablets(?d, ?n), divide(?r, ?p, ?n)]
   >>> rule.head
   [price_per_tablet(?d, ?r)]

   
Body and head are list of SWRL atoms. The attributes of each atom can be read and modified:

::

   >>> rule.body[0]
   Drug(?d)
   >>> rule.body[0].class_predicate
   drug.Drug
   >>> rule.body[0].arguments
   [?d]

Please refer to SWRL documentation for the list of atoms and their description. One notable difference is that
Owlready always use the "arguments" attributes for accessing arguments, while SWRL uses sometimes "arguments"
and sometimes "argument1" and "argument2".



================================================
File: doc/sparql.rst
================================================
SPARQL queries
==============

Since version 0.30, Owlready proposes 2 methods for performing SPARQL queries: the native SPARQL engine and RDFlib.


Native SPARQL engine
********************

The native SPARQL engine automatically translates SPARQL queries into SQL queries, and then run the SQL queries with SQLite3.

The native SPARQL engine has better performances than RDFlib (about 60 times faster when tested on Gene Ontology,
but it highly depends on queries and data). It also has no dependencies and it has a much shorter start-up time.

However, it currently supports only a subset of SPARQL.


SPARQL elements supported
-------------------------

* SELECT, INSERT and DELETE queries
* UNION
* OPTIONAL
* FILTER, BIND, FILTER EXISTS, FILTER NOT EXISTS
* GRAPH clauses
* SELECT sub queries
* VALUES in SELECT queries
* All SPARQL functions and aggregation functions
* Blank nodes notations with square bracket, e.g. '[ a XXX]'
* Parameters in queries (i.e. '??' or '??1')
* Property path expressions, e.g. 'a/rdfs:subClassOf*',  excepted those listed below

SPARQL elements not supported
-----------------------------

* ASK, DESCRIBE, LOAD, ADD, MOVE, COPY, CLEAR, DROP, CONSTRUCT queries
* INSERT DATA, DELETE DATA, DELETE WHERE queries (you may use INSERT or DELETE instead)
* SERVICE (Federated queries)
* FROM, FROM NAMED keywords
* MINUS
* Property path expressions with parentheses of the following forms:

  - nested repeats, e.g. (a/p*)*
  - sequence nested inside a repeat, e.g. (p1/p2)*
  - negative property set nested inside a repeat, e.g. (!(p1 | p2))*

  i.e. repeats cannot contain other repeats, sequences and negative property sets.


Performing SPARQL queries
-------------------------

The .sparql() methods of the World object can be used to perform a SPARQL query and obtain the results.
Notice that .sparql() returns a generator, so we used here the list() function to show the results.
The list contains one row for each result found, with one or more columns (depending on the query).

::
   
   >>> # Loads Gene Ontology (~ 170 Mb), can take a moment!
   >>> go = get_ontology("http://purl.obolibrary.org/obo/go.owl").load()
   
   >>> # Get the number of OWL Class in GO
   >>> list(default_world.sparql("""
              SELECT (COUNT(?x) AS ?nb)
              { ?x a owl:Class . }
       """))
   [[60448]]


Notice that the following prefixes are automatically pre-defined:

*  rdf: -> http://www.w3.org/1999/02/22-rdf-syntax-ns#
*  rdfs: -> http://www.w3.org/2000/01/rdf-schema#
*  owl: -> http://www.w3.org/2002/07/owl#
*  xsd: -> http://www.w3.org/2001/XMLSchema#
*  obo: -> http://purl.obolibrary.org/obo/
*  owlready: -> http://www.lesfleursdunormal.fr/static/_downloads/owlready_ontology.owl#

In addition, Owlready automatically create prefixes from the last part of ontology IRI (without .owl extension),
e.g. the ontology "http://test.org/onto.owl" with be automatically associated with the "onto:" prefix.
Consequently, in most case you don't need to define prefixes (but you can still define them if you want).

The classes counted above include OWL named classes, but also some OWL constructs. One may count only named classes
using a FILTER condition and the ISIRI function, as follows:

::
   
   >>> # Get the number of OWL Class in GO
   >>> list(default_world.sparql("""
              SELECT (COUNT(?x) AS ?nb)
              { ?x a owl:Class . FILTER(ISIRI(?x)) }
       """))
   [[48535]]


We may also search for a given concept. When a query returns an entity, it returns it as an Owlready object.

::
   
   >>> # Get the "mitochondrion inheritance" concept from GO
   >>> r = list(default_world.sparql("""
              SELECT ?x
              { ?x rdfs:label "mitochondrion inheritance" . }
       """))
   >>> r
   [[obo.GO_0000001]]
   >>> mito_inher = r[0][0]

Here, the resulting object 'mito_inher' is an Owlready object (here, a Class) that can be used as any other classes in Owlready.

Owlready support simple property path expressions, such as 'rdfs:subClassOf*' or 'a/rdfs:subClassOf*'.
For example, we can get the superclasses of "mitochondrion inheritance" as follows:

::
   
   >>> list(default_world.sparql("""
              SELECT ?y
              { ?x rdfs:label "mitochondrion inheritance" .
                ?x rdfs:subClassOf* ?y }
       """))
   [[obo.GO_0000001], [obo.GO_0048308], [obo.GO_0048311], [obo.GO_0006996], [obo.GO_0007005], [obo.GO_0051646], [obo.GO_0016043], [obo.GO_0051640], [obo.GO_0009987], [obo.GO_0071840], [obo.GO_0051641], [obo.GO_0008150], [obo.GO_0051179]]

 
Or we can search for individuals belonging to the class "mitochondrion inheritance" or one of its descendants, as follows:

::
   
   >>> list(default_world.sparql("""
              SELECT ?y
              { ?x rdfs:label "mitochondrion inheritance" .
                ?y a/rdfs:subClassOf* ?x }
       """))
   []
   
(Here, we have no results because Gene Ontology does not include individuals).



INSERT queries
--------------

The ontology in which the new RDF triples are inserted can be given using a "with ontology:" block or
using the "WITH <ontology IRI> INSERT ..." syntax in SPARQL. If both are present, the "with ontology:" block takes priority.

::
   
   >>> insertion = get_ontology("http://test.org/insertion.owl")
   >>> with insertion:
   ...     default_world.sparql("""
              INSERT { ?x rdfs:label "héritage mitochondrial"@fr }
              WHERE  { ?x rdfs:label "mitochondrion inheritance" . }
              """)
   1

INSERT / DELETE queries returns the number of matches found by the WHERE part.

When running INSERT / DELETE queries, Owlready tries to update the Python objects corresponding to the modified entities,
if they were loaded from the quadstore.

The following example shows how to create new individuals with an INSERT query. It creates an individual for each subclass
of "membrane".

::
   
   >>> insertion = get_ontology("http://test.org/insertion.owl")
   >>> with insertion:
   ...     default_world.sparql("""
              INSERT { ?n rdfs:label "New individual!" . }
              WHERE  { ?x rdfs:label "membrane" .
                       ?y rdfs:subClassOf ?x .
                       BIND(NEWINSTANCEIRI(?y) AS ?n) }
              """)
   

We use here a BIND statement in order to create a new IRI, using the NEWINSTANCEIRI() function that create a new IRI for
an individual, similar to those created automatically by Owlready. You may also use the more standard UUID() SPARQL function,
which create a random arbitrary IRI.

The following example shows how to create OWL construct like restrictions with an INSERT query.

::
   
   >>> insertion = get_ontology("http://test.org/insertion.owl")
   >>> with insertion:
   ...     default_world.sparql("""
              INSERT { ?x rdfs:subClassOf [ a owl:Restriction ;
                                            owl:onProperty obo:BFO_0000050 ;
                                            owl:someValuesFrom obo:GO_0005623 ] . }
              WHERE  { ?x rdfs:label "membrane" . }
              """)
   1
   
   >>> obo.GO_0016020.label
   ['membrane']
   >>> obo.GO_0016020.is_a
   [obo.GO_0044464, obo.BFO_0000050.some(obo.GO_0005623)]

   

DELETE queries
--------------

DELETE queries are supported; they do not need to specify the ontology from which RDF triples are deleted.

::
   
   >>> default_world.sparql("""
           DELETE { ?r ?p ?o . }
           WHERE  {
               ?x rdfs:label "membrane" .
               ?x rdfs:subClassOf ?r .
               ?r a owl:Restriction .
               ?r ?p ?o .
           }
           """)

The native SPARQL engine supports queries with both a DELETE and an INSERT statement.


Parameters in SPARQL queries
----------------------------

Parameters allow to run the same query multiple times, with different parameter values.
They have two interests. First, they increase performances since the same query can be reused, thus avoiding to
parse new queries. Second, they prevent security problems by avoiding SPARQL code injection, e.g. if a string value includes
quotation marks.

Parameters can be included in the query by using double question marks, e.g. "??". Parameter values can be Owlready entities
or datatype values (int, float, string, etc.). Parameter values are passed in a list after the query:

::
   
   >>> list(default_world.sparql("""
              SELECT ?y
              { ?? rdfs:subClassOf* ?y }
       """, [mito_inher]))
   [[obo.GO_0000001], [obo.GO_0048308], [obo.GO_0048311],
    [obo.GO_0006996], [obo.GO_0007005], [obo.GO_0051646],
    [obo.GO_0016043], [obo.GO_0051640], [obo.GO_0009987],
    [obo.GO_0071840], [obo.GO_0051641], [obo.GO_0008150],
    [obo.GO_0051179]]


Parameters can also be numbered, e.g. "??1", "??2", etc. This is particularly usefull if the same parameter is used
multiple times in the query.

::
   
   >>> list(default_world.sparql("""
              SELECT ?y
              { ??1 rdfs:subClassOf* ?y }
       """, [mito_inher]))
   [[obo.GO_0000001], [obo.GO_0048308], [obo.GO_0048311],
    [obo.GO_0006996], [obo.GO_0007005], [obo.GO_0051646],
    [obo.GO_0016043], [obo.GO_0051640], [obo.GO_0009987],
    [obo.GO_0071840], [obo.GO_0051641], [obo.GO_0008150],
    [obo.GO_0051179]]


Non-standard additions to SPARQL
--------------------------------

The following functions are supported by Owlready, but not standard:

 * The SIMPLEREPLACE(a, b) function is a version of REPLACE() that does not support Regex. It works like Python or SQLite3 replace,
   and has better performances.
   
 * THE LIKE(a, b) function performs similarly to the SQL Like operator. It is more limited, but faster than the Regex SPARQL functions.
   
 * The NEWINSTANCEIRI() function create a new IRI for an instance of the class given as argument. This IRI is similar to those
   created by default by Owlready. Note that the function creates 2 RDF triples, asserting that the new individual is an
   OWL NamedIndividual and an instance of the desired class passed as argument.

 * The LOADED(iri) function returns True if the entity with the given IRI is currently loaded in Python, and False otherwise.

 * The STORID(iri) function returns the integer Store-ID used by Owlready in the quadstore for representing the entity.

 * The DATE(), TIME() and DATETIME() functions can be used to handle date and time. They behave as in SQLite3 (see https://www.sqlite.org/lang_datefunc.html).

 * The DATE_SUB(), DATE_ADD(), DATETIME_SUB and DATETIME_ADD() functions can be used to substract or add a time duration to a date or a datetime, for example : DATETIME_ADD(NOW(), "P1Y"^^xsd:duration)

In Owlready, INSERT and DELETE queries can have a GROUP BY, HAVING and/or ORDER BY clauses.
This is normally not allowed by the SPARQL specification.


Prepare SPARQL queries
----------------------

The .prepare_sparql() method of the World object can be used to prepare a SPARQL query. It returns a PreparedQuery object.

The .execute() method of the PreparedQuery can be used to execute the query. It takes as argument the list of parameters,
if any.

.. note::
   
   The .sparql() method calls .prepare_sparql(). Thus, there is no interest, in terms of performances, to use
   .prepare_sparql() instead of .sparql().

The PreparedQuery can be used to determine the type of query:

::

   >>> query = default_world.prepare_sparql("""SELECT (COUNT(?x) AS ?nb) { ?x a owl:Class . }""")
   >>> isinstance(query, owlready2.sparql.main.PreparedSelectQuery)
   True
   >>> isinstance(query, owlready2.sparql.main.PreparedModifyQuery) # INSERT and/or DELETE
   False

The following attributes are availble on the PreparedQuery object:

 * .nb_parameter: the number of parameters
 * .column_names: a list with the names of the columns in the query results, e.g. ["?nb"] in the example above.
 * .world: the world object for which the query has been prepared
 * .sql: the SQL translation of the SPARQL query

::

   >>> query.sql
   'SELECT  COUNT(q1.s), 43 FROM objs q1 WHERE q1.p=6 AND q1.o=11'
   
.. note::
   
   For INSERT and DELETE query, the .sql translation only involves the WHERE part. Insertions and deletions are
   performed in Python, not in SQL, in order to update the modified Owlready Python objects, if needed.


Open a SPARQL endpoint
----------------------

The owlready2.sparql.endpoint module can be used to open a SPARQL endpoint. It requires Flask or WSGI. It contains the EndPoint
class, that takes a World and can be used as a Flask page function.

The following script creates a SPARQL endpoint with Flask:

::
   
   import flask
   
   from owlready2 import *
   from owlready2.sparql.endpoint import *

   # Load one or more ontologies
   go = get_ontology("http://purl.obolibrary.org/obo/go.owl").load() # (~ 170 Mb), can take a moment!
   
   app = flask.Flask("Owlready_sparql_endpoint")
   endpoint = EndPoint(default_world)
   app.route("/sparql", methods = ["GET"])(endpoint)
   
   # Run the server with Werkzeug; you may use any other WSGI-compatible server
   import werkzeug.serving
   werkzeug.serving.run_simple("localhost", 5000, app)


And the following script does the same, but with WSGI:

::
   
   from owlready2 import *
   from owlready2.sparql.endpoint import *

   # Load one or more ontologies
   go = get_ontology("http://purl.obolibrary.org/obo/go.owl").load() # (~ 170 Mb), can take a moment!
   
   endpoint = EndPoint(default_world)
   app = endpoint.wsgi_app
   
   # Run the server with Werkzeug; you may use any other WSGI-compatible server
   import werkzeug.serving
   werkzeug.serving.run_simple("localhost", 5000, app)

   
You can then query the endpoint, e.g. by opening the following URL in your browser:

   `<http://localhost:5000/sparql?query=SELECT(COUNT(?x)AS%20?nb){?x%20a%20owl:Class.}>`_


Using RDFlib for executing SPARQL queries
*****************************************

The Owlready quadstore can be accessed as an RDFlib graph, which can be used to perform SPARQL queries:

::

   >>> graph = default_world.as_rdflib_graph()
   >>> r = list(graph.query("""SELECT ?p WHERE {
     <http://www.semanticweb.org/jiba/ontologies/2017/0/test#ma_pizza> <http://www.semanticweb.org/jiba/ontologies/2017/0/test#price> ?p .
   }"""))


The results can be automatically converted to Python and Owlready using the .query_owlready() method instead of .query():

::

   >>> r = list(graph.query_owlready("""SELECT ?p WHERE {
     <http://www.semanticweb.org/jiba/ontologies/2017/0/test#ma_pizza> <http://www.semanticweb.org/jiba/ontologies/2017/0/test#price> ?p .
   }"""))




================================================
File: doc/sync.rst
================================================
Parallelism, multiprocessing and synchronization
================================================

Parallelism consist in executing several part of your program in parallel.
Three options are possible:

 * **cooperative microthread (e.g. greenlets with GEvent):** it allows running several "greenlet" in parallel,
   switching from one to others, but it does not actually run several commands in parallel and increase performances.
   Nevertheless, it is very interesting in a server setting: 
 * **multi-thread parallelism:** it allows sharing data and objects between threads, however,
   Python has poor multithreading supports (due to the global interpreter lock (GIL), only one thread at a time may execute Python commands).
 * **multi-process parallelism:** it allows executing Python commands in parallel,
   however, data sharing is more difficult and objects cannot be shared between processes. In addition, keep in mind that
   Owlready does not update the local Python objects from the quadstore if they are modified by other processes.
   
Owlready (>= 0.41) supports all options:

 * cooperative microthread can be used in a server setting, in order to let the server answer a simple/small request while a long request is running.
 * multi-thread parallelism can be used to parallelize sets of long SPARQL queries (only the SQL query is parallelized, allowing to run Python commands meanwhile). There is no other interesting in multi-threading, due to Python's GIL.
 * multi-process parallelism can be used to run several processes in parallel.
 * cooperative microthread and multi-process parallelism can also be combined together.

Two difficulties arise when using parallelism:

* Sharing data between processes is complex. When using Owlready, the easier solution is to put the quadstore
  with the ontology data on disk. This does not apply to cooperative microthreads and threads.
* Sensible parts of the code must be synchronized, e.g. one should avoid that several threads or processes write in the quadstore
  at the same time.

Several web application servers use multiple processes, and thus you will also encounter these difficulties when using them.
For both microthreads and/or multiple processes, I recommend the `Gunicorn <https://gunicorn.org/>`_ web server.


Parallelized file parsing
-------------------------

For huge OWL file (> 8 Mb), Owlready (>= 0.41) automatically uses a separate process for parsing the file
(the main process being in charge of inserting triples in the quadstore). This provide a 25% performance boost
on huge ontologies.


Thread-based parallel execution of SPARQL queries
-------------------------------------------------

This is the simplest option, and probably the best if you have lots of long SPARQL queries.
Since version 0.41, Owlready supports some level of thread-based parallelization, for increasing performances
by executing several SPARQL queries in parallel. It does not require to care about synchronization or data sharing.

In order to use this feature, you first need to use a World stored on disk in a local file,
to deactive exclusive mode and to activate thread parallelism support, as follows:

::
   
   >>> default_world.set_backend(filename  = "my_quadstore.sqlite3",
                                 exclusive = False,
                                 enable_thread_parallelism = True)

When thread parallelism is activated, Owlready opens 3 additional connexions to the SQLite3 database storing the quadstore,
allowing 3 parallel threads.

Then, the quadstore must be saved on disk before running parallel queries, as follows:

::
   
   >>> default_world.save()
   

Executing many SPARQL queries in parallel
.........................................

The owlready2.sparql.execute_many() function can be used to execute several prepared SPARQL queries in parallel.
Both SELECT and INSERT/DELETE queries are supported.

execute_many() will start 3 threads for executing the queries in parallel, and returns a list of query results.

You may expect up to 100% performance boost, especially when the queries are long and complex
and the number of results is small (currently, Owlready only parallelize the SQL execution,
but not the loading of the resulting objects from the quadstore).

Here is a typical usage:

::

   >>> my_onto = get_ontology("XXX ontology IRI here")
   
   >>> queries = [
   ...     default_world.prepare_sparql("""XXX First SPARQL query here"""),
   ...     ...,
   ... ]
   
   >>> queries_params = [
   ...     [], # First SPARQL query parameters
   ...     ...,
   ... ]
   
   >>> import owlready2.sparql
   >>> results = [list(gen) for gen in owlready2.sparql.execute_many(my_onto, queries, queries_params)]

If you are also using cooperative microthreads with Gevent, you may use the Gevent thread pool.
This can be done by providing a "spawn" function to execute_many(). The spawn function must accept a
callable with no argument, start a thread executing that callable, and return the thread object (which is expected to have
a .join() method). Here is an example for Gevent:

::

   >>> import gevent.hub
   >>> gevent_spawn = gevent.hub.get_hub().threadpool.apply_async
   >>> results = [list(gen) for gen in owlready2.sparql.execute_many(my_onto, queries, queries_params, gevent_spawn)]


Executing a single SPARQL query in parallel
...........................................

A single SPARQL query can be executed in parallel, in a separate thread. The query will not run faster (it will rather takes
a little more time), but the main thread will be let available for other tasks. This can be interesting e.g. on a server,
where a long query can be parallelized; meanwhile, the main thread may answer to other clients.

::
   
   >>> query = default_world.prepare_sparql("""XXX SPARQL query here""")
   >>> query.execute(spawn = True)


Similarly, you may want to use the Gevent thread pool, as follows:

::

   >>> import gevent.hub
   >>> gevent_spawn = gevent.hub.get_hub().threadpool.apply_async
   >>> query.execute(spawn = gevent_spawn)


Cooperative microthreads (e.g. GEvent)
--------------------------------------

Microthreads will not improve the performances of Owlready, however, they will allow running several tasks in parallel,
which is interesting if you need to perform small tasks during long tasks (e.g. in a server), or if some part of your
program is waiting on an external, non-Python, task (e.g. a network call, including the use of a server database
like Postgresql).

Synchronization
...............

For using Owlready with cooperative microthreads, you need to:

* Use a custom lock for the quadstore. By default, Owlready use the internal SQLite3 database as a lock; this does not
  work with microthreads because all microthreads share the same SQLite3 connexion. The solution is to use a custom lock,
  for example with GEvent :
  
  ::
     
     >>> gevent.lock
     >>> default_world.set_backend(filename = "your_quadstore.sqlite3",
     ...                           lock     = gevent.lock.RLock())
     
* Perform each modification to an ontology inside a "with ontology:" block.
  This prevents multiple writes at the same time.
  For improving performances, you should also avoid long computation inside "with ontology:" blocks.
  
* Switch to other microthreads when desired (by calling gevent.sleep(0)).
  To let other microthreads write in the quadstore, you should do that outside "with ontology:" blocks.
  
Other synchronization tasks (listed below, for multiprocessing) are not needed for microthreads.


Multiprocessing
---------------

Multiprocessing requires synchronization, which can be very complex (and may have a significant performance cost).

Multiprocessing is recommended when using a read-only quadstore, because Owlready does not update the local
Python objects from the quadstore if they are modified by another process.

Owlready does not update the local Python objects from the quadstore when they are modified by another process.
Consequently, multiprocessing is recommended when using a read-only quadstore, or when the data can be split between
processes. For example, in a medical application, each process might be in charge of a sub-set of the patients.


Synchronization
...............

For using Owlready with multiple processes, and sharing the quadstore between processes, you need to:

* Store the quadstore on disk, and open the quadstore in non-exclusive mode (exclusive = False in set_backend()).
  For example:

  ::
     
     >>> default_world.set_backend(filename  = "your_quadstore.sqlite3",
     ...                           exclusive = False)
       
* Perform each modification to an ontology inside a "with ontology:" block. Owlready maintain a lock for each
  quadstore, which prevents multiple writes at the same time.
  Thus, for improving performances, you should also avoid long computation inside "with ontology:" blocks.
* You may also use "with world:" blocks to synchronize on the quadstore, but without specifying a particular ontology.
* Call World.save() at the end of each "with ontology:" block, in order to commit the changes to the quadstore database.
* If an individual may have been modified by another process, you can use the .reload() method to force reloading its
  property values:

  ::
     
     >>> individual.reload()


Server example
..............

This section gives a small example of a multi-process server using a shared Owlready quadstore.

The example uses `Flask <https://flask.palletsprojects.com/>`_ and `Gunicorn <https://gunicorn.org/>`_.
It provides 2 URL: the first one (/gen) creates 5 new instances of the C class. The second (/test) returns the ID
of the current process and the number of instances in the quadstore.

::

   import sys, os, flask, time
   from owlready2 import *
   
   default_world.set_backend(filename = "/tmp/t.sqlite3", exclusive = False)
   
   onto = get_ontology("http://test.org/onto.owl")
   
   with onto:
     class C(Thing): pass
     default_world.save()
     
   
   app = flask.Flask("OwlreadyBench")
   
   @app.route("/gen")
   def gen():
     with onto:
       for i in range(5):
         c = C()
         c.label = [os.getpid()]
         print(c, c.storid)
       default_world.save()
     return ""
   
   @app.route("/test")
   def test():
     time.sleep(0.02)
     nb = len(list(C.instances()))
     return "%s %s" % (os.getpid(), nb)

You can run this server in multiprocessor mode with Gunicorn as follows:

::

   gunicorn -b 127.0.0.1:5000 --preload -w 5 --worker-class=gevent test:app

where "test" is the previous file's name (without ".py"),
and 5 in "-w 5" is recommended to be the number of CPU plus 1 (here, my computer has 4 CPU, thus -w 5).

Then, after running the server, you can use the following script to make 100 concurrent calls to /gen, and then
10 concurrent calls to /test:

::
   
   from urllib.request import *
   
   import eventlet, eventlet.green.urllib.request
   def fetch(url): return eventlet.green.urllib.request.urlopen(url).read()
   
   urls = ["http://localhost:5000/gen"] * 100
   pool = eventlet.GreenPool()
   for body in pool.imap(fetch, urls): pass
   
   urls = ["http://localhost:5000/test"] * 10
   pool = eventlet.GreenPool()
   for body in pool.imap(fetch, urls): print(body)

As the 10 calls to /test are executed by different processes, this allows to verify that the various processes have access
to all the created instances (normally, 500 instances).

The previous server example can also be run with `uWSGI <https://uwsgi-docs.readthedocs.io/en/latest/>`_ as follows:

::

   uwsgi --http 127.0.0.1:5000 --plugin python -p 5 --module test:app



Combining multiprocessing with cooperative microthreads
-------------------------------------------------------

Owlready (>= 0.46) can combine together both multiprocessing and cooperative microthreads.
This is interesting if you need microthreads (e.g. because you are using WebSockets) and you want to take advantage of
multiprocessing for improving performances.

For that, you need to store the quadstore on disk, and to open it with the "exclusive = False" and "extra_lock" arguments,
which use the given lock in addition to the SQLite lock (while the lock argument uses it instead of):

::
   
   >>> gevent.lock
   >>> default_world.set_backend(filename   = "your_quadstore.sqlite3",
   ...                           exclusive  = False,
   ...                           extra_lock = gevent.lock.RLock())

You need to follow the synchronization rules for both microthreads and processes, as explained above.




================================================
File: doc/world.rst
================================================
Worlds
======

Owlready2 stores every triples in a 'World' object, and it can handles several Worlds
in parallel. 'default_world' is the World used by default.


Persistent world: storing the quadstore in an SQLite3 file database
-------------------------------------------------------------------

Owlready2 uses an optimized quadstore. By default, the quadstore is stored in memory, but it can also be
stored in an SQLite3 file. This allows persistance: all ontologies loaded and created are stored in the file,
and can be reused later.
This is interesting for big ontologies: loading huge ontologies can take time, while opening the SQLite3 file
takes only a fraction of second, even for big files.
It also avoid to load huge ontologies in memory, if you only need to access a few
entities from these ontologies.

The .set_backend() method of World sets the SQLite3 filename associated to the quadstore,
for example:

::

   >>> default_world.set_backend(filename = "/path/to/your/file.sqlite3")

.. note::
   
   If the quad store is not empty when calling .set_backend(), RDF triples are automatically copied.
   However, this operation can have a high performance cost (especially if there are many triples).


When using persistence, the .save() method of World must be called for saving the actual
state of the quadstore in the SQLite3 file:

::

   >>> default_world.save()

Storing the quadstore in a file does not reduce the performance of Owlready2 (actually,
it seems that Owlready2 performs a little *faster* when storing the quadstore on the disk).

To reload an ontology stored in the quadstore (when the corresponding OWL file has been updated),
the reload and reload_if_newer optional parameters of .load() can be used (the former reload the ontology,
and the latter reload it only if the OWL file is more recent).

By default, Owlready2 opens the SQLite3 database in exclusive mode. This mode is faster, but it does not allow
several programs to use the same database simultaneously. If you need to have several Python programs that
access simultaneously the same Owlready2 quadstore, you can disable the exclusive mode as follows:

::

   >>> default_world.set_backend(filename = "/path/to/your/file.sqlite3", exclusive = False)



Using several isolated Worlds
-----------------------------

Owlready2 can support several, isolated, Worlds.
This is interesting if you want to load several version
of the same ontology, for example before and after reasoning.

A new World can be created using the World class:

::

   >>> my_world = World()
   >>> my_second_world = World(filename = "/path/to/quadstore.sqlite3")

Ontologies are then created and loaded using the .get_ontology() methods of the World
(when working with several Worlds, this method replaces the get_ontology() global function):

::

   >>> onto = my_world.get_ontology("http://test.org/onto/").load()

The World object can be used as a pseudo-dictionary for accessing entities using their IRI.
(when working with several Worlds, this method replaces the IRIS global pseudo-dictionary):
   
::

   >>> my_world["http://test.org/onto/my_iri"]

Finally, the reasoner can be executed on a specific World:
   
::

   >>> sync_reasoner(my_world)


Working with RDFlib
-------------------

Owlready2 uses an optimized RDF quadstore. This quadstore can also be accessed
as an RDFlib graph as follows:

::

   >>> graph = default_world.as_rdflib_graph()


In particular, the RDFlib graph can be used for performing SPARQL queries:

::

   >>> r = list(graph.query("""SELECT ?p WHERE {
     <http://www.semanticweb.org/jiba/ontologies/2017/0/test#ma_pizza> <http://www.semanticweb.org/jiba/ontologies/2017/0/test#price> ?p .
   }"""))




The results can be automatically converted to Python and Owlready using the .query_owlready() method instead of .query():

::

   >>> r = list(graph.query_owlready("""SELECT ?p WHERE {
     <http://www.semanticweb.org/jiba/ontologies/2017/0/test#ma_pizza> <http://www.semanticweb.org/jiba/ontologies/2017/0/test#price> ?p .
   }"""))


.. note::
   
   Owlready now include its own SPARQL engine, documented here: :doc:`sparql`.

Owlready blank nodes can be created with the graph.BNode() method:

::

   >>> bn = graph.BNode()
   >>> with onto:
   ...     graph.add((bn, rdflib.URIRef("http://www.w3.org/1999/02/22-rdf-syntax-ns#type"), rdflib.URIRef("http://www.w3.org/2002/07/owl#Class"))) 




================================================
File: doc/_static/empty.txt
================================================



